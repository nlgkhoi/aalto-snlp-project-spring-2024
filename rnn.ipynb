{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Except that Desmond played first base last nig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What i find funny is the loyalty and blindness...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Read the article  not just the headline &amp; you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Speaking of a horses backside  is that where y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Michael Barone- gee are you dumb.  No other wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  label\n",
       "0   0  Except that Desmond played first base last nig...      0\n",
       "1   1  What i find funny is the loyalty and blindness...      0\n",
       "2   2  Read the article  not just the headline & you ...      0\n",
       "3   3  Speaking of a horses backside  is that where y...      1\n",
       "4   4  Michael Barone- gee are you dumb.  No other wo...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_2024.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import unicodedata\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "EOS_token = 1\n",
    "lemmatizer = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "\tdef __init__(self, csv_path, dataset_type='train', vocab=None):\n",
    "\t\tdf = pd.read_csv(csv_path, quoting=3)\n",
    "\t\tprint(f'len df: {len(df)}')\n",
    "\t\tif dataset_type in ['train', 'val']:\n",
    "\t\t\tself.text, self.labels = zip(*[(text, label) for text, label in zip(df['text'], df['label'])])\n",
    "\t\telse:\n",
    "\t\t\tself.text = df['text'].tolist()\n",
    "\t\t\tself.labels = [0 for _ in range(len(self.text))]\n",
    "\t\tself.ids = df['id'].tolist()\n",
    "\t\tself.dataset_type = dataset_type\n",
    "\t\tself.tokenizer = get_tokenizer('basic_english')\n",
    "\t\tself._preprocess(vocab)\n",
    "\n",
    "\tdef _preprocess(self, vocab):\n",
    "\t\t# preprocess text\n",
    "\t\tself.text = [self._preprocess_sentence(text) for text in self.text]\n",
    "\n",
    "\t\tif vocab is None:\n",
    "\t\t\tself.vocab = build_vocab_from_iterator(self._yield_tokens(), specials=[\"<unk>\"])\n",
    "\t\t\tself.vocab.set_default_index(self.vocab['<unk>'])\n",
    "\t\t\tself.vocab.insert_token('<eos>', EOS_token)  # Insert <eos> token with index 1\n",
    "\t\telse:\n",
    "\t\t\tself.vocab = vocab\n",
    "\t\t\t\n",
    "\t\tself.vocab_size = len(self.vocab)\n",
    "\t\n",
    "\tdef _preprocess_sentence(self, sentence):\n",
    "\t\tsentence = normalizeString(sentence)\n",
    "\t\tsentence = self.tokenizer(sentence)\n",
    "\t\tsentence = lemmaString(sentence)\n",
    "\t\treturn sentence\n",
    "\n",
    "\tdef _yield_tokens(self):\n",
    "\t\tfor text_sample in self.text:\n",
    "\t\t\tyield text_sample\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.text)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tinput_seq = text_to_indices(self.vocab, self.text[idx])\n",
    "\t\tlabel = self.labels[idx]\n",
    "\t\treturn input_seq, label, self.ids[idx]\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "\treturn ''.join(\n",
    "\t\tc for c in unicodedata.normalize('NFD', s)\n",
    "\t\tif unicodedata.category(c) != 'Mn'\n",
    "\t)\n",
    "\n",
    "def normalizeString(s):\n",
    "\ts = unicodeToAscii(s.lower().strip())\n",
    "\ts = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "\ts = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "\treturn s\n",
    "\n",
    "def lemmaString(tokens):\n",
    "\treturn [token.lemma_ for token in lemmatizer(' '.join(tokens))]\n",
    "\n",
    "def text_to_indices(vocab, tokens):\n",
    "\tindices = [vocab[token] for token in tokens]\n",
    "\tindices.append(EOS_token)\n",
    "\treturn torch.tensor(indices, dtype=torch.long).view(-1)\n",
    "\n",
    "def seq_to_tokens(seq, vocab):\n",
    "    itos = vocab.get_itos()\n",
    "    return [itos[idx] for idx in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len df: 10\n"
     ]
    }
   ],
   "source": [
    "trainset = TranslationDataset('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['except', 'that', 'desmond', 'play', 'first', 'base', 'last', 'night', '.', 'tapia', 'be', 'in', 'lf', 'and', 'reynolds', 'have', 'a', 'night', 'off', '.', '<eos>']\n",
      "tensor([109,  18,  95, 157, 110,  78, 128,  44,   2, 189,   3,  17, 130,   7,\n",
      "        172,  16,  25,  44, 145,   2,   1]) 0\n",
      "<class 'torch.Tensor'> <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "src_sentence, label, id_ = trainset[0]\n",
    "print(seq_to_tokens(src_sentence, trainset.vocab))\n",
    "print(src_sentence, label)\n",
    "print(type(src_sentence), type(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_VALUE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate(list_of_samples):\n",
    "\t\"\"\"Merges a list of samples to form a mini-batch.\n",
    "\n",
    "\tArgs:\n",
    "\tlist_of_samples is a list of tuples (src_seq, tgt_label, id):\n",
    "\t\tsrc_seq is of shape (src_seq_length,)\n",
    "\t\ttgt_label is of shape (1,)\n",
    "\t\tid is an int\n",
    "\n",
    "\tReturns:\n",
    "\tsrc_seqs of shape (max_src_seq_length, batch_size): Tensor of padded source sequences.\n",
    "\t\tThe sequences should be sorted by length in a decreasing order, that is src_seqs[:,0] should be\n",
    "\t\tthe longest sequence, and src_seqs[:,-1] should be the shortest.\n",
    "\tsrc_seq_lengths: List of lengths of source sequences.\n",
    "\ttgt_labels of shape (batch_size, 1): Tensor of labels for each sequence.\n",
    "\t\"\"\"\n",
    "\t# YOUR CODE HERE\n",
    "\tsrc_seqs = [s[0] for s in list_of_samples]\n",
    "\ttgt_labels = torch.LongTensor([s[1] for s in list_of_samples])\n",
    "\tsrc_seq_lengths = [len(s) for s in src_seqs]\n",
    "\tids = [s[2] for s in list_of_samples]\n",
    "\tsrc_seqs = pad_sequence(src_seqs, padding_value=PADDING_VALUE)\n",
    "\n",
    "\tsrc_seq_lengths, indices = torch.sort(torch.tensor(src_seq_lengths), descending=True)\n",
    "\tsrc_seqs = src_seqs[:, indices]\n",
    "\ttgt_labels = tgt_labels[indices]\n",
    "\tids = [ids[i] for i in indices]\n",
    "\n",
    "\treturn src_seqs, src_seq_lengths.tolist(), tgt_labels, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_collate_shapes():\n",
    "    pairs = [\n",
    "        (torch.LongTensor([1, 2]), 1, 0),\n",
    "        (torch.LongTensor([6, 7, 8]), 0, 1),\n",
    "    ]\n",
    "    pad_src_seqs, src_seq_lengths, pad_tgt_seqs, ids = collate(pairs)\n",
    "    assert type(src_seq_lengths) == list, \"src_seq_lengths should be a list.\"\n",
    "    assert pad_src_seqs.shape == torch.Size([3, 2]), f\"Bad pad_src_seqs.shape: {pad_src_seqs.shape}\"\n",
    "    assert pad_src_seqs.dtype == torch.long\n",
    "    assert pad_tgt_seqs.shape == torch.Size([2]), f\"Bad pad_tgt_seqs.shape: {pad_tgt_seqs.shape}\"\n",
    "    assert pad_tgt_seqs.dtype == torch.long\n",
    "    print('Success')\n",
    "\n",
    "test_collate_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sequences combined:\n",
      "tensor([[11,  6,  1],\n",
      "        [12,  7,  2],\n",
      "        [13,  8,  0],\n",
      "        [14,  0,  0]])\n",
      "[4, 3, 2]\n",
      "Target sequences combined:\n",
      "tensor([0, 1, 0])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# This cell tests collate() function\n",
    "\n",
    "def test_collate_fn():\n",
    "    pairs = [\n",
    "        (torch.tensor([1, 2]), 0, 0),\n",
    "        (torch.tensor([6, 7, 8]), 1, 1),\n",
    "        (torch.tensor([11, 12, 13, 14]), 0, 2),\n",
    "    ]\n",
    "    pad_src_seqs, src_seq_lengths, pad_tgt_seqs, ids = collate(pairs)\n",
    "    assert pad_src_seqs.shape == torch.Size([4, 3]), f\"Bad pad_src_seqs.shape: {pad_src_seqs.shape}\"\n",
    "    assert pad_tgt_seqs.shape == torch.Size([3]), f\"Bad pad_tgt_seqs.shape: {pad_tgt_seqs.shape}\"\n",
    "    print('Source sequences combined:')\n",
    "    print(pad_src_seqs)\n",
    "    expected = torch.tensor([\n",
    "      [11, 6, 1],\n",
    "      [12, 7, 2],\n",
    "      [13, 8, 0],\n",
    "      [14, 0, 0],\n",
    "    ])\n",
    "    assert (pad_src_seqs == expected).all(), \"pad_src_seqs does not match expected values\"\n",
    "\n",
    "    print(src_seq_lengths)\n",
    "    if isinstance(src_seq_lengths[0], torch.Size):\n",
    "        src_seq_lengths = sum((list(l) for l in src_seq_lengths), [])\n",
    "    else:\n",
    "        src_seq_lengths = [int(l) for l in src_seq_lengths]\n",
    "    assert src_seq_lengths == [4, 3, 2], f\"Bad src_seq_lengths: {src_seq_lengths}\"\n",
    "\n",
    "    print('Target sequences combined:')\n",
    "    print(pad_tgt_seqs)\n",
    "    expected = torch.tensor([\n",
    "      0, 1, 0\n",
    "    ])\n",
    "    assert (pad_tgt_seqs == expected).all(), \"pad_tgt_seqs0 does not match expected values\"\n",
    "    print('Success')\n",
    "\n",
    "test_collate_fn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We create custom DataLoader using the implemented collate function\n",
    "# # We are going to process 64 sequences at the same time (batch_size=64)\n",
    "# trainset = TranslationDataset('train_2024.csv')\n",
    "# trainloader = DataLoader(dataset=trainset, batch_size=640, shuffle=False, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test data loader\n",
    "# for i, (src_seqs, src_seq_lengths, tgt_seqs, ids) in enumerate(trainloader):\n",
    "#     print(f\"Batch {i} src_seqs:\")\n",
    "#     print(src_seqs)\n",
    "#     print(f'src_seqs.shape: {src_seqs.shape}')\n",
    "#     print(f\"Batch {i} src_seq_lengths:\")\n",
    "#     print(src_seq_lengths)\n",
    "#     print(f\"Batch {i} tgt_seqs:\")\n",
    "#     print(tgt_seqs)\n",
    "#     print(f'tgt_seqs.shape: {tgt_seqs.shape}')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\tdef __init__(self, src_dictionary_size, embed_size, hidden_size, dropout=0.2, glove_embeddings=None):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\tsrc_dictionary_size: The number of words in the source dictionary.\n",
    "\t\tembed_size: The number of dimensions in the word embeddings.\n",
    "\t\thidden_size: The number of features in the hidden state of GRU.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(LSTM, self).__init__()\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.embedding = nn.Embedding(src_dictionary_size, embed_size)\n",
    "\t\tif glove_embeddings is not None:\n",
    "\t\t\tself.load_glove_embeddings(glove_embeddings, embed_size)\n",
    "\t\n",
    "\t\tself.lstm = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=1, batch_first=False, dropout=dropout, bidirectional=False)\n",
    "\t\tself.fc1 = nn.Linear(hidden_size, 128)\n",
    "\t\tself.fc2 = nn.Linear(128, 1)\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\n",
    "\tdef load_glove_embeddings(self, glove_embeddings, embed_size):\n",
    "\t\t\"\"\"Initialize the embedding layer with GloVe embeddings.\"\"\"\n",
    "\t\tweights_matrix = torch.zeros((self.embedding.num_embeddings, embed_size))\n",
    "\n",
    "\t\tfor i, word in enumerate(glove_embeddings):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tweights_matrix[i] = torch.FloatTensor(glove_embeddings[word])\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(e)\n",
    "\t\t\t\tprint(torch.FloatTensor(glove_embeddings[word]).size())\n",
    "\t\t\t\tprint(f'word: {word}, i: {i}')\n",
    "\n",
    "\t\tself.embedding.load_state_dict({'weight': weights_matrix})\n",
    "\n",
    "\tdef forward(self, pad_seqs, seq_lengths, hidden):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\tpad_seqs of shape (max_seq_length, batch_size): Padded source sequences.\n",
    "\t\tseq_lengths: List of sequence lengths.\n",
    "\t\thidden of shape (1, batch_size, hidden_size): Initial states of the GRU.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\toutputs of shape (max_seq_length, batch_size, hidden_size): Padded outputs of GRU at every step.\n",
    "\t\thidden of shape (1, batch_size, hidden_size): Updated states of the GRU.\n",
    "\t\t\"\"\"\n",
    "\t\t# YOUR CODE HERE\n",
    "\t\tembedded = self.embedding(pad_seqs) # shape: (max_seq_length, batch_size, embed_size)\n",
    "\t\tpacked = pack_padded_sequence(embedded, seq_lengths)\n",
    "\t\toutputs, hidden = self.lstm(packed, hidden) \n",
    "\t\toutputs, output_lengths = pad_packed_sequence(outputs, batch_first=False) # shape: (max_seq_length, batch_size, hidden_size)\n",
    "\t\tlast_timesteps = torch.stack([outputs[length-1, i] for i, length in enumerate(output_lengths)]) # shape: (batch_size, hidden_size)\n",
    "\t\t# feed through the fully connected layer\n",
    "\t\toutputs = self.fc1(last_timesteps)\n",
    "\t\toutputs = self.dropout(outputs)\n",
    "\t\toutputs = self.relu(outputs)\n",
    "\t\toutputs = self.fc2(outputs)\n",
    "\t\toutputs = self.sigmoid(outputs)\n",
    "\t\treturn outputs\n",
    "\n",
    "\tdef init_hidden(self, batch_size=1, device='cpu'):\n",
    "\t\tnum_directions = 1\n",
    "\t\treturn (\n",
    "\t\t\ttorch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "\t\t\ttorch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_CNN(nn.Module):\n",
    "    def __init__(self, src_dictionary_size, embed_size, hidden_size, num_filters=100, kernel_sizes= [3, 4, 5], dropout=0.2, glove_embeddings=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        src_dictionary_size: The number of words in the source dictionary.\n",
    "        embed_size: The number of dimensions in the word embeddings.\n",
    "        hidden_size: The number of features in the hidden state of GRU.\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(src_dictionary_size, embed_size)\n",
    "        if glove_embeddings is not None:\n",
    "            self.load_glove_embeddings(glove_embeddings, embed_size)\n",
    "\n",
    "        # CNN layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embed_size, out_channels=num_filters, kernel_size=k, stride=1, padding=k // 2)\n",
    "            for k in kernel_sizes\n",
    "        ])\n",
    "        self.conv_output_size = num_filters * len(kernel_sizes)\n",
    "    \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=1, batch_first=False, dropout=dropout, bidirectional=False)\n",
    "        \n",
    "        # FC layers\n",
    "        self.fc1 = nn.Linear(hidden_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def load_glove_embeddings(self, glove_embeddings, embed_size):\n",
    "        \"\"\"Initialize the embedding layer with GloVe embeddings.\"\"\"\n",
    "        weights_matrix = torch.zeros((self.embedding.num_embeddings, embed_size))\n",
    "\n",
    "        for i, word in enumerate(glove_embeddings):\n",
    "            try:\n",
    "                weights_matrix[i] = torch.FloatTensor(glove_embeddings[word])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(torch.FloatTensor(glove_embeddings[word]).size())\n",
    "                print(f'word: {word}, i: {i}')\n",
    "\n",
    "        self.embedding.load_state_dict({'weight': weights_matrix})\n",
    "\n",
    "    def forward(self, pad_seqs, seq_lengths, hidden):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        pad_seqs of shape (max_seq_length, batch_size): Padded source sequences.\n",
    "        seq_lengths: List of sequence lengths.\n",
    "        hidden of shape (1, batch_size, hidden_size): Initial states of the GRU.\n",
    "\n",
    "        Returns:\n",
    "        outputs of shape (max_seq_length, batch_size, hidden_size): Padded outputs of GRU at every step.\n",
    "        hidden of shape (1, batch_size, hidden_size): Updated states of the GRU.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        embedded = self.embedding(pad_seqs) # shape: (max_seq_length, batch_size, embed_size)\n",
    "        \n",
    "        # reshape before feeding through the CNN layers\n",
    "        embedded = embedded.permute(1, 2, 0)  # shape: (batch_size, embed_size, max_seq_length)\n",
    "\n",
    "        # Apply CNN and ReLU activation\n",
    "        cnn_out = [torch.relu(conv(embedded)) for conv in self.convs]\n",
    "        cnn_out = torch.cat(cnn_out, 1)  # concatenate along the channel dimension shape: (batch_size, num_filters * len(kernel_sizes), max_seq_length)\n",
    "        cnn_out = cnn_out.permute(2, 0, 1)  # shape: (max_seq_length, batch_size, conv_output_size)\n",
    "        embedded = cnn_out\n",
    "\n",
    "        # feed through the LSTM layer\n",
    "        packed = pack_padded_sequence(embedded, seq_lengths)\n",
    "        outputs, hidden = self.lstm(packed, hidden) \n",
    "        outputs, output_lengths = pad_packed_sequence(outputs, batch_first=False) # shape: (max_seq_length, batch_size, hidden_size)\n",
    "        last_timesteps = torch.stack([outputs[length-1, i] for i, length in enumerate(output_lengths)]) # shape: (batch_size, hidden_size)\n",
    "        # feed through the fully connected layer\n",
    "        outputs = self.fc1(last_timesteps)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.relu(outputs)\n",
    "        outputs = self.fc2(outputs)\n",
    "        outputs = self.sigmoid(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size=1, device='cpu'):\n",
    "        num_directions = 1\n",
    "        return (\n",
    "            torch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "            torch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "def test_LSTM_shapes():\n",
    "    hidden_size = 3\n",
    "    lstm = LSTM(src_dictionary_size=5, embed_size=10, hidden_size=hidden_size)\n",
    "\n",
    "    max_seq_length = 4\n",
    "    batch_size = 2\n",
    "    hidden = lstm.init_hidden(batch_size=batch_size)\n",
    "    pad_seqs = torch.tensor([\n",
    "        [        1,             2],\n",
    "        [        2,     EOS_token],\n",
    "        [        3, PADDING_VALUE],\n",
    "        [EOS_token, PADDING_VALUE]\n",
    "    ])\n",
    "\n",
    "    outputs = lstm.forward(pad_seqs=pad_seqs, seq_lengths=[4, 2], hidden=hidden)\n",
    "    assert outputs.shape == torch.Size([batch_size, 1]), f\"Bad outputs.shape: {outputs.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_LSTM_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, val_loader):\n",
    "\tmodel.eval()\n",
    "\ttotal_loss = 0\n",
    "\tcriterion = nn.BCELoss()\n",
    "\twith torch.no_grad():\n",
    "\t\tfor i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(val_loader):\n",
    "\t\t\tsrc_seqs, tgt_labels = src_seqs.to(device), tgt_labels.to(device)\n",
    "\t\t\thidden = model.init_hidden(src_seqs.shape[1], device=device)\n",
    "\t\t\toutputs = model(src_seqs, src_seq_lengths, hidden)\n",
    "\t\t\tloss = criterion(outputs.squeeze(), tgt_labels.float())\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\treturn total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99000\n"
     ]
    }
   ],
   "source": [
    "# We create custom DataLoader using the implemented collate function\n",
    "# We are going to process 640 sequences at the same time (batch_size=640)\n",
    "# load vocab\n",
    "# vocab = torch.load('vocab.pth')\n",
    "# vocab = None\n",
    "# trainset = TranslationDataset('train_2024.csv', vocab=vocab)\n",
    "trainset = torch.load('dataloaders/trainset.pth')\n",
    "print(len(trainset.text))\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=640, shuffle=False, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    }
   ],
   "source": [
    "# We create custom DataLoader using the implemented collate function\n",
    "# We are going to process 64 sequences at the same time (batch_size=64)\n",
    "# valset = TranslationDataset('dev_2024.csv', vocab=trainset.vocab)\n",
    "valset = torch.load('dataloaders/valset.pth')\n",
    "print(len(valset.text))\n",
    "valloader = DataLoader(dataset=valset, batch_size=256, shuffle=False, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trainset\n",
    "# torch.save(trainset, 'trainset.pth')\n",
    "\n",
    "# save valset\n",
    "# torch.save(valset, 'valset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance, patience):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          patience (int):    Maximum number of epochs with unsuccessful updates.\n",
    "          tolerance (float): We assume that the update is unsuccessful if the validation error is larger\n",
    "                              than the best validation error so far plus this tolerance.\n",
    "        \"\"\"\n",
    "        self.tolerance = tolerance\n",
    "        self.patience = patience\n",
    "    \n",
    "    def stop_criterion(self, val_errors):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          val_errors (iterable): Validation errors after every update during training.\n",
    "        \n",
    "        Returns: True if training should be stopped: when the validation error is larger than the best\n",
    "                  validation error obtained so far (with given tolearance) for patience epochs (number of consecutive epochs for which the criterion is satisfied).\n",
    "                 \n",
    "                 Otherwise, False.\n",
    "        \"\"\"\n",
    "        if len(val_errors) <= self.patience:\n",
    "            return False\n",
    "\n",
    "        min_val_error = min(val_errors)\n",
    "        val_errors = np.array(val_errors[-self.patience:])\n",
    "        return all(val_errors > min_val_error + self.tolerance)\n",
    "\n",
    "early_stop = EarlyStopping(tolerance=0.001, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# Create the LSTM model\n",
    "hidden_size = embed_size = 256\n",
    "lstm = LSTM(trainset.vocab_size, embed_size, hidden_size).to(device)\n",
    "\n",
    "# Load pretrained LSTM\n",
    "# lstm.load_state_dict(torch.load('lstm_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue training\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 1, iter 10: avg. loss = 0.2052, Time spent: 4.75s\n",
      "Epoch 1, iter 20: avg. loss = 0.2008, Time spent: 5.09s\n",
      "Epoch 1, iter 30: avg. loss = 0.1968, Time spent: 8.31s\n",
      "Epoch 1, iter 40: avg. loss = 0.1959, Time spent: 5.94s\n",
      "Epoch 1, iter 50: avg. loss = 0.1912, Time spent: 5.70s\n",
      "Epoch 1, iter 60: avg. loss = 0.1879, Time spent: 5.42s\n",
      "Epoch 1, iter 70: avg. loss = 0.1865, Time spent: 5.26s\n",
      "Epoch 1, iter 80: avg. loss = 0.1839, Time spent: 5.56s\n",
      "Epoch 1, iter 90: avg. loss = 0.1822, Time spent: 10.76s\n",
      "Epoch 1, iter 100: avg. loss = 0.1820, Time spent: 5.45s\n",
      "Epoch 1, iter 110: avg. loss = 0.1828, Time spent: 5.78s\n",
      "Epoch 1, iter 120: avg. loss = 0.1833, Time spent: 5.45s\n",
      "Epoch 1, iter 130: avg. loss = 0.1823, Time spent: 6.67s\n",
      "Epoch 1, iter 140: avg. loss = 0.1820, Time spent: 4.60s\n",
      "Epoch 1, iter 150: avg. loss = 0.1830, Time spent: 4.72s\n",
      "find new best model, save to lstm.pth, eval_loss: 0.2162\n",
      "Epoch 1, val loss = 0.2162, train loss = 0.1829; Time spent: 891.66s\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 2, iter 10: avg. loss = 0.1783, Time spent: 5.31s\n",
      "Epoch 2, iter 20: avg. loss = 0.1817, Time spent: 4.65s\n",
      "Epoch 2, iter 30: avg. loss = 0.1790, Time spent: 8.16s\n",
      "Epoch 2, iter 40: avg. loss = 0.1756, Time spent: 5.39s\n",
      "Epoch 2, iter 50: avg. loss = 0.1711, Time spent: 4.87s\n",
      "Epoch 2, iter 60: avg. loss = 0.1681, Time spent: 5.34s\n",
      "Epoch 2, iter 70: avg. loss = 0.1674, Time spent: 5.24s\n",
      "Epoch 2, iter 80: avg. loss = 0.1660, Time spent: 5.68s\n",
      "Epoch 2, iter 90: avg. loss = 0.1644, Time spent: 10.02s\n",
      "Epoch 2, iter 100: avg. loss = 0.1642, Time spent: 5.02s\n",
      "Epoch 2, iter 110: avg. loss = 0.1651, Time spent: 6.07s\n",
      "Epoch 2, iter 120: avg. loss = 0.1664, Time spent: 5.07s\n",
      "Epoch 2, iter 130: avg. loss = 0.1660, Time spent: 5.74s\n",
      "Epoch 2, iter 140: avg. loss = 0.1655, Time spent: 4.67s\n",
      "Epoch 2, iter 150: avg. loss = 0.1654, Time spent: 5.71s\n",
      "find new best model, save to lstm.pth, eval_loss: 0.2002\n",
      "Epoch 2, val loss = 0.2002, train loss = 0.1652; Time spent: 881.16s\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 3, iter 10: avg. loss = 0.1646, Time spent: 4.70s\n",
      "Epoch 3, iter 20: avg. loss = 0.1663, Time spent: 5.74s\n",
      "Epoch 3, iter 30: avg. loss = 0.1643, Time spent: 8.70s\n",
      "Epoch 3, iter 40: avg. loss = 0.1616, Time spent: 6.00s\n",
      "Epoch 3, iter 50: avg. loss = 0.1574, Time spent: 5.02s\n",
      "Epoch 3, iter 60: avg. loss = 0.1543, Time spent: 5.72s\n",
      "Epoch 3, iter 70: avg. loss = 0.1527, Time spent: 4.79s\n",
      "Epoch 3, iter 80: avg. loss = 0.1511, Time spent: 5.48s\n",
      "Epoch 3, iter 90: avg. loss = 0.1497, Time spent: 8.52s\n",
      "Epoch 3, iter 100: avg. loss = 0.1496, Time spent: 4.83s\n",
      "Epoch 3, iter 110: avg. loss = 0.1501, Time spent: 4.88s\n",
      "Epoch 3, iter 120: avg. loss = 0.1517, Time spent: 4.72s\n",
      "Epoch 3, iter 130: avg. loss = 0.1548, Time spent: 5.41s\n",
      "Epoch 3, iter 140: avg. loss = 0.1566, Time spent: 4.68s\n",
      "Epoch 3, iter 150: avg. loss = 0.1587, Time spent: 4.87s\n",
      "Epoch 3, val loss = 0.2138, train loss = 0.1594; Time spent: 829.56s\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 4, iter 10: avg. loss = 0.1786, Time spent: 4.73s\n",
      "Epoch 4, iter 20: avg. loss = 0.1773, Time spent: 5.00s\n",
      "Epoch 4, iter 30: avg. loss = 0.1742, Time spent: 7.09s\n",
      "Epoch 4, iter 40: avg. loss = 0.1702, Time spent: 4.48s\n",
      "Epoch 4, iter 50: avg. loss = 0.1651, Time spent: 5.37s\n",
      "Epoch 4, iter 60: avg. loss = 0.1605, Time spent: 4.32s\n",
      "Epoch 4, iter 70: avg. loss = 0.1582, Time spent: 4.10s\n",
      "Epoch 4, iter 80: avg. loss = 0.1554, Time spent: 4.08s\n",
      "Epoch 4, iter 90: avg. loss = 0.1537, Time spent: 7.58s\n",
      "Epoch 4, iter 100: avg. loss = 0.1529, Time spent: 4.31s\n",
      "Epoch 4, iter 110: avg. loss = 0.1562, Time spent: 4.86s\n",
      "Epoch 4, iter 120: avg. loss = 0.1587, Time spent: 6.38s\n",
      "Epoch 4, iter 130: avg. loss = 0.1596, Time spent: 6.91s\n",
      "Epoch 4, iter 140: avg. loss = 0.1596, Time spent: 5.87s\n",
      "Epoch 4, iter 150: avg. loss = 0.1598, Time spent: 4.71s\n",
      "find new best model, save to lstm.pth, eval_loss: 0.1979\n",
      "Epoch 4, val loss = 0.1979, train loss = 0.1591; Time spent: 774.32s\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 5, iter 10: avg. loss = 0.1544, Time spent: 4.45s\n",
      "Epoch 5, iter 20: avg. loss = 0.1527, Time spent: 4.49s\n",
      "Epoch 5, iter 30: avg. loss = 0.1498, Time spent: 6.69s\n",
      "Epoch 5, iter 40: avg. loss = 0.1463, Time spent: 4.62s\n",
      "Epoch 5, iter 50: avg. loss = 0.1434, Time spent: 4.44s\n",
      "Epoch 5, iter 60: avg. loss = 0.1407, Time spent: 5.10s\n",
      "Epoch 5, iter 70: avg. loss = 0.1391, Time spent: 4.87s\n",
      "Epoch 5, iter 80: avg. loss = 0.1368, Time spent: 4.51s\n",
      "Epoch 5, iter 90: avg. loss = 0.1354, Time spent: 8.38s\n",
      "Epoch 5, iter 100: avg. loss = 0.1351, Time spent: 5.34s\n",
      "Epoch 5, iter 110: avg. loss = 0.1353, Time spent: 5.28s\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 20\n",
    "# prompt ask for continue training or not\n",
    "cont = input('Continue training? yes or no')\n",
    "if cont == 'no':\n",
    "\tprint('Fresh training')\n",
    "\ttrain_losses = []\n",
    "\tval_losses = []\n",
    "\tbest_model = None\n",
    "\tbest_val_loss = float('inf')\n",
    "else:\n",
    "\tprint(f'Continue training')\n",
    "\t\n",
    "for epoch in range(n_epochs):\n",
    "\tlstm.train()\n",
    "\trunning_loss = 0.0\n",
    "\tepoch_start_time = time.time()\n",
    "\tprint(f'Number of batches: {len(trainloader)}')\n",
    "\tprint(f'batch_size: {trainloader.batch_size}')\n",
    "\tfor i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(trainloader):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tsrc_seqs, tgt_labels = src_seqs.to(device), tgt_labels.to(device)\n",
    "\t\thidden = lstm.init_hidden(src_seqs.shape[1], device=device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = lstm(src_seqs, src_seq_lengths, hidden)\n",
    "\t\tloss = criterion(outputs.squeeze(), tgt_labels.float())\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\tif i % 10 == 9:\n",
    "\t\t\tprint(f'Epoch {epoch + 1}, iter {i + 1}: avg. loss = {running_loss/(i + 1):.4f}, Time spent: {time.time()-start_time:.2f}s')\n",
    "\ttrain_losses.append(running_loss / len(trainloader))\n",
    "\teval_loss = val_loss(lstm, valloader)\n",
    "\tif eval_loss < best_val_loss:\n",
    "\t\tbest_val_loss = eval_loss\n",
    "\t\tbest_model = lstm.state_dict()\n",
    "\t\tif best_model is not None:\n",
    "\t\t\tprint(f'find new best model, save to lstm.pth, eval_loss: {eval_loss:.4f}')\n",
    "\t\t\ttorch.save(best_model, 'models/lstm.pth')\n",
    "\n",
    "\tif early_stop.stop_criterion(val_losses):\n",
    "\t\tprint(f'Early stopping on epoch {epoch + 1}')\n",
    "\t\tbreak\n",
    "\t\n",
    "\tval_losses.append(eval_loss)\n",
    "\tprint(f'Epoch {epoch + 1}, val loss = {eval_loss:.4f}, train loss = {train_losses[-1]:.4f}; Time spent: {time.time()-epoch_start_time:.2f}s')\n",
    "\trunning_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and vocab\n",
    "torch.save(lstm.state_dict(), 'lstm.pth')\n",
    "torch.save(trainset.vocab, 'vocab.pth')\n",
    "\n",
    "# # Load model\n",
    "# lstm = LSTM(trainset.vocab_size, embed_size, hidden_size).to(device)\n",
    "# lstm.load_state_dict(torch.load('lstm.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have a function to load GloVe embeddings\n",
    "def load_glove_embeddings(filepath):\n",
    "    glove_embeddings = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            glove_embeddings[word] = vector\n",
    "    return glove_embeddings\n",
    "\n",
    "# Load GloVe embeddings from a file\n",
    "glove_embeddings = load_glove_embeddings('glove_embeddings/glove.twitter.27B.100d.txt')\n",
    "\n",
    "# Create a dictionary with your src_dictionary and GloVe embeddings\n",
    "src_dictionary = trainset.vocab  # Add your vocabulary here\n",
    "src_dictionary_size = len(src_dictionary)\n",
    "embed_size = 100  # Example embedding size\n",
    "\n",
    "# Map GloVe vectors to your src_dictionary index\n",
    "mapped_glove_embeddings = {}\n",
    "for word, index in src_dictionary.get_stoi().items():\n",
    "    if word in glove_embeddings:\n",
    "        mapped_glove_embeddings[index] = glove_embeddings[word]\n",
    "    else:\n",
    "        # If word is not in GloVe, initialize a random vector\n",
    "        mapped_glove_embeddings[index] = np.random.normal(scale=0.6, size=(embed_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save mapped_glove_embeddings\n",
      "load mapped_glove_embeddings\n"
     ]
    }
   ],
   "source": [
    "# save and load mapped_glove_embeddings\n",
    "# print('save mapped_glove_embeddings')\n",
    "# torch.save(mapped_glove_embeddings, 'models/mapped_glove_embeddings.pth')\n",
    "print('load mapped_glove_embeddings')\n",
    "mapped_glove_embeddings = torch.load('models/mapped_glove_embeddings.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "embed_size = 100\n",
    "lstm_glove = LSTM(trainset.vocab_size, embed_size, hidden_size, dropout=0.2, glove_embeddings=mapped_glove_embeddings).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[0;32m----> 3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mlstm_glove\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m      5\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# prompt ask for continue training or not\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm_glove' is not defined"
     ]
    }
   ],
   "source": [
    "# training\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(lstm_glove.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "n_epochs = 40\n",
    "# prompt ask for continue training or not\n",
    "cont = input('Continue training? yes or no')\n",
    "if cont == 'no':\n",
    "\tprint('Fresh training')\n",
    "\ttrain_losses = []\n",
    "\tval_losses = []\n",
    "\tbest_model = None\n",
    "\tbest_val_loss = float('inf')\n",
    "else:\n",
    "\tprint(f'Continue training')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\tlstm_glove.train()\n",
    "\trunning_loss = 0.0\n",
    "\tepoch_start_time = time.time()\n",
    "\tprint(f'Number of batches: {len(trainloader)}')\n",
    "\tprint(f'batch_size: {trainloader.batch_size}')\n",
    "\tfor i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(trainloader):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tsrc_seqs, tgt_labels = src_seqs.to(device), tgt_labels.to(device)\n",
    "\t\thidden = lstm_glove.init_hidden(src_seqs.shape[1], device=device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = lstm_glove(src_seqs, src_seq_lengths, hidden)\n",
    "\t\tloss = criterion(outputs.squeeze(), tgt_labels.float())\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\tif i % 10 == 9:\n",
    "\t\t\tprint(f'Epoch {epoch + 1}, iter {i + 1}: avg. loss = {running_loss/(i + 1):.4f}, Time spent: {time.time()-start_time:.2f}s')\n",
    "\ttrain_losses.append(running_loss / len(trainloader))\n",
    "\teval_loss = val_loss(lstm_glove, valloader)\n",
    "\n",
    "\tif eval_loss < best_val_loss:\n",
    "\t\tbest_val_loss = eval_loss\n",
    "\t\tbest_model = lstm_glove.state_dict()\n",
    "\t\tif best_model is not None:\n",
    "\t\t\tprint(f'find new best model, save to models/lstm_glove.pth, eval_loss: {eval_loss:.4f}')\n",
    "\t\t\ttorch.save(best_model, os.path.join('models', 'lstm_glove.pth'))\n",
    "\n",
    "\t# if early_stop.stop_criterion(val_losses):\n",
    "\t# \tprint(f'Early stopping at epoch {epoch + 1}')\n",
    "\t# \tbreak\n",
    "\t\n",
    "\tval_losses.append(eval_loss)\n",
    "\tprint(f'Epoch {epoch + 1}, val loss = {eval_loss:.4f}, train loss = {train_losses[-1]:.4f}; Time spent: {time.time()-epoch_start_time:.2f}s')\n",
    "\trunning_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose model to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vanilla LSTM\n",
    "# hidden_size = embed_size = 256\n",
    "# lstm = LSTM(trainset.vocab_size, embed_size, hidden_size).to(device)\n",
    "# lstm.load_state_dict(torch.load('lstm.pth'))\n",
    "\n",
    "# LSTM with GloVe embeddings\n",
    "hidden_size = 256\n",
    "embed_size = 100\n",
    "lstm_glove = LSTM(trainset.vocab_size, embed_size, hidden_size, dropout=0.2, glove_embeddings=None).to(device)\n",
    "lstm_glove.load_state_dict(torch.load('models/lstm_glove.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(lstm, pad_src_seqs, src_seq_lengths):\n",
    "    \"\"\"Translate sequences from the source language to the target language using the trained model.\n",
    "\n",
    "    Args:\n",
    "    lstm (LSTM): Trained lstm.\n",
    "    pad_src_seqs of shape (max_src_seq_length, batch_size): Padded source sequences.\n",
    "    src_seq_lengths: List of source sequence lengths.\n",
    "\n",
    "    Returns:\n",
    "    out_seqs of shape (batch_size, 1): LongTensor of word indices of the output sequences.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    with torch.no_grad():\n",
    "        pad_src_seqs = pad_src_seqs.to(device)\n",
    "        lstm_hidden = lstm.init_hidden(pad_src_seqs.shape[1], device)\n",
    "        outputs = lstm(pad_src_seqs, src_seq_lengths, lstm_hidden)\n",
    "        out_seqs = outputs > 0.5\n",
    "        return out_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_translate_shapes(lstm):\n",
    "    pad_src_seqs = torch.tensor([\n",
    "        [1, 2],\n",
    "        [2, 3],\n",
    "        [3, 0],\n",
    "        [4, 0]\n",
    "    ])\n",
    "\n",
    "    out_seqs = classify(lstm, pad_src_seqs, src_seq_lengths=[4, 2])\n",
    "    assert out_seqs.shape == torch.Size([2, 1]), f\"Wrong out_seqs.shape: {out_seqs.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_translate_shapes(lstm_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify training data:\n",
      "-----------------------------\n",
      "SRC: ['the', 'benign', 'effect', 'of', 'the', 'financial', 'crisis', 'in', 'canada', 'that', 'reduce', 'consumer', 'borrowing', 'in', 'the', 'us', 'increase', 'it', 'here', '.', 'low', 'rate', 'but', 'a', 'healthy', 'gap', 'between', 'funding', 'level', 'for', 'bank', 'and', 'prime', 'rate', 'mean', 'huge', 'profit', 'form', 'retail', '.', 'the', 'bank', 'push', 'we', 'all', 'to', 'borrow', 'with', 'slogan', 'like', 'you', 'be', 'wealthy', 'than', 'you', 'think', '.', 'I', 'once', 'hear', 'a', 'bank', 'treasurer', 'imply', 'these', 'spread', 'represent', 'over', 'of', 'their', 'profit', 'the', 'prior', 'year', '.', 'and', 'so', 'it', 'be', 'ironic', 'that', 'the', 'bank', 'be', 'now', 'among', 'those', 'heed', 'the', 'debt', 'level', 'warning', '.', 'there', 'can', 'be', 'no', 'explanation', 'other', 'than', 'that', 'they', 'can', 'not', 'wean', 'themselves', 'off', 'it', 'and', 'need', 'osfi', 'to', 'help', '.', 'it', 'be', 'game', 'theory', 'run', 'amok', 'when', 'an', 'oligopoly', 'need', 'someone', 'outside', 'the', 'game', 'to', 'impel', 'they', 'to', 'change', 'the', 'way', 'they', 'play', '.', 'with', 'house', 'price', 'up', 'as', 'much', 'as', 'they', 'be', 'over', 'the', 'year', 'even', 'those', 'that', 'in', 'a', 'basis', 'point', 'rise', 'may', 'have', 'a', 'little', 'wiggle', 'room', '.', 'I', 'note', 'that', 'no', 'one', 'be', 'estimate', 'the', 'price', 'sensitivity', 'of', 'the', 'real', 'estate', 'market', 'to', 'the', 'move', '.', 'that', 'would', 'be', 'a', 'good', 'piece', 'of', 'work', '.', '<eos>']\n",
      "TGT: 0\n",
      "OUT: False\n",
      "\n",
      "SRC: ['thank', 'you', '<unk>', 'for', 'your', 'wise', 'word', '.', 'you', 'be', 'just', 'a', 'little', 'young', 'than', 'my', 'parent', 'bear', 'in', 'and', '.', 'yes', 'I', 'agree', 'with', 'your', 'statement', 'if', 'die', 'be', 'just', 'a', 'part', 'of', 'the', 'process', 'of', 'life', 'and', 'that', 'be', 'the', 'way', 'god', 'arrange', 'it', 'it', 'must', 'somehow', 'be', 'a', 'good', 'thing', '.', 'but', 'another', 'aspect', 'of', 'death', 'be', 'how', 'it', 'affect', 'our', 'relationship', 'with', 'other', 'living', 'creature', '.', 'we', 'be', 'so', 'easily', 'make', 'to', 'overlook', 'our', 'complicity', 'in', 'the', 'death', 'of', 'other', 'who', 'have', 'as', 'much', 'right', 'to', 'live', 'as', 'we', 'do', 'it', 'be', 'the', 'way', 'of', 'wisdom', 'to', 'pay', 'attention', 'to', 'the', 'life', 'of', 'these', 'countless', 'cousin', 'of', 'ours', 'and', 'never', 'do', 'anything', 'to', 'make', 'their', 'death', 'more', 'painful', 'than', 'they', 'be', '.', 'so', 'on', 'the', 'matter', 'of', 'assisted', 'suicide', 'I', 'be', 'confident', 'that', 'sick', 'people', 'with', 'no', 'hope', 'of', 'live', 'much', 'long', 'do', 'a', 'good', 'thing', 'to', 'spare', 'themselves', 'more', 'pain', 'and', 'their', 'love', 'one', 'inconvenience', '.', 'and', 'those', 'who', 'assist', 'they', 'also', 'do', 'a', 'good', 'thing', 'by', 'be', 'their', 'minister', '.', 'it', 's', 'much', 'well', 'than', 'the', 'unreal', 'inhumane', 'demand', 'of', 'modern', 'medical', 'life', 'save', 'practice', '.', '<eos>', '<unk>']\n",
      "TGT: 0\n",
      "OUT: False\n",
      "\n",
      "SRC: ['to', 'all', 'you', 'idiotic', 'naysayer', 'ok', 'let', 's', 'play', '.', '.', '.', 'say', 'climate', 'change', 'isn', 't', 'be', 'cause', 'by', 'stupid', 'human', 'activity', '<unk>', 'do', 'it', 'not', 'behoove', 'we', 'to', 'do', 'everything', 'we', 'can', 'to', 'mitigate', 'any', 'possibility', 'that', 'it', 'might', 'people', '?', 'I', 'm', 'not', 'say', 'we', 'can', 'fix', 'it', 'overnight', 'but', 'we', 're', 'one', 'of', 'the', 'early', 'generation', 'of', 'a', 'huge', 'industrial', 'revolution', 'and', 'can', 'set', 'the', 'tone', 'for', 'environmental', 'stewardship', 'for', 'future', 'one', '.', 'or', 'be', 'all', 'you', 'lazy', 'minded', 'moron', 'content', 'that', 'we', 'can', 'just', 'happily', 'continue', 'to', 'pollute', 'the', 'atmosphere', 'greedily', 'mine', 'and', 'drill', 'massively', 'over', 'fish', 'the', 'ocean', 'and', 'dump', 'million', 'of', 'metric', 'ton', 'of', 'trash', 'into', 'it', 'and', 'landfill', 'on', 'a', 'daily', 'basis', '?', 'we', 're', 'already', 'tragically', 'late', '!', 'ever', 'hear', 'the', 'saying', 'leave', 'a', 'place', 'in', 'well', 'condition', 'than', 'the', 'way', 'you', 'find', 'it', '.', 'you', 're', 'the', 'type', 'that', 'go', 'to', 'house', 'party', 'and', 'don', 't', 'stick', 'around', 'to', 'help', 'clean', 'up', 'your', 'mess', '.', 'your', 'unbelievably', 'stupid', 'selfish', 'and', 'dismissive', 'attitude', 'towards', 'the', 'environment', 'and', 'even', 'your', 'own', 'family', 's', 'future', 'be', 'just', 'beyond', 'stunning', '.', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "TGT: 1\n",
      "OUT: True\n",
      "\n",
      "SRC: ['oh', 'bullshit', '.', 'go', 'look', 'at', 'the', 'most', 'gender', 'equal', 'country', 'on', 'earth', 'that', 'would', 'be', 'iceland', 'and', 'you', 'll', 'find', 'that', 'the', '<unk>', 'have', 'not', 'be', 'replace', 'by', 'the', 'state', 'it', 'have', 'not', 'be', 'replace', 'by', 'anything', '.', 'people', 'just', 'fail', 'to', 'expect', 'anything', 'from', 'each', 'other', 'base', 'on', 'gender', 'and', 'double', 'standard', 'don', 't', 'exist', '.', 'and', 'contrary', 'to', 'stupid', 'claim', 'elsewhere', 'in', 'the', 'comment', 'guess', 'what', 'else', 'have', 'cease', 'to', 'exist', 'any', 'kind', 'of', '<unk>', '.', 'the', 'big', 'downside', 'iceland', 'have', 'face', 'be', 'that', 'not', 'have', 'any', 'double', 'standard', 'or', 'judgement', 'of', 'people', 's', 'behaviour', 'their', 'enjoyment', 'of', 'daily', 'casual', 'sex', 'have', 'give', 'they', 'a', 'rather', 'high', 'than', 'average', 'rate', 'of', '<unk>', 'know', 'locally', 'as', 'the', '<unk>', 'handshake', 'one', 'of', 'the', 'few', 'stds', 'you', 'can', 'fairly', 'easily', 'catch', 'even', 'when', 'use', 'condom', '.', 'but', 'then', 'it', 'be', 'also', 'one', 'of', 'the', 'easy', 'to', 'cure', 'and', 'with', 'an', 'excellent', 'free', 'for', 'all', 'healthcare', 'system', 'it', 's', 'really', 'not', 'a', 'major', 'problem', '.', 'if', 'that', 's', 'the', 'big', 'price', 'for', 'a', 'society', 'where', 'rape', 'be', 'basically', 'non', 'existent', 'I', 'would', 'pay', 'it', 'with', 'glee', '.', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "TGT: 1\n",
      "OUT: True\n",
      "\n",
      "SRC: ['these', 'poor', 'people', 'a', 'pawn', 'in', 'a', 'cruel', 'political', 'game', '.', 'obama', 'open', 'the', 'door', 'invite', 'their', 'parent', 'in', 'by', 'promise', 'to', 'make', 'their', 'lawbreaking', 'legal', 'and', 'later', 'reward', 'their', 'child', 'by', 'make', 'dream', 'act', 'previously', 'reject', 'by', 'congress', 'into', 'executive', 'order', 'daca', '.', 'he', 'dem', 'have', 'nothing', 'to', 'lose', 'in', 'this', 'cruel', 'game', 'that', 'have', 'nothing', 'to', 'do', 'with', 'compassion', 'and', 'here', 's', 'why', '.', 'if', 'hillary', 'would', 've', 'be', 'elect', 'she', 'would', 'continue', 'it', 'and', 'keep', 'flood', 'the', 'country', 'with', 'democratic', 'voter', '.', 'if', 'a', 'republican', 'win', 'as', 'he', 'do', 'he', 'would', 'have', 'a', 'mess', 'on', 'his', 'hand', 'have', 'to', 'cancel', 'daca', 'which', 'he', 'do', 'and', 'face', 'the', 'backlash', 'of', 'the', 'big', 'chunk', 'of', 'compassionate', 'american', 'voter', 'and', 'endure', 'riot', 'by', 'angry', 'who', 'can', 'blame', 'they', '?', 'the', 'be', 'lie', 'to', 'dreamer', '.', 'a', 'win', 'win', '.', 'it', 'be', 'all', 'plan', '.', 'now', 'obama', 'and', 'his', 'party', 'can', 'sit', 'back', 'pretend', 'to', 'care', 'and', 'enjoy', 'the', 'scenery', 'of', 'angry', 'youth', 'hate', 'on', 'current', 'president', 'who', 'have', 'nothing', 'to', 'do', 'with', 'false', 'illegal', 'promise', 'of', 'the', 'previous', 'administration', '.', 'dreamer', 'should', 'take', 'obama', 'to', 'court', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "TGT: 0\n",
      "OUT: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Translate a few sentences from the training set\n",
    "print('Classify training data:')\n",
    "print('-----------------------------')\n",
    "pad_src_seqs, src_seq_lengths, pad_tgt_seqs, ids = next(iter(valloader))\n",
    "out_seqs = classify(lstm_glove, pad_src_seqs, src_seq_lengths)\n",
    "\n",
    "for i in range(5):\n",
    "    print('SRC:', seq_to_tokens(pad_src_seqs[:,i], trainset.vocab))\n",
    "    print('TGT:', pad_tgt_seqs[i].item())\n",
    "    print('OUT:', out_seqs[i].item())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(lstm, dataloader=valloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(dataloader):\n",
    "        out_seqs = classify(lstm, src_seqs, src_seq_lengths)\n",
    "        correct += (out_seqs.squeeze().cpu().long() == tgt_labels).sum().item()\n",
    "        total += tgt_labels.shape[0]\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def test_f1_score(lstm, dataloader=valloader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(dataloader):\n",
    "        out_seqs = classify(lstm, src_seqs, src_seq_lengths)\n",
    "        y_true.extend(tgt_labels.cpu().numpy())\n",
    "        y_pred.extend(out_seqs.squeeze().cpu().numpy())\n",
    "    return f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9065940863540765\n"
     ]
    }
   ],
   "source": [
    "# print(test_accuracy(lstm_glove, valloader))\n",
    "print(test_f1_score(lstm_glove, valloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset = TranslationDataset('test_2024.csv', vocab=trainset.vocab, dataset_type='test')\n",
    "# testloader = DataLoader(dataset=testset, batch_size=1, shuffle=False, collate_fn=collate, pin_memory=True)\n",
    "# # save testset\n",
    "# torch.save(testset, 'testset.pth')    \n",
    "\n",
    "# load testset\n",
    "testset = torch.load('dataloaders/testset.pth')\n",
    "testloader = DataLoader(dataset=testset, batch_size=1, shuffle=False, collate_fn=collate, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10990</th>\n",
       "      <td>10995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10985</th>\n",
       "      <td>10996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>10997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10983</th>\n",
       "      <td>10998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10987</th>\n",
       "      <td>10999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "25         0      0\n",
       "0          1      0\n",
       "11         2      0\n",
       "20         3      1\n",
       "16         4      0\n",
       "...      ...    ...\n",
       "10990  10995      0\n",
       "10985  10996      0\n",
       "10998  10997      1\n",
       "10983  10998      1\n",
       "10987  10999      1\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do inference on test set and save the results into csv file\n",
    "def test_inference(lstm, output_filename='submission.csv', testset=testset):\n",
    "    testloader = DataLoader(dataset=testset, batch_size=32, shuffle=False, collate_fn=collate, pin_memory=True)\n",
    "    out = []\n",
    "    indices = []\n",
    "    for i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(testloader):\n",
    "        out_seqs = classify(lstm, src_seqs, src_seq_lengths)\n",
    "        try:\n",
    "            out.extend(out_seqs.squeeze().cpu().numpy())\n",
    "        except:\n",
    "            out.append(out_seqs.squeeze().cpu().numpy())\n",
    "        indices.extend(ids)\n",
    "    df = pd.DataFrame({'id': indices, 'label': out})\n",
    "    # convert label to int\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    # sort by id\n",
    "    df = df.sort_values(by='id')\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    return df\n",
    "\n",
    "test_inference(lstm_glove, output_filename='dev_inference.csv', testset=valset)\n",
    "# test_inference(lstm_glove, output_filename='submission.csv', testset=testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9152764640435471\n",
      "Recall: 0.9100817034496993\n",
      "F1: 0.9125615068314328\n"
     ]
    }
   ],
   "source": [
    "# import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# Compute Precision, Recall, and F1 Score of the imported predicted csv and the validation df\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Load the predicted csv\n",
    "y_pred = pd.read_csv('dev_inference.csv', index_col=0)\n",
    "y_pred = y_pred['label'].tolist()\n",
    "\n",
    "# Load the validation df\n",
    "y_true = pd.read_csv('dev_2024.csv', quoting=3)\n",
    "y_true = y_true['label'].tolist()\n",
    "\n",
    "# Compute the metrics\n",
    "precision, recall, f1 = compute_metrics(y_true, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
