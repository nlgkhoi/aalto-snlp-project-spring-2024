{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Except that Desmond played first base last nig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What i find funny is the loyalty and blindness...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Read the article  not just the headline &amp; you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Speaking of a horses backside  is that where y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Michael Barone- gee are you dumb.  No other wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  label\n",
       "0   0  Except that Desmond played first base last nig...      0\n",
       "1   1  What i find funny is the loyalty and blindness...      0\n",
       "2   2  Read the article  not just the headline & you ...      0\n",
       "3   3  Speaking of a horses backside  is that where y...      1\n",
       "4   4  Michael Barone- gee are you dumb.  No other wo...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_2024.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import unicodedata\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "EOS_token = 1\n",
    "lemmatizer = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "\tdef __init__(self, csv_path, dataset_type='train', vocab=None):\n",
    "\t\tdf = pd.read_csv(csv_path, quoting=3)\n",
    "\t\tprint(f'len df: {len(df)}')\n",
    "\t\tif dataset_type in ['train', 'val']:\n",
    "\t\t\tself.text, self.labels = zip(*[(text, label) for text, label in zip(df['text'], df['label'])])\n",
    "\t\telse:\n",
    "\t\t\tself.text = df['text'].tolist()\n",
    "\t\t\tself.labels = [0 for _ in range(len(self.text))]\n",
    "\t\tself.ids = df['id'].tolist()\n",
    "\t\tself.dataset_type = dataset_type\n",
    "\t\tself.tokenizer = get_tokenizer('basic_english')\n",
    "\t\tself._preprocess(vocab)\n",
    "\n",
    "\tdef _preprocess(self, vocab):\n",
    "\t\t# preprocess text\n",
    "\t\tself.text = [self._preprocess_sentence(text) for text in self.text]\n",
    "\n",
    "\t\tif vocab is None:\n",
    "\t\t\tself.vocab = build_vocab_from_iterator(self._yield_tokens(), specials=[\"<unk>\"])\n",
    "\t\t\tself.vocab.set_default_index(self.vocab['<unk>'])\n",
    "\t\t\tself.vocab.insert_token('<eos>', EOS_token)  # Insert <eos> token with index 1\n",
    "\t\telse:\n",
    "\t\t\tself.vocab = vocab\n",
    "\t\t\t\n",
    "\t\tself.vocab_size = len(self.vocab)\n",
    "\t\n",
    "\tdef _preprocess_sentence(self, sentence):\n",
    "\t\tsentence = normalizeString(sentence)\n",
    "\t\tsentence = self.tokenizer(sentence)\n",
    "\t\tsentence = lemmaString(sentence)\n",
    "\t\treturn sentence\n",
    "\n",
    "\tdef _yield_tokens(self):\n",
    "\t\tfor text_sample in self.text:\n",
    "\t\t\tyield text_sample\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.text)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tinput_seq = text_to_indices(self.vocab, self.text[idx])\n",
    "\t\tlabel = self.labels[idx]\n",
    "\t\treturn input_seq, label, self.ids[idx]\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "\treturn ''.join(\n",
    "\t\tc for c in unicodedata.normalize('NFD', s)\n",
    "\t\tif unicodedata.category(c) != 'Mn'\n",
    "\t)\n",
    "\n",
    "def normalizeString(s):\n",
    "\ts = unicodeToAscii(s.lower().strip())\n",
    "\ts = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "\ts = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "\treturn s\n",
    "\n",
    "def lemmaString(tokens):\n",
    "\treturn [token.lemma_ for token in lemmatizer(' '.join(tokens))]\n",
    "\n",
    "def text_to_indices(vocab, tokens):\n",
    "\tindices = [vocab[token] for token in tokens]\n",
    "\tindices.append(EOS_token)\n",
    "\treturn torch.tensor(indices, dtype=torch.long).view(-1)\n",
    "\n",
    "def seq_to_tokens(seq, vocab):\n",
    "    itos = vocab.get_itos()\n",
    "    return [itos[idx] for idx in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len df: 10\n"
     ]
    }
   ],
   "source": [
    "trainset = TranslationDataset('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['except', 'that', 'desmond', 'play', 'first', 'base', 'last', 'night', '.', 'tapia', 'be', 'in', 'lf', 'and', 'reynolds', 'have', 'a', 'night', 'off', '.', '<eos>']\n",
      "tensor([109,  18,  95, 157, 110,  78, 128,  44,   2, 189,   3,  17, 130,   7,\n",
      "        172,  16,  25,  44, 145,   2,   1]) 0\n",
      "<class 'torch.Tensor'> <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "src_sentence, label, id_ = trainset[0]\n",
    "print(seq_to_tokens(src_sentence, trainset.vocab))\n",
    "print(src_sentence, label)\n",
    "print(type(src_sentence), type(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_VALUE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate(list_of_samples):\n",
    "\t\"\"\"Merges a list of samples to form a mini-batch.\n",
    "\n",
    "\tArgs:\n",
    "\tlist_of_samples is a list of tuples (src_seq, tgt_label, id):\n",
    "\t\tsrc_seq is of shape (src_seq_length,)\n",
    "\t\ttgt_label is of shape (1,)\n",
    "\t\tid is an int\n",
    "\n",
    "\tReturns:\n",
    "\tsrc_seqs of shape (max_src_seq_length, batch_size): Tensor of padded source sequences.\n",
    "\t\tThe sequences should be sorted by length in a decreasing order, that is src_seqs[:,0] should be\n",
    "\t\tthe longest sequence, and src_seqs[:,-1] should be the shortest.\n",
    "\tsrc_seq_lengths: List of lengths of source sequences.\n",
    "\ttgt_labels of shape (batch_size, 1): Tensor of labels for each sequence.\n",
    "\t\"\"\"\n",
    "\t# YOUR CODE HERE\n",
    "\tsrc_seqs = [s[0] for s in list_of_samples]\n",
    "\ttgt_labels = torch.LongTensor([s[1] for s in list_of_samples])\n",
    "\tsrc_seq_lengths = [len(s) for s in src_seqs]\n",
    "\tids = [s[2] for s in list_of_samples]\n",
    "\tsrc_seqs = pad_sequence(src_seqs, padding_value=PADDING_VALUE)\n",
    "\n",
    "\tsrc_seq_lengths, indices = torch.sort(torch.tensor(src_seq_lengths), descending=True)\n",
    "\tsrc_seqs = src_seqs[:, indices]\n",
    "\ttgt_labels = tgt_labels[indices]\n",
    "\n",
    "\treturn src_seqs, src_seq_lengths.tolist(), tgt_labels, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_collate_shapes():\n",
    "    pairs = [\n",
    "        (torch.LongTensor([1, 2]), 1, 0),\n",
    "        (torch.LongTensor([6, 7, 8]), 0, 1),\n",
    "    ]\n",
    "    pad_src_seqs, src_seq_lengths, pad_tgt_seqs, ids = collate(pairs)\n",
    "    assert type(src_seq_lengths) == list, \"src_seq_lengths should be a list.\"\n",
    "    assert pad_src_seqs.shape == torch.Size([3, 2]), f\"Bad pad_src_seqs.shape: {pad_src_seqs.shape}\"\n",
    "    assert pad_src_seqs.dtype == torch.long\n",
    "    assert pad_tgt_seqs.shape == torch.Size([2]), f\"Bad pad_tgt_seqs.shape: {pad_tgt_seqs.shape}\"\n",
    "    assert pad_tgt_seqs.dtype == torch.long\n",
    "    print('Success')\n",
    "\n",
    "test_collate_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sequences combined:\n",
      "tensor([[11,  6,  1],\n",
      "        [12,  7,  2],\n",
      "        [13,  8,  0],\n",
      "        [14,  0,  0]])\n",
      "[4, 3, 2]\n",
      "Target sequences combined:\n",
      "tensor([0, 1, 0])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# This cell tests collate() function\n",
    "\n",
    "def test_collate_fn():\n",
    "    pairs = [\n",
    "        (torch.tensor([1, 2]), 0, 0),\n",
    "        (torch.tensor([6, 7, 8]), 1, 1),\n",
    "        (torch.tensor([11, 12, 13, 14]), 0, 2),\n",
    "    ]\n",
    "    pad_src_seqs, src_seq_lengths, pad_tgt_seqs, ids = collate(pairs)\n",
    "    assert pad_src_seqs.shape == torch.Size([4, 3]), f\"Bad pad_src_seqs.shape: {pad_src_seqs.shape}\"\n",
    "    assert pad_tgt_seqs.shape == torch.Size([3]), f\"Bad pad_tgt_seqs.shape: {pad_tgt_seqs.shape}\"\n",
    "    print('Source sequences combined:')\n",
    "    print(pad_src_seqs)\n",
    "    expected = torch.tensor([\n",
    "      [11, 6, 1],\n",
    "      [12, 7, 2],\n",
    "      [13, 8, 0],\n",
    "      [14, 0, 0],\n",
    "    ])\n",
    "    assert (pad_src_seqs == expected).all(), \"pad_src_seqs does not match expected values\"\n",
    "\n",
    "    print(src_seq_lengths)\n",
    "    if isinstance(src_seq_lengths[0], torch.Size):\n",
    "        src_seq_lengths = sum((list(l) for l in src_seq_lengths), [])\n",
    "    else:\n",
    "        src_seq_lengths = [int(l) for l in src_seq_lengths]\n",
    "    assert src_seq_lengths == [4, 3, 2], f\"Bad src_seq_lengths: {src_seq_lengths}\"\n",
    "\n",
    "    print('Target sequences combined:')\n",
    "    print(pad_tgt_seqs)\n",
    "    expected = torch.tensor([\n",
    "      0, 1, 0\n",
    "    ])\n",
    "    assert (pad_tgt_seqs == expected).all(), \"pad_tgt_seqs0 does not match expected values\"\n",
    "    print('Success')\n",
    "\n",
    "test_collate_fn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We create custom DataLoader using the implemented collate function\n",
    "# # We are going to process 64 sequences at the same time (batch_size=64)\n",
    "# trainset = TranslationDataset('train_2024.csv')\n",
    "# trainloader = DataLoader(dataset=trainset, batch_size=640, shuffle=False, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test data loader\n",
    "# for i, (src_seqs, src_seq_lengths, tgt_seqs, ids) in enumerate(trainloader):\n",
    "#     print(f\"Batch {i} src_seqs:\")\n",
    "#     print(src_seqs)\n",
    "#     print(f'src_seqs.shape: {src_seqs.shape}')\n",
    "#     print(f\"Batch {i} src_seq_lengths:\")\n",
    "#     print(src_seq_lengths)\n",
    "#     print(f\"Batch {i} tgt_seqs:\")\n",
    "#     print(tgt_seqs)\n",
    "#     print(f'tgt_seqs.shape: {tgt_seqs.shape}')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\tdef __init__(self, src_dictionary_size, embed_size, hidden_size, dropout=0.2, glove_embeddings=None):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\tsrc_dictionary_size: The number of words in the source dictionary.\n",
    "\t\tembed_size: The number of dimensions in the word embeddings.\n",
    "\t\thidden_size: The number of features in the hidden state of GRU.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(LSTM, self).__init__()\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.embedding = nn.Embedding(src_dictionary_size, embed_size)\n",
    "\t\tif glove_embeddings is not None:\n",
    "\t\t\tself.load_glove_embeddings(glove_embeddings, embed_size)\n",
    "\t\n",
    "\t\tself.lstm = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=1, batch_first=False, dropout=dropout, bidirectional=False)\n",
    "\t\tself.fc1 = nn.Linear(hidden_size, 128)\n",
    "\t\tself.fc2 = nn.Linear(128, 1)\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\n",
    "\tdef load_glove_embeddings(self, glove_embeddings, embed_size):\n",
    "\t\t\"\"\"Initialize the embedding layer with GloVe embeddings.\"\"\"\n",
    "\t\tweights_matrix = torch.zeros((self.embedding.num_embeddings, embed_size))\n",
    "\n",
    "\t\tfor i, word in enumerate(glove_embeddings):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tweights_matrix[i] = torch.FloatTensor(glove_embeddings[word])\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(e)\n",
    "\t\t\t\tprint(torch.FloatTensor(glove_embeddings[word]).size())\n",
    "\t\t\t\tprint(f'word: {word}, i: {i}')\n",
    "\n",
    "\t\tself.embedding.load_state_dict({'weight': weights_matrix})\n",
    "\n",
    "\tdef forward(self, pad_seqs, seq_lengths, hidden):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\tpad_seqs of shape (max_seq_length, batch_size): Padded source sequences.\n",
    "\t\tseq_lengths: List of sequence lengths.\n",
    "\t\thidden of shape (1, batch_size, hidden_size): Initial states of the GRU.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\toutputs of shape (max_seq_length, batch_size, hidden_size): Padded outputs of GRU at every step.\n",
    "\t\thidden of shape (1, batch_size, hidden_size): Updated states of the GRU.\n",
    "\t\t\"\"\"\n",
    "\t\t# YOUR CODE HERE\n",
    "\t\tembedded = self.embedding(pad_seqs) # shape: (max_seq_length, batch_size, embed_size)\n",
    "\t\tpacked = pack_padded_sequence(embedded, seq_lengths)\n",
    "\t\toutputs, hidden = self.lstm(packed, hidden) \n",
    "\t\toutputs, output_lengths = pad_packed_sequence(outputs, batch_first=False) # shape: (max_seq_length, batch_size, hidden_size)\n",
    "\t\tlast_timesteps = torch.stack([outputs[length-1, i] for i, length in enumerate(output_lengths)]) # shape: (batch_size, hidden_size)\n",
    "\t\t# feed through the fully connected layer\n",
    "\t\toutputs = self.fc1(last_timesteps)\n",
    "\t\toutputs = self.dropout(outputs)\n",
    "\t\toutputs = self.relu(outputs)\n",
    "\t\toutputs = self.fc2(outputs)\n",
    "\t\toutputs = self.sigmoid(outputs)\n",
    "\t\treturn outputs\n",
    "\n",
    "\tdef init_hidden(self, batch_size=1, device='cpu'):\n",
    "\t\tnum_directions = 1\n",
    "\t\treturn (\n",
    "\t\t\ttorch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "\t\t\ttorch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_CNN(nn.Module):\n",
    "    def __init__(self, src_dictionary_size, embed_size, hidden_size, num_filters=100, kernel_sizes= [3, 4, 5], dropout=0.2, glove_embeddings=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        src_dictionary_size: The number of words in the source dictionary.\n",
    "        embed_size: The number of dimensions in the word embeddings.\n",
    "        hidden_size: The number of features in the hidden state of GRU.\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(src_dictionary_size, embed_size)\n",
    "        if glove_embeddings is not None:\n",
    "            self.load_glove_embeddings(glove_embeddings, embed_size)\n",
    "\n",
    "        # CNN layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embed_size, out_channels=num_filters, kernel_size=k, stride=1, padding=k // 2)\n",
    "            for k in kernel_sizes\n",
    "        ])\n",
    "        self.conv_output_size = num_filters * len(kernel_sizes)\n",
    "    \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=1, batch_first=False, dropout=dropout, bidirectional=False)\n",
    "        \n",
    "        # FC layers\n",
    "        self.fc1 = nn.Linear(hidden_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def load_glove_embeddings(self, glove_embeddings, embed_size):\n",
    "        \"\"\"Initialize the embedding layer with GloVe embeddings.\"\"\"\n",
    "        weights_matrix = torch.zeros((self.embedding.num_embeddings, embed_size))\n",
    "\n",
    "        for i, word in enumerate(glove_embeddings):\n",
    "            try:\n",
    "                weights_matrix[i] = torch.FloatTensor(glove_embeddings[word])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(torch.FloatTensor(glove_embeddings[word]).size())\n",
    "                print(f'word: {word}, i: {i}')\n",
    "\n",
    "        self.embedding.load_state_dict({'weight': weights_matrix})\n",
    "\n",
    "    def forward(self, pad_seqs, seq_lengths, hidden):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        pad_seqs of shape (max_seq_length, batch_size): Padded source sequences.\n",
    "        seq_lengths: List of sequence lengths.\n",
    "        hidden of shape (1, batch_size, hidden_size): Initial states of the GRU.\n",
    "\n",
    "        Returns:\n",
    "        outputs of shape (max_seq_length, batch_size, hidden_size): Padded outputs of GRU at every step.\n",
    "        hidden of shape (1, batch_size, hidden_size): Updated states of the GRU.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        embedded = self.embedding(pad_seqs) # shape: (max_seq_length, batch_size, embed_size)\n",
    "        \n",
    "        # reshape before feeding through the CNN layers\n",
    "        embedded = embedded.permute(1, 2, 0)  # shape: (batch_size, embed_size, max_seq_length)\n",
    "\n",
    "        # Apply CNN and ReLU activation\n",
    "        cnn_out = [torch.relu(conv(embedded)) for conv in self.convs]\n",
    "        cnn_out = torch.cat(cnn_out, 1)  # concatenate along the channel dimension shape: (batch_size, num_filters * len(kernel_sizes), max_seq_length)\n",
    "        cnn_out = cnn_out.permute(2, 0, 1)  # shape: (max_seq_length, batch_size, conv_output_size)\n",
    "        embedded = cnn_out\n",
    "\n",
    "        # feed through the LSTM layer\n",
    "        packed = pack_padded_sequence(embedded, seq_lengths)\n",
    "        outputs, hidden = self.lstm(packed, hidden) \n",
    "        outputs, output_lengths = pad_packed_sequence(outputs, batch_first=False) # shape: (max_seq_length, batch_size, hidden_size)\n",
    "        last_timesteps = torch.stack([outputs[length-1, i] for i, length in enumerate(output_lengths)]) # shape: (batch_size, hidden_size)\n",
    "        # feed through the fully connected layer\n",
    "        outputs = self.fc1(last_timesteps)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.relu(outputs)\n",
    "        outputs = self.fc2(outputs)\n",
    "        outputs = self.sigmoid(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size=1, device='cpu'):\n",
    "        num_directions = 1\n",
    "        return (\n",
    "            torch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "            torch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "def test_LSTM_shapes():\n",
    "    hidden_size = 3\n",
    "    lstm = LSTM(src_dictionary_size=5, embed_size=10, hidden_size=hidden_size)\n",
    "\n",
    "    max_seq_length = 4\n",
    "    batch_size = 2\n",
    "    hidden = lstm.init_hidden(batch_size=batch_size)\n",
    "    pad_seqs = torch.tensor([\n",
    "        [        1,             2],\n",
    "        [        2,     EOS_token],\n",
    "        [        3, PADDING_VALUE],\n",
    "        [EOS_token, PADDING_VALUE]\n",
    "    ])\n",
    "\n",
    "    outputs = lstm.forward(pad_seqs=pad_seqs, seq_lengths=[4, 2], hidden=hidden)\n",
    "    assert outputs.shape == torch.Size([batch_size, 1]), f\"Bad outputs.shape: {outputs.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_LSTM_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, val_loader):\n",
    "\tmodel.eval()\n",
    "\ttotal_loss = 0\n",
    "\tcriterion = nn.BCELoss()\n",
    "\twith torch.no_grad():\n",
    "\t\tfor i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(val_loader):\n",
    "\t\t\tsrc_seqs, tgt_labels = src_seqs.to(device), tgt_labels.to(device)\n",
    "\t\t\thidden = model.init_hidden(src_seqs.shape[1], device=device)\n",
    "\t\t\toutputs = model(src_seqs, src_seq_lengths, hidden)\n",
    "\t\t\tloss = criterion(outputs.squeeze(), tgt_labels.float())\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\treturn total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len df: 99000\n"
     ]
    }
   ],
   "source": [
    "# We create custom DataLoader using the implemented collate function\n",
    "# We are going to process 640 sequences at the same time (batch_size=640)\n",
    "# load vocab\n",
    "# vocab = torch.load('vocab.pth')\n",
    "# vocab = None\n",
    "# trainset = TranslationDataset('train_2024.csv', vocab=vocab)\n",
    "trainset = torch.load('dataloaders/trainset.pth')\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=640, shuffle=False, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    }
   ],
   "source": [
    "# We create custom DataLoader using the implemented collate function\n",
    "# We are going to process 64 sequences at the same time (batch_size=64)\n",
    "# valset = TranslationDataset('dev_2024.csv', vocab=trainset.vocab)\n",
    "valset = torch.load('dataloaders/valset.pth')\n",
    "valloader = DataLoader(dataset=valset, batch_size=256, shuffle=False, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trainset\n",
    "# torch.save(trainset, 'trainset.pth')\n",
    "\n",
    "# save valset\n",
    "# torch.save(valset, 'valset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance, patience):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          patience (int):    Maximum number of epochs with unsuccessful updates.\n",
    "          tolerance (float): We assume that the update is unsuccessful if the validation error is larger\n",
    "                              than the best validation error so far plus this tolerance.\n",
    "        \"\"\"\n",
    "        self.tolerance = tolerance\n",
    "        self.patience = patience\n",
    "    \n",
    "    def stop_criterion(self, val_errors):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          val_errors (iterable): Validation errors after every update during training.\n",
    "        \n",
    "        Returns: True if training should be stopped: when the validation error is larger than the best\n",
    "                  validation error obtained so far (with given tolearance) for patience epochs (number of consecutive epochs for which the criterion is satisfied).\n",
    "                 \n",
    "                 Otherwise, False.\n",
    "        \"\"\"\n",
    "        if len(val_errors) <= self.patience:\n",
    "            return False\n",
    "\n",
    "        min_val_error = min(val_errors)\n",
    "        val_errors = np.array(val_errors[-self.patience:])\n",
    "        return all(val_errors > min_val_error + self.tolerance)\n",
    "\n",
    "early_stop = EarlyStopping(tolerance=0.0005, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# Create the LSTM model\n",
    "hidden_size = embed_size = 256\n",
    "lstm = LSTM(trainset.vocab_size, embed_size, hidden_size).to(device)\n",
    "\n",
    "# Load pretrained LSTM\n",
    "# lstm.load_state_dict(torch.load('lstm_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 1, iter 10: avg. loss = 0.3508, Time spent: 2.22s\n",
      "Epoch 1, iter 20: avg. loss = 0.3380, Time spent: 2.27s\n",
      "Epoch 1, iter 30: avg. loss = 0.3257, Time spent: 3.42s\n",
      "Epoch 1, iter 40: avg. loss = 0.3182, Time spent: 2.18s\n",
      "Epoch 1, iter 50: avg. loss = 0.3095, Time spent: 2.19s\n",
      "Epoch 1, iter 60: avg. loss = 0.3007, Time spent: 2.29s\n",
      "Epoch 1, iter 70: avg. loss = 0.2944, Time spent: 2.21s\n",
      "Epoch 1, iter 80: avg. loss = 0.2888, Time spent: 2.17s\n",
      "Epoch 1, iter 90: avg. loss = 0.2835, Time spent: 4.14s\n",
      "Epoch 1, iter 100: avg. loss = 0.2781, Time spent: 2.28s\n",
      "Epoch 1, iter 110: avg. loss = 0.2745, Time spent: 2.29s\n",
      "Epoch 1, iter 120: avg. loss = 0.2728, Time spent: 2.21s\n",
      "Epoch 1, iter 130: avg. loss = 0.2700, Time spent: 2.54s\n",
      "Epoch 1, iter 140: avg. loss = 0.2675, Time spent: 2.25s\n",
      "Epoch 1, iter 150: avg. loss = 0.2652, Time spent: 2.32s\n",
      "find new best model, save to lstm.pth, eval_loss: 0.2042\n",
      "Epoch 1, val loss = 0.2042, train loss = 0.2637; Time spent: 382.34s\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 2, iter 10: avg. loss = 0.2239, Time spent: 2.22s\n",
      "Epoch 2, iter 20: avg. loss = 0.2218, Time spent: 2.27s\n",
      "Epoch 2, iter 30: avg. loss = 0.2166, Time spent: 3.42s\n",
      "Epoch 2, iter 40: avg. loss = 0.2139, Time spent: 2.18s\n",
      "Epoch 2, iter 50: avg. loss = 0.2094, Time spent: 2.20s\n",
      "Epoch 2, iter 60: avg. loss = 0.2052, Time spent: 2.30s\n",
      "Epoch 2, iter 70: avg. loss = 0.2030, Time spent: 2.21s\n",
      "Epoch 2, iter 80: avg. loss = 0.1999, Time spent: 2.18s\n",
      "Epoch 2, iter 90: avg. loss = 0.1974, Time spent: 4.12s\n",
      "Epoch 2, iter 100: avg. loss = 0.1955, Time spent: 2.28s\n",
      "Epoch 2, iter 110: avg. loss = 0.1947, Time spent: 2.29s\n",
      "Epoch 2, iter 120: avg. loss = 0.1938, Time spent: 2.20s\n",
      "Epoch 2, iter 130: avg. loss = 0.1938, Time spent: 2.53s\n",
      "Epoch 2, iter 140: avg. loss = 0.1935, Time spent: 2.25s\n",
      "Epoch 2, iter 150: avg. loss = 0.1934, Time spent: 2.32s\n",
      "find new best model, save to lstm.pth, eval_loss: 0.1623\n",
      "Epoch 2, val loss = 0.1623, train loss = 0.1928; Time spent: 382.62s\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 3, iter 10: avg. loss = 0.1836, Time spent: 2.22s\n",
      "Epoch 3, iter 20: avg. loss = 0.1844, Time spent: 2.27s\n",
      "Epoch 3, iter 30: avg. loss = 0.1819, Time spent: 3.42s\n",
      "Epoch 3, iter 40: avg. loss = 0.1809, Time spent: 2.19s\n",
      "Epoch 3, iter 50: avg. loss = 0.1776, Time spent: 2.20s\n",
      "Epoch 3, iter 60: avg. loss = 0.1747, Time spent: 2.31s\n",
      "Epoch 3, iter 70: avg. loss = 0.1724, Time spent: 2.21s\n",
      "Epoch 3, iter 80: avg. loss = 0.1695, Time spent: 2.19s\n",
      "Epoch 3, iter 90: avg. loss = 0.1669, Time spent: 4.15s\n",
      "Epoch 3, iter 100: avg. loss = 0.1655, Time spent: 2.29s\n",
      "Epoch 3, iter 110: avg. loss = 0.1652, Time spent: 2.29s\n",
      "Epoch 3, iter 120: avg. loss = 0.1641, Time spent: 2.21s\n",
      "Epoch 3, iter 130: avg. loss = 0.1637, Time spent: 2.55s\n",
      "Epoch 3, iter 140: avg. loss = 0.1627, Time spent: 2.25s\n",
      "Epoch 3, iter 150: avg. loss = 0.1624, Time spent: 2.34s\n",
      "find new best model, save to lstm.pth, eval_loss: 0.1312\n",
      "Epoch 3, val loss = 0.1312, train loss = 0.1618; Time spent: 385.12s\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 4, iter 10: avg. loss = 0.1483, Time spent: 2.22s\n",
      "Epoch 4, iter 20: avg. loss = 0.1503, Time spent: 2.28s\n",
      "Epoch 4, iter 30: avg. loss = 0.1480, Time spent: 3.41s\n",
      "Epoch 4, iter 40: avg. loss = 0.1460, Time spent: 2.18s\n",
      "Epoch 4, iter 50: avg. loss = 0.1438, Time spent: 2.21s\n",
      "Epoch 4, iter 60: avg. loss = 0.1416, Time spent: 2.30s\n",
      "Epoch 4, iter 70: avg. loss = 0.1398, Time spent: 2.21s\n",
      "Epoch 4, iter 80: avg. loss = 0.1377, Time spent: 2.19s\n",
      "Epoch 4, iter 90: avg. loss = 0.1368, Time spent: 4.15s\n",
      "Epoch 4, iter 100: avg. loss = 0.1368, Time spent: 2.28s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Workspace\\aalto-snlp-project-spring-2024\\rnn.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y111sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m outputs \u001b[39m=\u001b[39m lstm(src_seqs, src_seq_lengths, hidden)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y111sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs\u001b[39m.\u001b[39msqueeze(), tgt_labels\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y111sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y111sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y111sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 20\n",
    "# prompt ask for continue training or not\n",
    "cont = input('Continue training? yes or no')\n",
    "if cont == 'no':\n",
    "\tprint('Fresh training')\n",
    "\ttrain_losses = []\n",
    "\tval_losses = []\n",
    "\tbest_model = None\n",
    "\tbest_val_loss = float('inf')\n",
    "else:\n",
    "\tprint(f'Continue training')\n",
    "\t\n",
    "for epoch in range(n_epochs):\n",
    "\tlstm.train()\n",
    "\trunning_loss = 0.0\n",
    "\tepoch_start_time = time.time()\n",
    "\tprint(f'Number of batches: {len(trainloader)}')\n",
    "\tprint(f'batch_size: {trainloader.batch_size}')\n",
    "\tfor i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(trainloader):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tsrc_seqs, tgt_labels = src_seqs.to(device), tgt_labels.to(device)\n",
    "\t\thidden = lstm.init_hidden(src_seqs.shape[1], device=device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = lstm(src_seqs, src_seq_lengths, hidden)\n",
    "\t\tloss = criterion(outputs.squeeze(), tgt_labels.float())\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\tif i % 10 == 9:\n",
    "\t\t\tprint(f'Epoch {epoch + 1}, iter {i + 1}: avg. loss = {running_loss/(i + 1):.4f}, Time spent: {time.time()-start_time:.2f}s')\n",
    "\ttrain_losses.append(running_loss / len(trainloader))\n",
    "\teval_loss = val_loss(lstm, valloader)\n",
    "\tif eval_loss < best_val_loss:\n",
    "\t\tbest_val_loss = eval_loss\n",
    "\t\tbest_model = lstm.state_dict()\n",
    "\t\tif best_model is not None:\n",
    "\t\t\tprint(f'find new best model, save to lstm.pth, eval_loss: {eval_loss:.4f}')\n",
    "\t\t\ttorch.save(best_model, 'models/lstm.pth')\n",
    "\n",
    "\tif early_stop.stop_criterion(val_losses):\n",
    "\t\tprint(f'Early stopping on epoch {epoch + 1}')\n",
    "\t\tbreak\n",
    "\t\n",
    "\tval_losses.append(eval_loss)\n",
    "\tprint(f'Epoch {epoch + 1}, val loss = {eval_loss:.4f}, train loss = {train_losses[-1]:.4f}; Time spent: {time.time()-epoch_start_time:.2f}s')\n",
    "\trunning_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and vocab\n",
    "torch.save(lstm.state_dict(), 'lstm.pth')\n",
    "torch.save(trainset.vocab, 'vocab.pth')\n",
    "\n",
    "# # Load model\n",
    "# lstm = LSTM(trainset.vocab_size, embed_size, hidden_size).to(device)\n",
    "# lstm.load_state_dict(torch.load('lstm.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assume you have a function to load GloVe embeddings\n",
    "# def load_glove_embeddings(filepath):\n",
    "#     glove_embeddings = {}\n",
    "#     with open(filepath, 'r', encoding='utf-8') as f:\n",
    "#         for line in f:\n",
    "#             values = line.split()\n",
    "#             word = values[0]\n",
    "#             vector = np.asarray(values[1:], dtype='float32')\n",
    "#             glove_embeddings[word] = vector\n",
    "#     return glove_embeddings\n",
    "\n",
    "# # Load GloVe embeddings from a file\n",
    "# glove_embeddings = load_glove_embeddings('glove_embeddings/glove.twitter.27B.100d.txt')\n",
    "\n",
    "# # Create a dictionary with your src_dictionary and GloVe embeddings\n",
    "# src_dictionary = trainset.vocab  # Add your vocabulary here\n",
    "# src_dictionary_size = len(src_dictionary)\n",
    "# embed_size = 100  # Example embedding size\n",
    "\n",
    "# # Map GloVe vectors to your src_dictionary index\n",
    "# mapped_glove_embeddings = {}\n",
    "# for word, index in src_dictionary.get_stoi().items():\n",
    "#     if word in glove_embeddings:\n",
    "#         mapped_glove_embeddings[index] = glove_embeddings[word]\n",
    "#     else:\n",
    "#         # If word is not in GloVe, initialize a random vector\n",
    "#         mapped_glove_embeddings[index] = np.random.normal(scale=0.6, size=(embed_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load mapped_glove_embeddings\n",
    "# torch.save(mapped_glove_embeddings, 'mapped_glove_embeddings.pth')\n",
    "mapped_glove_embeddings = torch.load('mapped_glove_embeddings.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "embed_size = 100\n",
    "lstm_glove = LSTM(trainset.vocab_size, embed_size, hidden_size, dropout=0.2, glove_embeddings=mapped_glove_embeddings).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fresh training\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 1, iter 10: avg. loss = 0.4392, Time spent: 2.22s\n",
      "Epoch 1, iter 20: avg. loss = 0.4525, Time spent: 2.26s\n",
      "Epoch 1, iter 30: avg. loss = 0.4297, Time spent: 3.41s\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(lstm_glove.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 40\n",
    "# prompt ask for continue training or not\n",
    "cont = input('Continue training? yes or no')\n",
    "if cont == 'no':\n",
    "\tprint('Fresh training')\n",
    "\ttrain_losses = []\n",
    "\tval_losses = []\n",
    "\tbest_model = None\n",
    "\tbest_val_loss = float('inf')\n",
    "else:\n",
    "\tprint(f'Continue training')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\tlstm_glove.train()\n",
    "\trunning_loss = 0.0\n",
    "\tepoch_start_time = time.time()\n",
    "\tprint(f'Number of batches: {len(trainloader)}')\n",
    "\tprint(f'batch_size: {trainloader.batch_size}')\n",
    "\tfor i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(trainloader):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tsrc_seqs, tgt_labels = src_seqs.to(device), tgt_labels.to(device)\n",
    "\t\thidden = lstm_glove.init_hidden(src_seqs.shape[1], device=device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = lstm_glove(src_seqs, src_seq_lengths, hidden)\n",
    "\t\tloss = criterion(outputs.squeeze(), tgt_labels.float())\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\tif i % 10 == 9:\n",
    "\t\t\tprint(f'Epoch {epoch + 1}, iter {i + 1}: avg. loss = {running_loss/(i + 1):.4f}, Time spent: {time.time()-start_time:.2f}s')\n",
    "\ttrain_losses.append(running_loss / len(trainloader))\n",
    "\teval_loss = val_loss(lstm_glove, valloader)\n",
    "\n",
    "\tif eval_loss < best_val_loss:\n",
    "\t\tbest_val_loss = eval_loss\n",
    "\t\tbest_model = lstm_glove.state_dict()\n",
    "\t\tif best_model is not None:\n",
    "\t\t\tprint(f'find new best model, save to models/lstm_glove.pth, eval_loss: {eval_loss:.4f}')\n",
    "\t\t\ttorch.save(best_model, os.path.join('models', 'lstm_glove.pth'))\n",
    "\n",
    "\tif early_stop.stop_criterion(val_losses):\n",
    "\t\tprint(f'Early stopping at epoch {epoch + 1}')\n",
    "\t\tbreak\n",
    "\t\n",
    "\tval_losses.append(eval_loss)\n",
    "\tprint(f'Epoch {epoch + 1}, val loss = {eval_loss:.4f}, train loss = {train_losses[-1]:.4f}; Time spent: {time.time()-epoch_start_time:.2f}s')\n",
    "\trunning_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose model to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vanilla LSTM\n",
    "# hidden_size = embed_size = 256\n",
    "# lstm = LSTM(trainset.vocab_size, embed_size, hidden_size).to(device)\n",
    "# lstm.load_state_dict(torch.load('lstm.pth'))\n",
    "\n",
    "# LSTM with GloVe embeddings\n",
    "# lstm_glove = LSTM(trainset.vocab_size, embed_size, hidden_size, dropout=0.2, glove_embeddings=None).to(device)\n",
    "lstm_glove.load_state_dict(torch.load('models/lstm_glove.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(lstm, pad_src_seqs, src_seq_lengths):\n",
    "    \"\"\"Translate sequences from the source language to the target language using the trained model.\n",
    "\n",
    "    Args:\n",
    "    lstm (LSTM): Trained lstm.\n",
    "    pad_src_seqs of shape (max_src_seq_length, batch_size): Padded source sequences.\n",
    "    src_seq_lengths: List of source sequence lengths.\n",
    "\n",
    "    Returns:\n",
    "    out_seqs of shape (batch_size, 1): LongTensor of word indices of the output sequences.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    with torch.no_grad():\n",
    "        pad_src_seqs = pad_src_seqs.to(device)\n",
    "        lstm_hidden = lstm.init_hidden(pad_src_seqs.shape[1], device)\n",
    "        outputs = lstm(pad_src_seqs, src_seq_lengths, lstm_hidden)\n",
    "        out_seqs = outputs > 0.5\n",
    "        return out_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_translate_shapes(lstm):\n",
    "    pad_src_seqs = torch.tensor([\n",
    "        [1, 2],\n",
    "        [2, 3],\n",
    "        [3, 0],\n",
    "        [4, 0]\n",
    "    ])\n",
    "\n",
    "    out_seqs = classify(lstm, pad_src_seqs, src_seq_lengths=[4, 2])\n",
    "    assert out_seqs.shape == torch.Size([2, 1]), f\"Wrong out_seqs.shape: {out_seqs.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_translate_shapes(lstm_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify training data:\n",
      "-----------------------------\n",
      "SRC: ['good', 'article', 'but', 'few', 'read', 'the', 'rg', '.', 'for', 'enforcement', 'folk', 'we', 'see', 'that', 'there', 'be', 'a', 'wide', 'degree', 'of', 'latitude', 'in', 'how', 'officer', 'apply', 'the', 'law', '.', 'only', 'ticket', 'issue', 'so', 'far', 'indicate', 'to', 'I', 'that', 'of', 'the', 'total', 'infraction', 'it', 's', 'a', 'drop', 'in', 'the', 'bucket', '.', 'and', 'then', 'there', 'be', 'judge', 'some', 'of', 'whom', 'will', 'reduce', 'the', 'fine', 'for', 'first', 'offense', 'or', 'mitigating', 'circumstance', '.', 'what', 'would', 'an', 'officer', 'do', 'if', 'someone', 'later', 'injure', 'or', 'kill', 'someone', 'while', 'texte', '?', 'I', 'be', 'inclined', 'to', 'issue', 'more', 'ticket', 'and', 'let', 'the', 'judge', 'make', 'the', 'call', '.', 'for', 'anyone', 'catch', 'lie', 'about', 'it', 'that', 'be', 'an', 'immediate', 'ticket', '.', 'these', 'people', 'know', '.', 'I', 'send', 'a', 'text', 'to', 'a', 'friend', 'that', 'return', 'an', 'automate', 'text', 'say', 'that', 'she', 'be', 'drive', 'and', 'would', 'reply', 'later', '.', 'that', 'be', 'a', 'great', 'app', '.', 'guess', 'I', 'd', 'say', 'half', 'the', 'driver', 'think', 'it', 'be', 'ok', 'to', 'text', 'at', 'a', 'light', '.', 'you', 'can', 'see', 'many', 'furtively', 'texte', 'and', 'some', 'be', 'the', 'one', 'in', 'front', 'of', 'you', 'that', 'seem', 'to', 'not', 'notice', 'the', 'light', '.', 'I', 'd', 'add', 'a', 'few', 'sign', 'at', 'street', 'light', 'that', 'read', 'distracted', 'drive', 'law', 'apply', 'while', 'stop', 'at', 'light', '.', '<eos>']\n",
      "TGT: 0\n",
      "OUT: False\n",
      "\n",
      "SRC: ['whenever', 'abortion', 'come', 'up', 'I', 'have', 'a', 'question', 'I', 've', 'be', 'ask', 'for', 'ten', 'year', 'now', 'of', 'the', 'life', 'begin', 'at', 'conception', 'crowd', '.', 'in', 'ten', 'year', 'no', 'one', 'have', 'ever', 'answer', 'it', 'honestly', '.', 'here', 'it', 'be', '.', 'you', 're', 'in', 'a', 'fertility', 'clinic', '.', 'why', 'isn', 't', 'important', '.', 'the', 'fire', 'alarm', 'go', 'off', '.', 'you', 'run', 'for', 'the', 'exit', '.', 'as', 'you', 'run', 'down', 'this', 'hallway', 'you', 'hear', 'a', 'child', 'scream', 'from', 'behind', 'a', 'door', '.', 'you', 'throw', 'open', 'the', 'door', 'and', 'find', 'a', 'five', 'year', 'old', 'child', 'cry', 'for', 'help', '.', 'they', 're', 'in', 'one', 'corner', 'of', 'the', 'room', '.', 'in', 'the', 'other', 'corner', 'you', 'spot', 'a', 'frozen', 'container', 'label', 'viable', 'human', 'embryo', '.', 'the', 'smoke', 'be', 'rise', '.', 'you', 'start', 'to', 'choke', '.', 'you', 'know', 'you', 'can', 'grab', 'one', 'or', 'the', 'other', 'but', 'not', 'both', 'before', 'you', 'succumb', 'to', 'smoke', 'inhalation', 'and', 'die', 'save', 'no', 'one', '.', 'do', 'you', 'a', 'save', 'the', 'child', 'or', 'b', 'save', 'the', 'thousand', 'embryo', '?', 'there', 'be', 'no', 'c', '.', 'c', 'mean', 'you', 'all', 'die', '.', 'patrick', 's', '.', 'tomlinson', 'http', 'www', '.', 'patrickstomlinson', '.', 'com', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "TGT: 0\n",
      "OUT: False\n",
      "\n",
      "SRC: ['it', 's', 'definitely', 'a', 'new', 'thing', '.', 'I', 'don', 't', 'mind', 'it', 'myself', '.', '.', '.', 'I', 'find', 'myself', 'be', 'more', 'conscious', 'of', 'the', 'difference', 'between', 'a', 'good', 'comment', 'vs', '.', 'a', 'comment', 'that', 'fail', 'the', 'civility', 'test', 'find', 'myself', 'rating', 'comment', 'good', 'even', 'if', 'I', 'disagree', 'with', 'they', 'when', 'they', 'be', 'civil', 'especially', 'if', 'they', 'bring', 'up', 'point', 'that', 'I', 'can', 'think', 'about', '.', 'it', 'make', 'I', 'feel', 'well', 'about', 'people', 'I', 'disagree', 'with', '.', 'I', 'just', 'read', 'an', 'article', 'which', 'mention', 'civil', 'comment', 'its', 'rationale', '.', 'the', 'entire', 'article', 'be', 'worth', 'a', 'read', 'the', 'social', 'impact', 'of', 'uncivil', 'discourse', 'be', 'one', 'thing', 'but', 'there', 's', 'also', 'economic', 'world', 'political', 'implication', 'among', 'other', '.', 'I', 'think', 'we', 're', 'likely', 'to', 'see', 'tech', 'company', 'roll', 'a', 'lot', 'more', 'product', 'to', 'encourage', 'civility', 'in', 'social', 'medium', 'in', 'the', 'come', 'year', '.', 'play', 'nice', '!', 'how', 'the', 'internet', 'be', 'try', 'to', 'design', 'out', 'toxic', 'behaviour', 'http', 'www', '.', 'theguardian', '.', 'com', 'technology', 'feb', 'play', 'nice', 'how', 'the', 'internet', 'be', 'try', 'to', 'design', 'out', 'toxic', 'behaviour', 'have', 'a', 'great', 'night', 'tom', 'good', 'talk', 'with', 'you', '.', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "TGT: 0\n",
      "OUT: False\n",
      "\n",
      "SRC: ['what', 'I', 'find', 'funny', 'be', 'the', 'loyalty', 'and', 'blindness', 'of', 'english', 'community', '.', 'the', 'bad', 'possible', 'choice', 'for', 'they', 'be', 'liberal', 'and', 'yet', 'they', 'keep', 'vote', 'for', 'they', 'every', 'time', '.', 'they', 'keep', 'renew', 'hope', 'every', 'election', 'year', 'prior', 'to', 'it', 'just', 'to', 'ignore', 'they', 'at', 'the', 'win', 'speach', 'already', '.', 'honestly', 'pq', 'have', 'more', 'respect', 'for', 'english', 'community', 'then', 'liberal', 'at', 'least', 'they', 'do', 'not', 'lie', 'to', 'you', 'just', 'to', 'get', 'your', 'vote', '.', 'that', 'be', 'say', 'I', 'do', 'not', 'vote', 'pq', 'either', 'tired', 'of', 'those', 'old', 'man', 'but', 'that', 'be', 'another', 'story', '.', 'I', 'mostly', 'vote', 'local', 'candidate', 'regardless', 'of', 'party', 'even', 'vote', 'liberal', 'once', '.', '.', 'outch', 'that', 'be', 'hard', 'to', 'admit', '.', 'but', 'seriously', 'guy', 's', 'drop', 'the', 'act', 'anti', 'pq', 'anti', 'qs', 'do', 'not', 'vote', 'for', 'caq', 'cause', 'they', 'do', 'not', 'win', 'etc', '.', '.', 'any', 'of', 'those', 'will', 'at', 'least', 'respect', 'you', 'when', 'they', 'say', 'no', '.', 'and', 'most', 'of', 'time', 'they', 'will', 'say', 'yes', 'and', 'act', 'on', 'it', 'not', 'just', 'say', 'it', 'like', 'liberal', 'do', '.', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "TGT: 0\n",
      "OUT: False\n",
      "\n",
      "SRC: ['when', 'you', 'come', 'from', 'a', 'totalitarian', 'society', 'that', 'be', 'very', 'tribal', 'and', 'that', 'tribalism', 'be', 'express', 'through', 'the', 'glue', 'of', 'religion', 'a', 'free', 'secular', 'society', 'like', 'that', 'in', 'the', 'west', 'be', 'view', 'quite', 'differently', '.', 'that', 'be', 'especially', 'so', 'when', 'the', 'prescript', 'of', 'that', 'religion', 'deny', 'many', 'of', 'the', 'basic', 'human', 'right', 'that', 'we', 'in', 'the', 'west', 'take', 'for', 'grant', '.', 'hence', 'we', 'be', 'subject', 'to', 'these', 'incomprehensible', 'terrorist', 'attack', 'both', 'thru', 'new', 'immigrant', 'from', 'those', 'culture', 'and', 'from', 'homegrown', 'terrorist', 'who', 'romantize', 'the', 'whiff', 'of', 'th', 'century', 'culture', '.', 'yet', 'here', 'in', 'the', 'west', 'we', 'be', 'be', 'brainwash', 'by', 'those', 'who', 'profess', 'the', 'benefit', 'of', 'open', 'border', 'but', 'not', 'open', 'society', 'by', 'allow', 'these', 'alien', 'culture', 'to', 'profusely', 'populate', 'our', 'land', '.', 'its', 'insidious', 'and', 'subversive', 'and', 'be', 'now', 'accompany', 'by', 'suppression', 'of', 'free', 'speech', 'as', 'we', 'be', 'now', 'seeing', 'throw', 'at', 'we', 'by', 'the', 'msm', 'and', 'their', 'boss', 'in', 'the', 'wealthy', '.', 'it', 'must', 'be', 'counter', 'and', 'snuff', 'out', '.', 'else', 'our', 'basic', 'human', 'right', 'will', 'be', 'erode', 'from', 'within', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "TGT: 0\n",
      "OUT: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Translate a few sentences from the training set\n",
    "print('Classify training data:')\n",
    "print('-----------------------------')\n",
    "pad_src_seqs, src_seq_lengths, pad_tgt_seqs, ids = next(iter(valloader))\n",
    "out_seqs = classify(lstm_glove, pad_src_seqs, src_seq_lengths)\n",
    "\n",
    "for i in range(5):\n",
    "    print('SRC:', seq_to_tokens(pad_src_seqs[:,i], trainset.vocab))\n",
    "    print('TGT:', pad_tgt_seqs[i].item())\n",
    "    print('OUT:', out_seqs[i].item())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(lstm, dataloader=valloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(dataloader):\n",
    "        out_seqs = classify(lstm, src_seqs, src_seq_lengths)\n",
    "        correct += (out_seqs.squeeze().cpu().long() == tgt_labels).sum().item()\n",
    "        total += tgt_labels.shape[0]\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def test_f1_score(lstm, dataloader=valloader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(dataloader):\n",
    "        out_seqs = classify(lstm, src_seqs, src_seq_lengths)\n",
    "        y_true.extend(tgt_labels.cpu().numpy())\n",
    "        y_pred.extend(out_seqs.squeeze().cpu().numpy())\n",
    "    return f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8814897027993587\n"
     ]
    }
   ],
   "source": [
    "# print(test_accuracy(lstm_glove, valloader))\n",
    "print(test_f1_score(lstm_glove, valloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset = TranslationDataset('test_2024.csv', vocab=trainset.vocab, dataset_type='test')\n",
    "# testloader = DataLoader(dataset=testset, batch_size=1, shuffle=False, collate_fn=collate, pin_memory=True)\n",
    "# # save testset\n",
    "# torch.save(testset, 'testset.pth')    \n",
    "\n",
    "# load testset\n",
    "testset = torch.load('dataloaders/testset.pth')\n",
    "testloader = DataLoader(dataset=testset, batch_size=1, shuffle=False, collate_fn=collate, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do inference on test set and save the results into csv file\n",
    "def test_inference(lstm, output_filename='submission.csv', testloader=testloader):\n",
    "    out = []\n",
    "    indices = []\n",
    "    for i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(testloader):\n",
    "        out_seqs = classify(lstm, src_seqs, src_seq_lengths)\n",
    "        try:\n",
    "            out.extend(out_seqs.squeeze().cpu().numpy())\n",
    "        except:\n",
    "            out.append(out_seqs.squeeze().cpu().numpy())\n",
    "        indices.extend(ids)\n",
    "    df = pd.DataFrame({'id': indices, 'label': out})\n",
    "    # convert label to int\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    # sort by id\n",
    "    df = df.sort_values(by='id')\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    return df\n",
    "\n",
    "test_inference(lstm, output_filename='dev_inference.csv', testloader=valloader)\n",
    "# test_inference(lstm_glove, output_filename='submission.csv', testloader=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [11000, 99000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Workspace\\aalto-snlp-project-spring-2024\\rnn.ipynb Cell 45\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y125sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m y_true \u001b[39m=\u001b[39m y_true[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y125sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Compute the metrics\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y125sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m precision, recall, f1 \u001b[39m=\u001b[39m compute_metrics(y_true, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y125sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPrecision: \u001b[39m\u001b[39m{\u001b[39;00mprecision\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y125sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRecall: \u001b[39m\u001b[39m{\u001b[39;00mrecall\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32md:\\Workspace\\aalto-snlp-project-spring-2024\\rnn.ipynb Cell 45\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y125sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_metrics\u001b[39m(y_true, y_pred):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y125sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     precision \u001b[39m=\u001b[39m precision_score(y_true, y_pred, average\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmacro\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y125sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     recall \u001b[39m=\u001b[39m recall_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y125sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     f1 \u001b[39m=\u001b[39m f1_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2127\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1970\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   1971\u001b[0m     {\n\u001b[0;32m   1972\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1996\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1997\u001b[0m ):\n\u001b[0;32m   1998\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1999\u001b[0m \n\u001b[0;32m   2000\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2125\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   2126\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2127\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   2128\u001b[0m         y_true,\n\u001b[0;32m   2129\u001b[0m         y_pred,\n\u001b[0;32m   2130\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   2131\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   2132\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   2133\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   2134\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   2135\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   2136\u001b[0m     )\n\u001b[0;32m   2137\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1563\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m \n\u001b[0;32m   1565\u001b[0m \u001b[39mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[39m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m zero_division_value \u001b[39m=\u001b[39m _check_zero_division(zero_division)\n\u001b[1;32m-> 1721\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1723\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1499\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1499\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1500\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [11000, 99000]"
     ]
    }
   ],
   "source": [
    "# import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# Compute Precision, Recall, and F1 Score of the imported predicted csv and the validation df\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Load the predicted csv\n",
    "y_pred = pd.read_csv('dev_inference.csv', index_col=0)\n",
    "y_pred = y_pred['label'].tolist()\n",
    "\n",
    "# Load the validation df\n",
    "y_true = pd.read_csv('dev_2024.csv', quoting=3)\n",
    "y_true = y_true['label'].tolist()\n",
    "\n",
    "# Compute the metrics\n",
    "precision, recall, f1 = compute_metrics(y_true, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
