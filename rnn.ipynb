{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the GPU!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"Using MPS!\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"Using the CPU!\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Except that Desmond played first base last nig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What i find funny is the loyalty and blindness...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Read the article  not just the headline &amp; you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Speaking of a horses backside  is that where y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Michael Barone- gee are you dumb.  No other wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  label\n",
       "0   0  Except that Desmond played first base last nig...      0\n",
       "1   1  What i find funny is the loyalty and blindness...      0\n",
       "2   2  Read the article  not just the headline & you ...      0\n",
       "3   3  Speaking of a horses backside  is that where y...      1\n",
       "4   4  Michael Barone- gee are you dumb.  No other wo...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_2024.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import unicodedata\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "EOS_token = 1\n",
    "lemmatizer = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "\tdef __init__(self, csv_path, dataset_type='train', vocab=None):\n",
    "\t\tdf = pd.read_csv(csv_path, quoting=3)\n",
    "\t\tprint(f'len df: {len(df)}')\n",
    "\t\tif dataset_type in ['train', 'val']:\n",
    "\t\t\tself.text, self.labels = zip(*[(text, label) for text, label in zip(df['text'], df['label'])])\n",
    "\t\telse:\n",
    "\t\t\tself.text = df['text'].tolist()\n",
    "\t\t\tself.labels = [0 for _ in range(len(self.text))]\n",
    "\t\tself.ids = df['id'].tolist()\n",
    "\t\tself.dataset_type = dataset_type\n",
    "\t\tself.tokenizer = get_tokenizer('basic_english')\n",
    "\t\tself._preprocess(vocab)\n",
    "\n",
    "\tdef _preprocess(self, vocab):\n",
    "\t\t# preprocess text\n",
    "\t\tself.text = [self._preprocess_sentence(text) for text in self.text]\n",
    "\n",
    "\t\tif vocab is None:\n",
    "\t\t\tself.vocab = build_vocab_from_iterator(self._yield_tokens(), specials=[\"<unk>\"])\n",
    "\t\t\tself.vocab.set_default_index(self.vocab['<unk>'])\n",
    "\t\t\tself.vocab.insert_token('<eos>', EOS_token)  # Insert <eos> token with index 1\n",
    "\t\telse:\n",
    "\t\t\tself.vocab = vocab\n",
    "\t\t\t\n",
    "\t\tself.vocab_size = len(self.vocab)\n",
    "\t\n",
    "\tdef _preprocess_sentence(self, sentence):\n",
    "\t\tsentence = normalizeString(sentence)\n",
    "\t\tsentence = self.tokenizer(sentence)\n",
    "\t\tsentence = lemmaString(sentence)\n",
    "\t\treturn sentence\n",
    "\n",
    "\tdef _yield_tokens(self):\n",
    "\t\tfor text_sample in self.text:\n",
    "\t\t\tyield text_sample\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.text)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tinput_seq = text_to_indices(self.vocab, self.text[idx])\n",
    "\t\tlabel = self.labels[idx]\n",
    "\t\treturn input_seq, label, self.ids[idx]\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "\treturn ''.join(\n",
    "\t\tc for c in unicodedata.normalize('NFD', s)\n",
    "\t\tif unicodedata.category(c) != 'Mn'\n",
    "\t)\n",
    "\n",
    "def normalizeString(s):\n",
    "\ts = unicodeToAscii(s.lower().strip())\n",
    "\ts = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "\ts = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "\treturn s\n",
    "\n",
    "def lemmaString(tokens):\n",
    "\treturn [token.lemma_ for token in lemmatizer(' '.join(tokens))]\n",
    "\n",
    "def text_to_indices(vocab, tokens):\n",
    "\tindices = [vocab[token] for token in tokens]\n",
    "\tindices.append(EOS_token)\n",
    "\treturn torch.tensor(indices, dtype=torch.long).view(-1)\n",
    "\n",
    "def seq_to_tokens(seq, vocab):\n",
    "    itos = vocab.get_itos()\n",
    "    return [itos[idx] for idx in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len df: 9\n"
     ]
    }
   ],
   "source": [
    "trainset = TranslationDataset('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'get', 'the', 'odd', 'feeling', 'klastri', 'the', 'head', 'of', 'the', 'aclu', 'of', 'hawaii', 'will', 'step', 'in', 'and', 'defend', 'this', 'scum', 'for', 'freedom', 'of', 'speech', '.', '<eos>']\n",
      "tensor([ 15,  48,   3, 183, 133, 164,   3, 152,  13,   3,  77,  13, 150,  75,\n",
      "        228,  25,   5, 115,  31, 215,  12, 138,  13, 226,   2,   1]) ?\n",
      "<class 'torch.Tensor'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "src_sentence, label, id_ = trainset[0]\n",
    "print(seq_to_tokens(src_sentence, trainset.vocab))\n",
    "print(src_sentence, label)\n",
    "print(type(src_sentence), type(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_VALUE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate(list_of_samples):\n",
    "\t\"\"\"Merges a list of samples to form a mini-batch.\n",
    "\n",
    "\tArgs:\n",
    "\tlist_of_samples is a list of tuples (src_seq, tgt_label, id):\n",
    "\t\tsrc_seq is of shape (src_seq_length,)\n",
    "\t\ttgt_label is of shape (1,)\n",
    "\t\tid is an int\n",
    "\n",
    "\tReturns:\n",
    "\tsrc_seqs of shape (max_src_seq_length, batch_size): Tensor of padded source sequences.\n",
    "\t\tThe sequences should be sorted by length in a decreasing order, that is src_seqs[:,0] should be\n",
    "\t\tthe longest sequence, and src_seqs[:,-1] should be the shortest.\n",
    "\tsrc_seq_lengths: List of lengths of source sequences.\n",
    "\ttgt_labels of shape (batch_size, 1): Tensor of labels for each sequence.\n",
    "\t\"\"\"\n",
    "\t# YOUR CODE HERE\n",
    "\tsrc_seqs = [s[0] for s in list_of_samples]\n",
    "\ttgt_labels = torch.LongTensor([s[1] for s in list_of_samples])\n",
    "\tsrc_seq_lengths = [len(s) for s in src_seqs]\n",
    "\tids = [s[2] for s in list_of_samples]\n",
    "\tsrc_seqs = pad_sequence(src_seqs, padding_value=PADDING_VALUE)\n",
    "\n",
    "\tsrc_seq_lengths, indices = torch.sort(torch.tensor(src_seq_lengths), descending=True)\n",
    "\tsrc_seqs = src_seqs[:, indices]\n",
    "\ttgt_labels = tgt_labels[indices]\n",
    "\tids = [ids[i] for i in indices]\n",
    "\n",
    "\treturn src_seqs, src_seq_lengths.tolist(), tgt_labels, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_collate_shapes():\n",
    "    pairs = [\n",
    "        (torch.LongTensor([1, 2]), 1, 0),\n",
    "        (torch.LongTensor([6, 7, 8]), 0, 1),\n",
    "    ]\n",
    "    pad_src_seqs, src_seq_lengths, pad_tgt_seqs, ids = collate(pairs)\n",
    "    assert type(src_seq_lengths) == list, \"src_seq_lengths should be a list.\"\n",
    "    assert pad_src_seqs.shape == torch.Size([3, 2]), f\"Bad pad_src_seqs.shape: {pad_src_seqs.shape}\"\n",
    "    assert pad_src_seqs.dtype == torch.long\n",
    "    assert pad_tgt_seqs.shape == torch.Size([2]), f\"Bad pad_tgt_seqs.shape: {pad_tgt_seqs.shape}\"\n",
    "    assert pad_tgt_seqs.dtype == torch.long\n",
    "    print('Success')\n",
    "\n",
    "test_collate_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sequences combined:\n",
      "tensor([[11,  6,  1],\n",
      "        [12,  7,  2],\n",
      "        [13,  8,  0],\n",
      "        [14,  0,  0]])\n",
      "[4, 3, 2]\n",
      "Target sequences combined:\n",
      "tensor([0, 1, 0])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# This cell tests collate() function\n",
    "\n",
    "def test_collate_fn():\n",
    "    pairs = [\n",
    "        (torch.tensor([1, 2]), 0, 0),\n",
    "        (torch.tensor([6, 7, 8]), 1, 1),\n",
    "        (torch.tensor([11, 12, 13, 14]), 0, 2),\n",
    "    ]\n",
    "    pad_src_seqs, src_seq_lengths, pad_tgt_seqs, ids = collate(pairs)\n",
    "    assert pad_src_seqs.shape == torch.Size([4, 3]), f\"Bad pad_src_seqs.shape: {pad_src_seqs.shape}\"\n",
    "    assert pad_tgt_seqs.shape == torch.Size([3]), f\"Bad pad_tgt_seqs.shape: {pad_tgt_seqs.shape}\"\n",
    "    print('Source sequences combined:')\n",
    "    print(pad_src_seqs)\n",
    "    expected = torch.tensor([\n",
    "      [11, 6, 1],\n",
    "      [12, 7, 2],\n",
    "      [13, 8, 0],\n",
    "      [14, 0, 0],\n",
    "    ])\n",
    "    assert (pad_src_seqs == expected).all(), \"pad_src_seqs does not match expected values\"\n",
    "\n",
    "    print(src_seq_lengths)\n",
    "    if isinstance(src_seq_lengths[0], torch.Size):\n",
    "        src_seq_lengths = sum((list(l) for l in src_seq_lengths), [])\n",
    "    else:\n",
    "        src_seq_lengths = [int(l) for l in src_seq_lengths]\n",
    "    assert src_seq_lengths == [4, 3, 2], f\"Bad src_seq_lengths: {src_seq_lengths}\"\n",
    "\n",
    "    print('Target sequences combined:')\n",
    "    print(pad_tgt_seqs)\n",
    "    expected = torch.tensor([\n",
    "      0, 1, 0\n",
    "    ])\n",
    "    assert (pad_tgt_seqs == expected).all(), \"pad_tgt_seqs0 does not match expected values\"\n",
    "    print('Success')\n",
    "\n",
    "test_collate_fn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We create custom DataLoader using the implemented collate function\n",
    "# # We are going to process 64 sequences at the same time (batch_size=64)\n",
    "# trainset = TranslationDataset('train_2024.csv')\n",
    "# trainloader = DataLoader(dataset=trainset, batch_size=640, shuffle=False, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test data loader\n",
    "# for i, (src_seqs, src_seq_lengths, tgt_seqs, ids) in enumerate(trainloader):\n",
    "#     print(f\"Batch {i} src_seqs:\")\n",
    "#     print(src_seqs)\n",
    "#     print(f'src_seqs.shape: {src_seqs.shape}')\n",
    "#     print(f\"Batch {i} src_seq_lengths:\")\n",
    "#     print(src_seq_lengths)\n",
    "#     print(f\"Batch {i} tgt_seqs:\")\n",
    "#     print(tgt_seqs)\n",
    "#     print(f'tgt_seqs.shape: {tgt_seqs.shape}')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\tdef __init__(self, src_dictionary_size, embed_size, hidden_size, dropout=0.2, glove_embeddings=None):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\tsrc_dictionary_size: The number of words in the source dictionary.\n",
    "\t\tembed_size: The number of dimensions in the word embeddings.\n",
    "\t\thidden_size: The number of features in the hidden state of GRU.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(LSTM, self).__init__()\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.embedding = nn.Embedding(src_dictionary_size, embed_size)\n",
    "\t\tif glove_embeddings is not None:\n",
    "\t\t\tself.load_glove_embeddings(glove_embeddings, embed_size)\n",
    "\t\n",
    "\t\tself.lstm = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=1, batch_first=False, dropout=dropout, bidirectional=False)\n",
    "\t\tself.fc1 = nn.Linear(hidden_size, 128)\n",
    "\t\tself.fc2 = nn.Linear(128, 1)\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\n",
    "\tdef load_glove_embeddings(self, glove_embeddings, embed_size):\n",
    "\t\t\"\"\"Initialize the embedding layer with GloVe embeddings.\"\"\"\n",
    "\t\tweights_matrix = torch.zeros((self.embedding.num_embeddings, embed_size))\n",
    "\n",
    "\t\tfor i, word in enumerate(glove_embeddings):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tweights_matrix[i] = torch.FloatTensor(glove_embeddings[word])\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(e)\n",
    "\t\t\t\tprint(torch.FloatTensor(glove_embeddings[word]).size())\n",
    "\t\t\t\tprint(f'word: {word}, i: {i}')\n",
    "\n",
    "\t\tself.embedding.load_state_dict({'weight': weights_matrix})\n",
    "\n",
    "\tdef forward(self, pad_seqs, seq_lengths, hidden):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\tpad_seqs of shape (max_seq_length, batch_size): Padded source sequences.\n",
    "\t\tseq_lengths: List of sequence lengths.\n",
    "\t\thidden of shape (1, batch_size, hidden_size): Initial states of the GRU.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\toutputs of shape (max_seq_length, batch_size, hidden_size): Padded outputs of GRU at every step.\n",
    "\t\thidden of shape (1, batch_size, hidden_size): Updated states of the GRU.\n",
    "\t\t\"\"\"\n",
    "\t\t# YOUR CODE HERE\n",
    "\t\tembedded = self.embedding(pad_seqs) # shape: (max_seq_length, batch_size, embed_size)\n",
    "\t\tpacked = pack_padded_sequence(embedded, seq_lengths)\n",
    "\t\toutputs, hidden = self.lstm(packed, hidden) \n",
    "\t\toutputs, output_lengths = pad_packed_sequence(outputs, batch_first=False) # shape: (max_seq_length, batch_size, hidden_size)\n",
    "\t\tlast_timesteps = torch.stack([outputs[length-1, i] for i, length in enumerate(output_lengths)]) # shape: (batch_size, hidden_size)\n",
    "\t\t# feed through the fully connected layer\n",
    "\t\toutputs = self.fc1(last_timesteps)\n",
    "\t\toutputs = self.dropout(outputs)\n",
    "\t\toutputs = self.relu(outputs)\n",
    "\t\toutputs = self.fc2(outputs)\n",
    "\t\toutputs = self.sigmoid(outputs)\n",
    "\t\treturn outputs\n",
    "\n",
    "\tdef init_hidden(self, batch_size=1, device='cpu'):\n",
    "\t\tnum_directions = 1\n",
    "\t\treturn (\n",
    "\t\t\ttorch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "\t\t\ttorch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_CNN(nn.Module):\n",
    "    def __init__(self, src_dictionary_size, embed_size, hidden_size, num_filters=100, kernel_sizes= [3, 4, 5], dropout=0.2, glove_embeddings=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        src_dictionary_size: The number of words in the source dictionary.\n",
    "        embed_size: The number of dimensions in the word embeddings.\n",
    "        hidden_size: The number of features in the hidden state of GRU.\n",
    "        \"\"\"\n",
    "        super(LSTM_CNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(src_dictionary_size, embed_size)\n",
    "        if glove_embeddings is not None:\n",
    "            self.load_glove_embeddings(glove_embeddings, embed_size)\n",
    "\n",
    "        # CNN layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embed_size, out_channels=num_filters, kernel_size=k, stride=1, padding=\"same\")\n",
    "            for k in kernel_sizes\n",
    "        ])\n",
    "        self.conv_output_size = num_filters * len(kernel_sizes)\n",
    "    \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(input_size=self.conv_output_size, hidden_size=hidden_size, num_layers=1, batch_first=False, dropout=dropout, bidirectional=False)\n",
    "        \n",
    "        # FC layers\n",
    "        self.fc1 = nn.Linear(hidden_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def load_glove_embeddings(self, glove_embeddings, embed_size):\n",
    "        \"\"\"Initialize the embedding layer with GloVe embeddings.\"\"\"\n",
    "        weights_matrix = torch.zeros((self.embedding.num_embeddings, embed_size))\n",
    "\n",
    "        for i, word in enumerate(glove_embeddings):\n",
    "            try:\n",
    "                weights_matrix[i] = torch.FloatTensor(glove_embeddings[word])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(torch.FloatTensor(glove_embeddings[word]).size())\n",
    "                print(f'word: {word}, i: {i}')\n",
    "\n",
    "        self.embedding.load_state_dict({'weight': weights_matrix})\n",
    "\n",
    "    def forward(self, pad_seqs, seq_lengths, hidden):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        pad_seqs of shape (max_seq_length, batch_size): Padded source sequences.\n",
    "        seq_lengths: List of sequence lengths.\n",
    "        hidden of shape (1, batch_size, hidden_size): Initial states of the GRU.\n",
    "\n",
    "        Returns:\n",
    "        outputs of shape (max_seq_length, batch_size, hidden_size): Padded outputs of GRU at every step.\n",
    "        hidden of shape (1, batch_size, hidden_size): Updated states of the GRU.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        embedded = self.embedding(pad_seqs) # shape: (max_seq_length, batch_size, embed_size)\n",
    "        # reshape before feeding through the CNN layers\n",
    "        embedded = embedded.permute(1, 2, 0)  # shape: (batch_size, embed_size, max_seq_length)\n",
    "        \n",
    "        # Apply CNN and ReLU activation\n",
    "        cnn_out = [torch.relu(conv(embedded)) for conv in self.convs]\n",
    "        # for i, out in enumerate(cnn_out):\n",
    "        #     print(f'cnn_out[{i}] size: {out.size()}') # shape: (batch_size, num_filters, max_seq_length)\n",
    "        cnn_out = torch.cat(cnn_out, 1)  # concatenate along the channel dimension shape: (batch_size, num_filters * len(kernel_sizes), max_seq_length)\n",
    "        cnn_out = cnn_out.permute(2, 0, 1)  # shape: (max_seq_length, batch_size, conv_output_size)\n",
    "        embedded = cnn_out\n",
    "        # feed through the LSTM layer\n",
    "        packed = pack_padded_sequence(embedded, seq_lengths)\n",
    "        outputs, hidden = self.lstm(packed, hidden) \n",
    "        outputs, output_lengths = pad_packed_sequence(outputs, batch_first=False) # shape: (max_seq_length, batch_size, hidden_size)\n",
    "        last_timesteps = torch.stack([outputs[length-1, i] for i, length in enumerate(output_lengths)]) # shape: (batch_size, hidden_size)\n",
    "        # feed through the fully connected layer\n",
    "        outputs = self.fc1(last_timesteps)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.relu(outputs)\n",
    "        outputs = self.fc2(outputs)\n",
    "        # outputs = self.sigmoid(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size=1, device='cpu'):\n",
    "        num_directions = 1\n",
    "        return (\n",
    "            torch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "            torch.zeros(self.lstm.num_layers * num_directions, batch_size, self.hidden_size).to(device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "def test_LSTM_shapes():\n",
    "    hidden_size = 3\n",
    "    lstm = LSTM(src_dictionary_size=5, embed_size=10, hidden_size=hidden_size)\n",
    "\n",
    "    max_seq_length = 4\n",
    "    batch_size = 2\n",
    "    hidden = lstm.init_hidden(batch_size=batch_size)\n",
    "    pad_seqs = torch.tensor([\n",
    "        [        1,             2],\n",
    "        [        2,     EOS_token],\n",
    "        [        3, PADDING_VALUE],\n",
    "        [EOS_token, PADDING_VALUE]\n",
    "    ])\n",
    "\n",
    "    outputs = lstm.forward(pad_seqs=pad_seqs, seq_lengths=[4, 2], hidden=hidden)\n",
    "    assert outputs.shape == torch.Size([batch_size, 1]), f\"Bad outputs.shape: {outputs.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_LSTM_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, val_loader):\n",
    "\tmodel.eval()\n",
    "\ttotal_loss = 0\n",
    "\tcriterion = nn.BCELoss()\n",
    "\twith torch.no_grad():\n",
    "\t\tfor i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(val_loader):\n",
    "\t\t\tsrc_seqs, tgt_labels = src_seqs.to(device), tgt_labels.to(device)\n",
    "\t\t\thidden = model.init_hidden(src_seqs.shape[1], device=device)\n",
    "\t\t\toutputs = model(src_seqs, src_seq_lengths, hidden)\n",
    "\t\t\tloss = criterion(outputs.squeeze(), tgt_labels.float())\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\treturn total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99000\n"
     ]
    }
   ],
   "source": [
    "# We create custom DataLoader using the implemented collate function\n",
    "# We are going to process 640 sequences at the same time (batch_size=640)\n",
    "# load vocab\n",
    "# vocab = torch.load('vocab.pth')\n",
    "# vocab = None\n",
    "# trainset = TranslationDataset('train_2024.csv', vocab=vocab)\n",
    "trainset = torch.load('datasets/lstm/trainset.pth')\n",
    "print(len(trainset.text))\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=640, shuffle=False, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    }
   ],
   "source": [
    "# We create custom DataLoader using the implemented collate function\n",
    "# We are going to process 64 sequences at the same time (batch_size=64)\n",
    "# valset = TranslationDataset('dev_2024.csv', vocab=trainset.vocab)\n",
    "valset = torch.load('datasets/lstm/valset.pth')\n",
    "print(len(valset.text))\n",
    "valloader = DataLoader(dataset=valset, batch_size=256, shuffle=False, collate_fn=collate, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trainset\n",
    "# torch.save(trainset, 'trainset.pth')\n",
    "\n",
    "# save valset\n",
    "# torch.save(valset, 'valset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance, patience):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          patience (int):    Maximum number of epochs with unsuccessful updates.\n",
    "          tolerance (float): We assume that the update is unsuccessful if the validation error is larger\n",
    "                              than the best validation error so far plus this tolerance.\n",
    "        \"\"\"\n",
    "        self.tolerance = tolerance\n",
    "        self.patience = patience\n",
    "    \n",
    "    def stop_criterion(self, val_errors):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          val_errors (iterable): Validation errors after every update during training.\n",
    "        \n",
    "        Returns: True if training should be stopped: when the validation error is larger than the best\n",
    "                  validation error obtained so far (with given tolearance) for patience epochs (number of consecutive epochs for which the criterion is satisfied).\n",
    "                 \n",
    "                 Otherwise, False.\n",
    "        \"\"\"\n",
    "        if len(val_errors) <= self.patience:\n",
    "            return False\n",
    "\n",
    "        min_val_error = min(val_errors)\n",
    "        val_errors = np.array(val_errors[-self.patience:])\n",
    "        return all(val_errors > min_val_error + self.tolerance)\n",
    "\n",
    "early_stop = EarlyStopping(tolerance=0.001, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# Create the LSTM model\n",
    "hidden_size = embed_size = 256\n",
    "lstm = LSTM(trainset.vocab_size, embed_size, hidden_size).to(device)\n",
    "\n",
    "# Load pretrained LSTM\n",
    "# lstm.load_state_dict(torch.load('lstm_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue training\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 1, iter 10: avg. loss = 0.2052, Time spent: 4.75s\n",
      "Epoch 1, iter 20: avg. loss = 0.2008, Time spent: 5.09s\n",
      "Epoch 1, iter 30: avg. loss = 0.1968, Time spent: 8.31s\n",
      "Epoch 1, iter 40: avg. loss = 0.1959, Time spent: 5.94s\n",
      "Epoch 1, iter 50: avg. loss = 0.1912, Time spent: 5.70s\n",
      "Epoch 1, iter 60: avg. loss = 0.1879, Time spent: 5.42s\n",
      "Epoch 1, iter 70: avg. loss = 0.1865, Time spent: 5.26s\n",
      "Epoch 1, iter 80: avg. loss = 0.1839, Time spent: 5.56s\n",
      "Epoch 1, iter 90: avg. loss = 0.1822, Time spent: 10.76s\n",
      "Epoch 1, iter 100: avg. loss = 0.1820, Time spent: 5.45s\n",
      "Epoch 1, iter 110: avg. loss = 0.1828, Time spent: 5.78s\n",
      "Epoch 1, iter 120: avg. loss = 0.1833, Time spent: 5.45s\n",
      "Epoch 1, iter 130: avg. loss = 0.1823, Time spent: 6.67s\n",
      "Epoch 1, iter 140: avg. loss = 0.1820, Time spent: 4.60s\n",
      "Epoch 1, iter 150: avg. loss = 0.1830, Time spent: 4.72s\n",
      "find new best model, save to lstm.pth, eval_loss: 0.2162\n",
      "Epoch 1, val loss = 0.2162, train loss = 0.1829; Time spent: 891.66s\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 2, iter 10: avg. loss = 0.1783, Time spent: 5.31s\n",
      "Epoch 2, iter 20: avg. loss = 0.1817, Time spent: 4.65s\n",
      "Epoch 2, iter 30: avg. loss = 0.1790, Time spent: 8.16s\n",
      "Epoch 2, iter 40: avg. loss = 0.1756, Time spent: 5.39s\n",
      "Epoch 2, iter 50: avg. loss = 0.1711, Time spent: 4.87s\n",
      "Epoch 2, iter 60: avg. loss = 0.1681, Time spent: 5.34s\n",
      "Epoch 2, iter 70: avg. loss = 0.1674, Time spent: 5.24s\n",
      "Epoch 2, iter 80: avg. loss = 0.1660, Time spent: 5.68s\n",
      "Epoch 2, iter 90: avg. loss = 0.1644, Time spent: 10.02s\n",
      "Epoch 2, iter 100: avg. loss = 0.1642, Time spent: 5.02s\n",
      "Epoch 2, iter 110: avg. loss = 0.1651, Time spent: 6.07s\n",
      "Epoch 2, iter 120: avg. loss = 0.1664, Time spent: 5.07s\n",
      "Epoch 2, iter 130: avg. loss = 0.1660, Time spent: 5.74s\n",
      "Epoch 2, iter 140: avg. loss = 0.1655, Time spent: 4.67s\n",
      "Epoch 2, iter 150: avg. loss = 0.1654, Time spent: 5.71s\n",
      "find new best model, save to lstm.pth, eval_loss: 0.2002\n",
      "Epoch 2, val loss = 0.2002, train loss = 0.1652; Time spent: 881.16s\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 3, iter 10: avg. loss = 0.1646, Time spent: 4.70s\n",
      "Epoch 3, iter 20: avg. loss = 0.1663, Time spent: 5.74s\n",
      "Epoch 3, iter 30: avg. loss = 0.1643, Time spent: 8.70s\n",
      "Epoch 3, iter 40: avg. loss = 0.1616, Time spent: 6.00s\n",
      "Epoch 3, iter 50: avg. loss = 0.1574, Time spent: 5.02s\n",
      "Epoch 3, iter 60: avg. loss = 0.1543, Time spent: 5.72s\n",
      "Epoch 3, iter 70: avg. loss = 0.1527, Time spent: 4.79s\n",
      "Epoch 3, iter 80: avg. loss = 0.1511, Time spent: 5.48s\n",
      "Epoch 3, iter 90: avg. loss = 0.1497, Time spent: 8.52s\n",
      "Epoch 3, iter 100: avg. loss = 0.1496, Time spent: 4.83s\n",
      "Epoch 3, iter 110: avg. loss = 0.1501, Time spent: 4.88s\n",
      "Epoch 3, iter 120: avg. loss = 0.1517, Time spent: 4.72s\n",
      "Epoch 3, iter 130: avg. loss = 0.1548, Time spent: 5.41s\n",
      "Epoch 3, iter 140: avg. loss = 0.1566, Time spent: 4.68s\n",
      "Epoch 3, iter 150: avg. loss = 0.1587, Time spent: 4.87s\n",
      "Epoch 3, val loss = 0.2138, train loss = 0.1594; Time spent: 829.56s\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 4, iter 10: avg. loss = 0.1786, Time spent: 4.73s\n",
      "Epoch 4, iter 20: avg. loss = 0.1773, Time spent: 5.00s\n",
      "Epoch 4, iter 30: avg. loss = 0.1742, Time spent: 7.09s\n",
      "Epoch 4, iter 40: avg. loss = 0.1702, Time spent: 4.48s\n",
      "Epoch 4, iter 50: avg. loss = 0.1651, Time spent: 5.37s\n",
      "Epoch 4, iter 60: avg. loss = 0.1605, Time spent: 4.32s\n",
      "Epoch 4, iter 70: avg. loss = 0.1582, Time spent: 4.10s\n",
      "Epoch 4, iter 80: avg. loss = 0.1554, Time spent: 4.08s\n",
      "Epoch 4, iter 90: avg. loss = 0.1537, Time spent: 7.58s\n",
      "Epoch 4, iter 100: avg. loss = 0.1529, Time spent: 4.31s\n",
      "Epoch 4, iter 110: avg. loss = 0.1562, Time spent: 4.86s\n",
      "Epoch 4, iter 120: avg. loss = 0.1587, Time spent: 6.38s\n",
      "Epoch 4, iter 130: avg. loss = 0.1596, Time spent: 6.91s\n",
      "Epoch 4, iter 140: avg. loss = 0.1596, Time spent: 5.87s\n",
      "Epoch 4, iter 150: avg. loss = 0.1598, Time spent: 4.71s\n",
      "find new best model, save to lstm.pth, eval_loss: 0.1979\n",
      "Epoch 4, val loss = 0.1979, train loss = 0.1591; Time spent: 774.32s\n",
      "Number of batches: 155\n",
      "batch_size: 640\n",
      "Epoch 5, iter 10: avg. loss = 0.1544, Time spent: 4.45s\n",
      "Epoch 5, iter 20: avg. loss = 0.1527, Time spent: 4.49s\n",
      "Epoch 5, iter 30: avg. loss = 0.1498, Time spent: 6.69s\n",
      "Epoch 5, iter 40: avg. loss = 0.1463, Time spent: 4.62s\n",
      "Epoch 5, iter 50: avg. loss = 0.1434, Time spent: 4.44s\n",
      "Epoch 5, iter 60: avg. loss = 0.1407, Time spent: 5.10s\n",
      "Epoch 5, iter 70: avg. loss = 0.1391, Time spent: 4.87s\n",
      "Epoch 5, iter 80: avg. loss = 0.1368, Time spent: 4.51s\n",
      "Epoch 5, iter 90: avg. loss = 0.1354, Time spent: 8.38s\n",
      "Epoch 5, iter 100: avg. loss = 0.1351, Time spent: 5.34s\n",
      "Epoch 5, iter 110: avg. loss = 0.1353, Time spent: 5.28s\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "n_epochs = 20\n",
    "# prompt ask for continue training or not\n",
    "cont = input('Continue training? yes or no')\n",
    "if cont == 'no':\n",
    "\tprint('Fresh training')\n",
    "\ttrain_losses = []\n",
    "\tval_losses = []\n",
    "\tbest_model = None\n",
    "\tbest_val_loss = float('inf')\n",
    "else:\n",
    "\tprint(f'Continue training')\n",
    "\t\n",
    "for epoch in range(n_epochs):\n",
    "\tlstm.train()\n",
    "\trunning_loss = 0.0\n",
    "\tepoch_start_time = time.time()\n",
    "\tprint(f'Number of batches: {len(trainloader)}')\n",
    "\tprint(f'batch_size: {trainloader.batch_size}')\n",
    "\tfor i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(trainloader):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tsrc_seqs, tgt_labels = src_seqs.to(device), tgt_labels.to(device)\n",
    "\t\thidden = lstm.init_hidden(src_seqs.shape[1], device=device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = lstm(src_seqs, src_seq_lengths, hidden)\n",
    "\t\tloss = criterion(outputs.squeeze(), tgt_labels.float())\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\tif i % 10 == 9:\n",
    "\t\t\tprint(f'Epoch {epoch + 1}, iter {i + 1}: avg. loss = {running_loss/(i + 1):.4f}, Time spent: {time.time()-start_time:.2f}s')\n",
    "\ttrain_losses.append(running_loss / len(trainloader))\n",
    "\teval_loss = val_loss(lstm, valloader)\n",
    "\tif eval_loss < best_val_loss:\n",
    "\t\tbest_val_loss = eval_loss\n",
    "\t\tbest_model = lstm.state_dict()\n",
    "\t\tif best_model is not None:\n",
    "\t\t\tprint(f'find new best model, save to lstm.pth, eval_loss: {eval_loss:.4f}')\n",
    "\t\t\ttorch.save(best_model, 'models/lstm.pth')\n",
    "\n",
    "\tif early_stop.stop_criterion(val_losses):\n",
    "\t\tprint(f'Early stopping on epoch {epoch + 1}')\n",
    "\t\tbreak\n",
    "\t\n",
    "\tval_losses.append(eval_loss)\n",
    "\tprint(f'Epoch {epoch + 1}, val loss = {eval_loss:.4f}, train loss = {train_losses[-1]:.4f}; Time spent: {time.time()-epoch_start_time:.2f}s')\n",
    "\trunning_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and vocab\n",
    "torch.save(lstm.state_dict(), 'lstm.pth')\n",
    "torch.save(trainset.vocab, 'vocab.pth')\n",
    "\n",
    "# # Load model\n",
    "# lstm = LSTM(trainset.vocab_size, embed_size, hidden_size).to(device)\n",
    "# lstm.load_state_dict(torch.load('lstm.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assume you have a function to load GloVe embeddings\n",
    "# def load_glove_embeddings(filepath):\n",
    "#     glove_embeddings = {}\n",
    "#     with open(filepath, 'r', encoding='utf-8') as f:\n",
    "#         for line in f:\n",
    "#             values = line.split()\n",
    "#             word = values[0]\n",
    "#             vector = np.asarray(values[1:], dtype='float32')\n",
    "#             glove_embeddings[word] = vector\n",
    "#     return glove_embeddings\n",
    "\n",
    "# # Load GloVe embeddings from a file\n",
    "# glove_embeddings = load_glove_embeddings('glove_embeddings/glove.twitter.27B.100d.txt')\n",
    "\n",
    "# # Create a dictionary with your src_dictionary and GloVe embeddings\n",
    "# src_dictionary = trainset.vocab  # Add your vocabulary here\n",
    "# src_dictionary_size = len(src_dictionary)\n",
    "# embed_size = 100  # Example embedding size\n",
    "\n",
    "# # Map GloVe vectors to your src_dictionary index\n",
    "# mapped_glove_embeddings = {}\n",
    "# for word, index in src_dictionary.get_stoi().items():\n",
    "#     if word in glove_embeddings:\n",
    "#         mapped_glove_embeddings[index] = glove_embeddings[word]\n",
    "#     else:\n",
    "#         # If word is not in GloVe, initialize a random vector\n",
    "#         mapped_glove_embeddings[index] = np.random.normal(scale=0.6, size=(embed_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save mapped_glove_embeddings\n",
      "load mapped_glove_embeddings\n"
     ]
    }
   ],
   "source": [
    "# save and load mapped_glove_embeddings\n",
    "# print('save mapped_glove_embeddings')\n",
    "# torch.save(mapped_glove_embeddings, 'models/mapped_glove_embeddings.pth')\n",
    "print('load mapped_glove_embeddings')\n",
    "mapped_glove_embeddings = torch.load('models/mapped_glove_embeddings.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "embed_size = 100\n",
    "lstm_glove = LSTM(trainset.vocab_size, embed_size, hidden_size, dropout=0.2, glove_embeddings=mapped_glove_embeddings).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_glove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[0;32m----> 3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mlstm_glove\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m      5\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# prompt ask for continue training or not\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm_glove' is not defined"
     ]
    }
   ],
   "source": [
    "# training\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(lstm_glove.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "n_epochs = 40\n",
    "# prompt ask for continue training or not\n",
    "cont = input('Continue training? yes or no')\n",
    "if cont == 'no':\n",
    "\tprint('Fresh training')\n",
    "\ttrain_losses = []\n",
    "\tval_losses = []\n",
    "\tbest_model = None\n",
    "\tbest_val_loss = float('inf')\n",
    "else:\n",
    "\tprint(f'Continue training')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\tlstm_glove.train()\n",
    "\trunning_loss = 0.0\n",
    "\tepoch_start_time = time.time()\n",
    "\tprint(f'Number of batches: {len(trainloader)}')\n",
    "\tprint(f'batch_size: {trainloader.batch_size}')\n",
    "\tfor i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(trainloader):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tsrc_seqs, tgt_labels = src_seqs.to(device), tgt_labels.to(device)\n",
    "\t\thidden = lstm_glove.init_hidden(src_seqs.shape[1], device=device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = lstm_glove(src_seqs, src_seq_lengths, hidden)\n",
    "\t\tloss = criterion(outputs.squeeze(), tgt_labels.float())\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\tif i % 10 == 9:\n",
    "\t\t\tprint(f'Epoch {epoch + 1}, iter {i + 1}: avg. loss = {running_loss/(i + 1):.4f}, Time spent: {time.time()-start_time:.2f}s')\n",
    "\ttrain_losses.append(running_loss / len(trainloader))\n",
    "\teval_loss = val_loss(lstm_glove, valloader)\n",
    "\n",
    "\tif eval_loss < best_val_loss:\n",
    "\t\tbest_val_loss = eval_loss\n",
    "\t\tbest_model = lstm_glove.state_dict()\n",
    "\t\tif best_model is not None:\n",
    "\t\t\tprint(f'find new best model, save to models/lstm_glove.pth, eval_loss: {eval_loss:.4f}')\n",
    "\t\t\ttorch.save(best_model, os.path.join('models', 'lstm_glove.pth'))\n",
    "\n",
    "\t# if early_stop.stop_criterion(val_losses):\n",
    "\t# \tprint(f'Early stopping at epoch {epoch + 1}')\n",
    "\t# \tbreak\n",
    "\t\n",
    "\tval_losses.append(eval_loss)\n",
    "\tprint(f'Epoch {epoch + 1}, val loss = {eval_loss:.4f}, train loss = {train_losses[-1]:.4f}; Time spent: {time.time()-epoch_start_time:.2f}s')\n",
    "\trunning_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load mapped_glove_embeddings\n"
     ]
    }
   ],
   "source": [
    "# load mapped_glove_embeddings\n",
    "print('load mapped_glove_embeddings')\n",
    "mapped_glove_embeddings = torch.load('models/mapped_glove_embeddings.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "embed_size = 100\n",
    "lstm_cnn_glove = LSTM_CNN(trainset.vocab_size, embed_size, hidden_size, num_filters=100, kernel_sizes= [3, 4, 5], dropout=0.2, glove_embeddings=mapped_glove_embeddings).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fresh training\n",
      "Number of batches: 155\n",
      "batch_size: 640\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Workspace\\aalto-snlp-project-spring-2024\\rnn.ipynb Cell 38\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m hidden \u001b[39m=\u001b[39m lstm_cnn_glove\u001b[39m.\u001b[39minit_hidden(src_seqs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m outputs \u001b[39m=\u001b[39m lstm_cnn_glove(src_seqs, src_seq_lengths, hidden)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs\u001b[39m.\u001b[39msqueeze(), tgt_labels\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32md:\\Workspace\\aalto-snlp-project-spring-2024\\rnn.ipynb Cell 38\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m embedded \u001b[39m=\u001b[39m embedded\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m)  \u001b[39m# shape: (batch_size, embed_size, max_seq_length)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Apply CNN and ReLU activation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m cnn_out \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39;49mrelu(conv(embedded)) \u001b[39mfor\u001b[39;49;00m conv \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvs]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# for i, out in enumerate(cnn_out):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m#     print(f'cnn_out[{i}] size: {out.size()}') # shape: (batch_size, num_filters, max_seq_length)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m cnn_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(cnn_out, \u001b[39m1\u001b[39m)  \u001b[39m# concatenate along the channel dimension shape: (batch_size, num_filters * len(kernel_sizes), max_seq_length)\u001b[39;00m\n",
      "\u001b[1;32md:\\Workspace\\aalto-snlp-project-spring-2024\\rnn.ipynb Cell 38\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m embedded \u001b[39m=\u001b[39m embedded\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m)  \u001b[39m# shape: (batch_size, embed_size, max_seq_length)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Apply CNN and ReLU activation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m cnn_out \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mrelu(conv(embedded)) \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# for i, out in enumerate(cnn_out):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m#     print(f'cnn_out[{i}] size: {out.size()}') # shape: (batch_size, num_filters, max_seq_length)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/aalto-snlp-project-spring-2024/rnn.ipynb#Y661sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m cnn_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(cnn_out, \u001b[39m1\u001b[39m)  \u001b[39m# concatenate along the channel dimension shape: (batch_size, num_filters * len(kernel_sizes), max_seq_length)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    307\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "# Without class weights\n",
    "# criterion = nn.BCELoss()\n",
    "# With class weights\n",
    "pos_weight = torch.tensor([2.72]).to(device)  # Adjust the weight as needed\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer = optim.Adam(lstm_cnn_glove.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "n_epochs = 20\n",
    "# prompt ask for continue training or not\n",
    "cont = input('Continue training? yes or no')\n",
    "if cont == 'no':\n",
    "\tprint('Fresh training')\n",
    "\ttrain_losses = []\n",
    "\tval_losses = []\n",
    "\tbest_model = None\n",
    "\tbest_val_loss = float('inf')\n",
    "else:\n",
    "\tprint(f'Continue training')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\tlstm_cnn_glove.train()\n",
    "\trunning_loss = 0.0\n",
    "\tepoch_start_time = time.time()\n",
    "\tprint(f'Number of batches: {len(trainloader)}')\n",
    "\tprint(f'batch_size: {trainloader.batch_size}')\n",
    "\tfor i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(trainloader):\n",
    "\t\tstart_time = time.time()\n",
    "\t\tsrc_seqs, tgt_labels = src_seqs.to(device), tgt_labels.to(device)\n",
    "\t\thidden = lstm_cnn_glove.init_hidden(src_seqs.shape[1], device=device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = lstm_cnn_glove(src_seqs, src_seq_lengths, hidden)\n",
    "\t\tloss = criterion(outputs.squeeze(), tgt_labels.float())\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\tif i % 10 == 9:\n",
    "\t\t\tprint(f'Epoch {epoch + 1}, iter {i + 1}: avg. loss = {running_loss/(i + 1):.4f}, Time spent: {time.time()-start_time:.2f}s')\n",
    "\ttrain_losses.append(running_loss / len(trainloader))\n",
    "\teval_loss = val_loss(lstm_cnn_glove, valloader)\n",
    "\n",
    "\tif eval_loss < best_val_loss:\n",
    "\t\tbest_val_loss = eval_loss\n",
    "\t\tbest_model = lstm_cnn_glove.state_dict()\n",
    "\t\tif best_model is not None:\n",
    "\t\t\tprint(f'find new best model, save to models/lstm_cnn_glove.pth, eval_loss: {eval_loss:.4f}')\n",
    "\t\t\ttorch.save(best_model, os.path.join('models', 'lstm_cnn_glove.pth'))\n",
    "\n",
    "\t# if early_stop.stop_criterion(val_losses):\n",
    "\t# \tprint(f'Early stopping at epoch {epoch + 1}')\n",
    "\t# \tbreak\n",
    "\t\n",
    "\tval_losses.append(eval_loss)\n",
    "\tprint(f'Epoch {epoch + 1}, val loss = {eval_loss:.4f}, train loss = {train_losses[-1]:.4f}; Time spent: {time.time()-epoch_start_time:.2f}s')\n",
    "\trunning_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose model to load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla LSTM\n",
    "# hidden_size = embed_size = 256\n",
    "# lstm = LSTM(trainset.vocab_size, embed_size, hidden_size).to(device)\n",
    "# lstm.load_state_dict(torch.load('models/lstm.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM with GloVe embeddings\n",
    "hidden_size = 256\n",
    "embed_size = 100\n",
    "lstm_glove = LSTM(trainset.vocab_size, embed_size, hidden_size, dropout=0.2, glove_embeddings=None).to(device)\n",
    "lstm_glove.load_state_dict(torch.load('models/lstm_glove.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-CNN with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xuong\\.conda\\envs\\sl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "embed_size = 100\n",
    "lstm_cnn_glove = LSTM_CNN(trainset.vocab_size, embed_size, hidden_size, num_filters=100, kernel_sizes= [3, 4, 5], dropout=0.3, glove_embeddings=None).to(device)\n",
    "lstm_cnn_glove.load_state_dict(torch.load('models/lstm_cnn_glove.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(lstm, pad_src_seqs, src_seq_lengths):\n",
    "    \"\"\"Translate sequences from the source language to the target language using the trained model.\n",
    "\n",
    "    Args:\n",
    "    lstm (LSTM): Trained lstm.\n",
    "    pad_src_seqs of shape (max_src_seq_length, batch_size): Padded source sequences.\n",
    "    src_seq_lengths: List of source sequence lengths.\n",
    "\n",
    "    Returns:\n",
    "    out_seqs of shape (batch_size, 1): LongTensor of word indices of the output sequences.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    with torch.no_grad():\n",
    "        lstm.eval()\n",
    "        pad_src_seqs = pad_src_seqs.to(device)\n",
    "        lstm_hidden = lstm.init_hidden(pad_src_seqs.shape[1], device)\n",
    "        outputs = lstm(pad_src_seqs, src_seq_lengths, lstm_hidden)\n",
    "        out_seqs = outputs > 0.5\n",
    "        return out_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_translate_shapes(lstm):\n",
    "    pad_src_seqs = torch.tensor([\n",
    "        [1, 2],\n",
    "        [2, 3],\n",
    "        [3, 0],\n",
    "        [4, 0]\n",
    "    ])\n",
    "\n",
    "    out_seqs = classify(lstm, pad_src_seqs, src_seq_lengths=[4, 2])\n",
    "    assert out_seqs.shape == torch.Size([2, 1]), f\"Wrong out_seqs.shape: {out_seqs.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_translate_shapes(lstm_cnn_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify training data:\n",
      "-----------------------------\n",
      "SRC: ['the', 'benign', 'effect', 'of', 'the', 'financial', 'crisis', 'in', 'canada', 'that', 'reduce', 'consumer', 'borrowing', 'in', 'the', 'us', 'increase', 'it', 'here', '.', 'low', 'rate', 'but', 'a', 'healthy', 'gap', 'between', 'funding', 'level', 'for', 'bank', 'and', 'prime', 'rate', 'mean', 'huge', 'profit', 'form', 'retail', '.', 'the', 'bank', 'push', 'we', 'all', 'to', 'borrow', 'with', 'slogan', 'like', 'you', 'be', 'wealthy', 'than', 'you', 'think', '.', 'I', 'once', 'hear', 'a', 'bank', 'treasurer', 'imply', 'these', 'spread', 'represent', 'over', 'of', 'their', 'profit', 'the', 'prior', 'year', '.', 'and', 'so', 'it', 'be', 'ironic', 'that', 'the', 'bank', 'be', 'now', 'among', 'those', 'heed', 'the', 'debt', 'level', 'warning', '.', 'there', 'can', 'be', 'no', 'explanation', 'other', 'than', 'that', 'they', 'can', 'not', 'wean', 'themselves', 'off', 'it', 'and', 'need', 'osfi', 'to', 'help', '.', 'it', 'be', 'game', 'theory', 'run', 'amok', 'when', 'an', 'oligopoly', 'need', 'someone', 'outside', 'the', 'game', 'to', 'impel', 'they', 'to', 'change', 'the', 'way', 'they', 'play', '.', 'with', 'house', 'price', 'up', 'as', 'much', 'as', 'they', 'be', 'over', 'the', 'year', 'even', 'those', 'that', 'in', 'a', 'basis', 'point', 'rise', 'may', 'have', 'a', 'little', 'wiggle', 'room', '.', 'I', 'note', 'that', 'no', 'one', 'be', 'estimate', 'the', 'price', 'sensitivity', 'of', 'the', 'real', 'estate', 'market', 'to', 'the', 'move', '.', 'that', 'would', 'be', 'a', 'good', 'piece', 'of', 'work', '.', '<eos>']\n",
      "TGT: 0\n",
      "OUT: False\n",
      "\n",
      "SRC: ['thank', 'you', '<unk>', 'for', 'your', 'wise', 'word', '.', 'you', 'be', 'just', 'a', 'little', 'young', 'than', 'my', 'parent', 'bear', 'in', 'and', '.', 'yes', 'I', 'agree', 'with', 'your', 'statement', 'if', 'die', 'be', 'just', 'a', 'part', 'of', 'the', 'process', 'of', 'life', 'and', 'that', 'be', 'the', 'way', 'god', 'arrange', 'it', 'it', 'must', 'somehow', 'be', 'a', 'good', 'thing', '.', 'but', 'another', 'aspect', 'of', 'death', 'be', 'how', 'it', 'affect', 'our', 'relationship', 'with', 'other', 'living', 'creature', '.', 'we', 'be', 'so', 'easily', 'make', 'to', 'overlook', 'our', 'complicity', 'in', 'the', 'death', 'of', 'other', 'who', 'have', 'as', 'much', 'right', 'to', 'live', 'as', 'we', 'do', 'it', 'be', 'the', 'way', 'of', 'wisdom', 'to', 'pay', 'attention', 'to', 'the', 'life', 'of', 'these', 'countless', 'cousin', 'of', 'ours', 'and', 'never', 'do', 'anything', 'to', 'make', 'their', 'death', 'more', 'painful', 'than', 'they', 'be', '.', 'so', 'on', 'the', 'matter', 'of', 'assisted', 'suicide', 'I', 'be', 'confident', 'that', 'sick', 'people', 'with', 'no', 'hope', 'of', 'live', 'much', 'long', 'do', 'a', 'good', 'thing', 'to', 'spare', 'themselves', 'more', 'pain', 'and', 'their', 'love', 'one', 'inconvenience', '.', 'and', 'those', 'who', 'assist', 'they', 'also', 'do', 'a', 'good', 'thing', 'by', 'be', 'their', 'minister', '.', 'it', 's', 'much', 'well', 'than', 'the', 'unreal', 'inhumane', 'demand', 'of', 'modern', 'medical', 'life', 'save', 'practice', '.', '<eos>', '<unk>']\n",
      "TGT: 0\n",
      "OUT: False\n",
      "\n",
      "SRC: ['to', 'all', 'you', 'idiotic', 'naysayer', 'ok', 'let', 's', 'play', '.', '.', '.', 'say', 'climate', 'change', 'isn', 't', 'be', 'cause', 'by', 'stupid', 'human', 'activity', '<unk>', 'do', 'it', 'not', 'behoove', 'we', 'to', 'do', 'everything', 'we', 'can', 'to', 'mitigate', 'any', 'possibility', 'that', 'it', 'might', 'people', '?', 'I', 'm', 'not', 'say', 'we', 'can', 'fix', 'it', 'overnight', 'but', 'we', 're', 'one', 'of', 'the', 'early', 'generation', 'of', 'a', 'huge', 'industrial', 'revolution', 'and', 'can', 'set', 'the', 'tone', 'for', 'environmental', 'stewardship', 'for', 'future', 'one', '.', 'or', 'be', 'all', 'you', 'lazy', 'minded', 'moron', 'content', 'that', 'we', 'can', 'just', 'happily', 'continue', 'to', 'pollute', 'the', 'atmosphere', 'greedily', 'mine', 'and', 'drill', 'massively', 'over', 'fish', 'the', 'ocean', 'and', 'dump', 'million', 'of', 'metric', 'ton', 'of', 'trash', 'into', 'it', 'and', 'landfill', 'on', 'a', 'daily', 'basis', '?', 'we', 're', 'already', 'tragically', 'late', '!', 'ever', 'hear', 'the', 'saying', 'leave', 'a', 'place', 'in', 'well', 'condition', 'than', 'the', 'way', 'you', 'find', 'it', '.', 'you', 're', 'the', 'type', 'that', 'go', 'to', 'house', 'party', 'and', 'don', 't', 'stick', 'around', 'to', 'help', 'clean', 'up', 'your', 'mess', '.', 'your', 'unbelievably', 'stupid', 'selfish', 'and', 'dismissive', 'attitude', 'towards', 'the', 'environment', 'and', 'even', 'your', 'own', 'family', 's', 'future', 'be', 'just', 'beyond', 'stunning', '.', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "TGT: 1\n",
      "OUT: True\n",
      "\n",
      "SRC: ['oh', 'bullshit', '.', 'go', 'look', 'at', 'the', 'most', 'gender', 'equal', 'country', 'on', 'earth', 'that', 'would', 'be', 'iceland', 'and', 'you', 'll', 'find', 'that', 'the', '<unk>', 'have', 'not', 'be', 'replace', 'by', 'the', 'state', 'it', 'have', 'not', 'be', 'replace', 'by', 'anything', '.', 'people', 'just', 'fail', 'to', 'expect', 'anything', 'from', 'each', 'other', 'base', 'on', 'gender', 'and', 'double', 'standard', 'don', 't', 'exist', '.', 'and', 'contrary', 'to', 'stupid', 'claim', 'elsewhere', 'in', 'the', 'comment', 'guess', 'what', 'else', 'have', 'cease', 'to', 'exist', 'any', 'kind', 'of', '<unk>', '.', 'the', 'big', 'downside', 'iceland', 'have', 'face', 'be', 'that', 'not', 'have', 'any', 'double', 'standard', 'or', 'judgement', 'of', 'people', 's', 'behaviour', 'their', 'enjoyment', 'of', 'daily', 'casual', 'sex', 'have', 'give', 'they', 'a', 'rather', 'high', 'than', 'average', 'rate', 'of', '<unk>', 'know', 'locally', 'as', 'the', '<unk>', 'handshake', 'one', 'of', 'the', 'few', 'stds', 'you', 'can', 'fairly', 'easily', 'catch', 'even', 'when', 'use', 'condom', '.', 'but', 'then', 'it', 'be', 'also', 'one', 'of', 'the', 'easy', 'to', 'cure', 'and', 'with', 'an', 'excellent', 'free', 'for', 'all', 'healthcare', 'system', 'it', 's', 'really', 'not', 'a', 'major', 'problem', '.', 'if', 'that', 's', 'the', 'big', 'price', 'for', 'a', 'society', 'where', 'rape', 'be', 'basically', 'non', 'existent', 'I', 'would', 'pay', 'it', 'with', 'glee', '.', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "TGT: 1\n",
      "OUT: True\n",
      "\n",
      "SRC: ['these', 'poor', 'people', 'a', 'pawn', 'in', 'a', 'cruel', 'political', 'game', '.', 'obama', 'open', 'the', 'door', 'invite', 'their', 'parent', 'in', 'by', 'promise', 'to', 'make', 'their', 'lawbreaking', 'legal', 'and', 'later', 'reward', 'their', 'child', 'by', 'make', 'dream', 'act', 'previously', 'reject', 'by', 'congress', 'into', 'executive', 'order', 'daca', '.', 'he', 'dem', 'have', 'nothing', 'to', 'lose', 'in', 'this', 'cruel', 'game', 'that', 'have', 'nothing', 'to', 'do', 'with', 'compassion', 'and', 'here', 's', 'why', '.', 'if', 'hillary', 'would', 've', 'be', 'elect', 'she', 'would', 'continue', 'it', 'and', 'keep', 'flood', 'the', 'country', 'with', 'democratic', 'voter', '.', 'if', 'a', 'republican', 'win', 'as', 'he', 'do', 'he', 'would', 'have', 'a', 'mess', 'on', 'his', 'hand', 'have', 'to', 'cancel', 'daca', 'which', 'he', 'do', 'and', 'face', 'the', 'backlash', 'of', 'the', 'big', 'chunk', 'of', 'compassionate', 'american', 'voter', 'and', 'endure', 'riot', 'by', 'angry', 'who', 'can', 'blame', 'they', '?', 'the', 'be', 'lie', 'to', 'dreamer', '.', 'a', 'win', 'win', '.', 'it', 'be', 'all', 'plan', '.', 'now', 'obama', 'and', 'his', 'party', 'can', 'sit', 'back', 'pretend', 'to', 'care', 'and', 'enjoy', 'the', 'scenery', 'of', 'angry', 'youth', 'hate', 'on', 'current', 'president', 'who', 'have', 'nothing', 'to', 'do', 'with', 'false', 'illegal', 'promise', 'of', 'the', 'previous', 'administration', '.', 'dreamer', 'should', 'take', 'obama', 'to', 'court', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "TGT: 0\n",
      "OUT: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Translate a few sentences from the training set\n",
    "print('Classify training data:')\n",
    "print('-----------------------------')\n",
    "pad_src_seqs, src_seq_lengths, pad_tgt_seqs, ids = next(iter(valloader))\n",
    "out_seqs = classify(lstm_cnn_glove, pad_src_seqs, src_seq_lengths)\n",
    "\n",
    "for i in range(5):\n",
    "    print('SRC:', seq_to_tokens(pad_src_seqs[:,i], trainset.vocab))\n",
    "    print('TGT:', pad_tgt_seqs[i].item())\n",
    "    print('OUT:', out_seqs[i].item())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset = TranslationDataset('test_2024.csv', vocab=trainset.vocab, dataset_type='test')\n",
    "# testloader = DataLoader(dataset=testset, batch_size=1, shuffle=False, collate_fn=collate, pin_memory=True)\n",
    "# # save testset\n",
    "# torch.save(testset, 'testset.pth')    \n",
    "\n",
    "# load testset\n",
    "testset = torch.load('datasets/lstm/testset.pth')\n",
    "testloader = DataLoader(dataset=testset, batch_size=32, shuffle=False, collate_fn=collate, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10990</th>\n",
       "      <td>10995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10985</th>\n",
       "      <td>10996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>10997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10983</th>\n",
       "      <td>10998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10987</th>\n",
       "      <td>10999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "25         0      0\n",
       "0          1      0\n",
       "11         2      0\n",
       "20         3      1\n",
       "16         4      0\n",
       "...      ...    ...\n",
       "10990  10995      0\n",
       "10985  10996      0\n",
       "10998  10997      1\n",
       "10983  10998      1\n",
       "10987  10999      1\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do inference on test set and save the results into csv file\n",
    "def test_inference(lstm, output_filename='submission.csv', testset=testset):\n",
    "    testloader = DataLoader(dataset=testset, batch_size=32, shuffle=False, collate_fn=collate, pin_memory=True)\n",
    "    out = []\n",
    "    indices = []\n",
    "    for i, (src_seqs, src_seq_lengths, tgt_labels, ids) in enumerate(testloader):\n",
    "        out_seqs = classify(lstm, src_seqs, src_seq_lengths)\n",
    "        try:\n",
    "            out.extend(out_seqs.squeeze().cpu().numpy())\n",
    "        except:\n",
    "            out.append(out_seqs.squeeze().cpu().numpy())\n",
    "        indices.extend(ids)\n",
    "    df = pd.DataFrame({'id': indices, 'label': out})\n",
    "    # convert label to int\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    # sort by id\n",
    "    df = df.sort_values(by='id')\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    return df\n",
    "\n",
    "test_inference(lstm_cnn_glove, output_filename='dev_inference.csv', testset=valset)\n",
    "# test_inference(lstm_cnn_glove, output_filename='submission.csv', testset=testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9315181306851825\n",
      "Recall: 0.9287450623400316\n",
      "F1: 0.9300990432293078\n"
     ]
    }
   ],
   "source": [
    "# import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# Compute Precision, Recall, and F1 Score of the imported predicted csv and the validation df\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Load the predicted csv\n",
    "y_pred = pd.read_csv('dev_inference.csv', index_col=0)\n",
    "y_pred = y_pred['label'].tolist()\n",
    "\n",
    "# Load the validation df\n",
    "y_true = pd.read_csv('dev_2024.csv', quoting=3)\n",
    "y_true = y_true['label'].tolist()\n",
    "\n",
    "# Compute the metrics\n",
    "precision, recall, f1 = compute_metrics(y_true, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
