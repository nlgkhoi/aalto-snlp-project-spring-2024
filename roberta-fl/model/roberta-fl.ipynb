{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa FL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables d'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# # Id des GPU disponibles : 0 et 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/h1q7vkt937n4jdt7nw_1mp040000gn/T/ipykernel_82259/2634764224.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/Users/lgk1910/anaconda3/envs/sl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/lgk1910/anaconda3/envs/sl/lib/python3.10/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/lgk1910/anaconda3/envs/sl/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/lgk1910/anaconda3/envs/sl/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <8E3FD81A-C2E9-3A49-B4B9-6094D47528A4> /Users/lgk1910/anaconda3/envs/sl/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <A69D69E1-75EF-32C4-83CE-D9457021DE94> /Users/lgk1910/anaconda3/envs/sl/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/lgk1910/anaconda3/envs/sl/lib/python3.10/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from typing import Any, Union, Dict, List\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchtext\n",
    "import nltk\n",
    "import sklearn\n",
    "import transformers\n",
    "import torchmetrics as tm\n",
    "from torchmetrics import MetricCollection, Metric, Accuracy, Precision, Recall, AUROC, HammingDistance, F1Score, ROC, AUC, PrecisionRecallCurve\n",
    "\n",
    "\n",
    "from loguru import logger\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOME_NAME = \"test-roberta-fl\"\n",
    "\n",
    "# Dataset\n",
    "DATA_DIR_PATH = os.path.abspath(\"../../\")\n",
    "TRAIN_DATASET_PATH = os.path.join(DATA_DIR_PATH, \"train_2024.csv\")\n",
    "VAL_DATASET_PATH = os.path.join(DATA_DIR_PATH, \"dev_2024.csv\")\n",
    "TEST_DATASET_PATH = os.path.join(DATA_DIR_PATH, \"test_2024.csv\")\n",
    "LABEL_LIST = ['non-toxic', 'toxic']\n",
    "# IDENTITY_LIST = ['male', 'female', 'transgender', 'other_gender', 'heterosexual',\n",
    "#                 'homosexual_gay_or_lesbian', 'bisexual','other_sexual_orientation',\n",
    "#                 'christian', 'jewish', 'muslim', 'hindu','buddhist', 'atheist',\n",
    "#                 'other_religion', 'black', 'white', 'asian', 'latino',\n",
    "#                 'other_race_or_ethnicity', 'physical_disability',\n",
    "#                 'intellectual_or_learning_disability',\n",
    "#                 'psychiatric_or_mental_illness','other_disability']\n",
    "# SELECTED_IDENTITY_LIST = ['male', 'female', 'black', 'white', 'homosexual_gay_or_lesbian',\n",
    "#                     'christian', 'jewish', 'muslim', 'psychiatric_or_mental_illness']\n",
    "\n",
    "# Session\n",
    "SESSION_DIR_PATH = os.path.abspath(\"../../session\")\n",
    "SESSION_DATETIME = datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S-%f\")\n",
    "SESSION_NAME = f\"{CUSTOME_NAME}_{SESSION_DATETIME}\"\n",
    "CURRENT_SESSION_DIR_PATH = os.path.join(SESSION_DIR_PATH, SESSION_NAME)\n",
    "# Créer le dossier de la session\n",
    "os.makedirs(CURRENT_SESSION_DIR_PATH, exist_ok=True)\n",
    "\n",
    "# Architecture de fichier dans `CURRENT_SESSION_DIR_PATH`\n",
    "LOG_FILE_NAME = f\"{SESSION_NAME}.loguru.log\"\n",
    "MODEL_FILE_NAME = f\"{SESSION_NAME}.model\"\n",
    "TEST_FILE_NAME = f\"{SESSION_NAME}.test.csv\"\n",
    "VALIDATION_DATASET_NAME = f\"{SESSION_NAME}.jigsaw2019-validation.csv\"\n",
    "VALIDATION_FILE_NAME = f\"{SESSION_NAME}.validation.csv\"\n",
    "METRIC_FILE_NAME = f\"{SESSION_NAME}.metric.json\"\n",
    "LOG_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, LOG_FILE_NAME)\n",
    "MODEL_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, MODEL_FILE_NAME)\n",
    "TEST_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, TEST_FILE_NAME)\n",
    "VALIDATION_DATASET_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, VALIDATION_DATASET_NAME)\n",
    "VALIDATION_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, VALIDATION_FILE_NAME)\n",
    "METRIC_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, METRIC_FILE_NAME)\n",
    "\n",
    "# CUDA\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-20 22:51:15.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mSESSION_NAME='test-roberta-fl_2024-03-20T22-51-13-063746'\u001b[0m\n",
      "\u001b[32m2024-03-20 22:51:15.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mTRAIN_DATASET_PATH='/Users/lgk1910/Library/CloudStorage/OneDrive-AaltoUniversity/Learning2/Statistical NLP/Assignment/aalto-snlp-project-spring-2024/train_2024.csv'\u001b[0m\n",
      "\u001b[32m2024-03-20 22:51:15.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mVAL_DATASET_PATH='/Users/lgk1910/Library/CloudStorage/OneDrive-AaltoUniversity/Learning2/Statistical NLP/Assignment/aalto-snlp-project-spring-2024/dev_2024.csv'\u001b[0m\n",
      "\u001b[32m2024-03-20 22:51:15.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mTEST_DATASET_PATH='/Users/lgk1910/Library/CloudStorage/OneDrive-AaltoUniversity/Learning2/Statistical NLP/Assignment/aalto-snlp-project-spring-2024/test_2024.csv'\u001b[0m\n",
      "\u001b[32m2024-03-20 22:51:15.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mCURRENT_SESSION_DIR_PATH='/Users/lgk1910/Library/CloudStorage/OneDrive-AaltoUniversity/Learning2/Statistical NLP/Assignment/aalto-snlp-project-spring-2024/session/test-roberta-fl_2024-03-20T22-51-13-063746'\u001b[0m\n",
      "\u001b[32m2024-03-20 22:51:15.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mLABEL_LIST=['non-toxic', 'toxic']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.add(LOG_FILE_PATH, level=\"TRACE\")\n",
    "logger.info(f\"{SESSION_NAME=}\")\n",
    "logger.info(f\"{TRAIN_DATASET_PATH=}\")\n",
    "logger.info(f\"{VAL_DATASET_PATH=}\")\n",
    "logger.info(f\"{TEST_DATASET_PATH=}\")\n",
    "logger.info(f\"{CURRENT_SESSION_DIR_PATH=}\")\n",
    "logger.info(f\"{LABEL_LIST=}\")\n",
    "# logger.info(f\"{IDENTITY_LIST=}\")\n",
    "# logger.info(f\"{SELECTED_IDENTITY_LIST=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérifier la cohérence de l'architecture et l'accès aux ressources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-20 22:51:16.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mChecking consistency...\u001b[0m\n",
      "\u001b[32m2024-03-20 22:51:16.686\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[32m\u001b[1mDatasets are reachable\u001b[0m\n",
      "\u001b[32m2024-03-20 22:51:16.725\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[32m\u001b[1mMPS is available\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Checking consistency...\")\n",
    "\n",
    "# Vérifier l'accès aux datasets\n",
    "if not os.path.exists(TRAIN_DATASET_PATH):\n",
    "    logger.critical(f\"Train dataset does not exist !\")\n",
    "    raise RuntimeError(\"Train dataset does not exist !\")\n",
    "if not os.path.exists(VAL_DATASET_PATH):\n",
    "    logger.critical(f\"Validation dataset does not exist !\")\n",
    "    raise RuntimeError(\"Validation dataset does not exist !\")\n",
    "if not os.path.exists(TEST_DATASET_PATH):\n",
    "    logger.critical(f\"Test dataset does not exist !\")\n",
    "    raise RuntimeError(\"Test dataset does not exist !\")\n",
    "logger.success(\"Datasets are reachable\")\n",
    "\n",
    "# Check if MPS available\n",
    "if not torch.backends.mps.is_available():\n",
    "    logger.critical(\"MPS is not available !\")\n",
    "    raise RuntimeError(\"MPS is not available !\")\n",
    "logger.success(\"MPS is available\")\n",
    "\n",
    "# # Vérifier l'accès aux GPU\n",
    "# GPU_IS_AVAILABLE = torch.cuda.is_available()\n",
    "# GPU_COUNT = torch.cuda.device_count()\n",
    "# logger.info(f\"{GPU_IS_AVAILABLE=}\")\n",
    "# logger.info(f\"{GPU_COUNT=}\")\n",
    "# if not GPU_IS_AVAILABLE:\n",
    "#     logger.critical(\"GPU and CUDA are not available !\")\n",
    "#     raise RuntimeError(\"GPU and CUDA are not available !\")\n",
    "# logger.success(\"GPU and CUDA are available\")\n",
    "# logger.info(f\"{device=}\")\n",
    "# for gpu_id in range(GPU_COUNT):\n",
    "#     gpu_name = torch.cuda.get_device_name(0)\n",
    "#     logger.info(f\"GPU {gpu_id} : {gpu_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_train_df = pd.read_csv(TRAIN_DATASET_PATH, index_col=0)\n",
    "# logger.success(\"Dataset loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pour réduire le nombre d'exemple et savoir sur quel groupes d'identités\n",
    "# # le modèle est entrainé, on prend un sous ensemble du jeu de données\n",
    "# train_df = all_train_df[~all_train_df.white.isna()]\n",
    "# if CUSTOME_NAME.startswith(\"test\"):\n",
    "#     # Si c'est juste une session pour tester le notebook\n",
    "#     logger.debug(\"Mode test is enabled. The training set has been truncated to 20 000 samples.\")\n",
    "#     train_df = train_df[:20_000]\n",
    "# # Pour le jeu de validation, on veut juste avoir des indications de perf\n",
    "# # Peu importe, c'est juste pour voir si l'entraînement s'est bien passé\n",
    "# # Sans pour autant regarder les biais\n",
    "# validation_df = all_train_df[all_train_df.white.isna()].sample(n=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remplacer toutes les colonnes correspondantes aux labels par 1 ou 0\n",
    "# # si la probabilité est supérieure ou égale à 0.5 ou non\n",
    "# train_df[LABEL_LIST] = (train_df[LABEL_LIST]>=0.5).astype(int)\n",
    "# validation_df[LABEL_LIST] = (validation_df[LABEL_LIST]>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-20 22:51:20.111\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[34m\u001b[1mMode test is enabled. The training set has been truncated to 20 000 samples.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATASET_PATH, quoting=3)\n",
    "if CUSTOME_NAME.startswith(\"test\"):\n",
    "    # Si c'est juste une session pour tester le notebook\n",
    "    logger.debug(\"Mode test is enabled. The training set has been truncated to 20 000 samples.\")\n",
    "    train_df = train_df[:10000]\n",
    "validation_df = pd.read_csv(VAL_DATASET_PATH, quoting=3)\n",
    "test_df = pd.read_csv(TEST_DATASET_PATH, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Distribution of labels in the training set'}, xlabel='label'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.groupby(train_df['label']).count()['id'].plot(kind='bar', title='Distribution of labels in the training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, data_df, tokenizer):\n",
    "        self.data = data_df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment = self.data.iloc[index][\"text\"]\n",
    "        label = torch.tensor(self.data.iloc[index]['label'], dtype=torch.float).unsqueeze(0)\n",
    "        \n",
    "        token_list, attention_mask = self.text_to_token_and_mask(comment)\n",
    "\n",
    "        return dict(index=index, ids=token_list, mask=attention_mask, labels=label)\n",
    "    \n",
    "    def text_to_token_and_mask(self, input_text):\n",
    "        tokenization_dict = tokenizer.encode_plus(input_text,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=128,\n",
    "                                padding='max_length',\n",
    "                                truncation=True,\n",
    "                                return_attention_mask=True,\n",
    "                                return_tensors='pt')\n",
    "        token_list = tokenization_dict[\"input_ids\"].flatten()\n",
    "        attention_mask = tokenization_dict[\"attention_mask\"].flatten()\n",
    "        return (token_list, attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_lr(optim, lr):\n",
    "    '''\n",
    "    Set the learning rate in the optimizer\n",
    "    '''\n",
    "    for g in optim.param_groups:\n",
    "        g['lr'] = lr\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer class and functions for models and predictions\n",
    "\n",
    "class TransformerClassifierStack(nn.Module):\n",
    "    def __init__(self, tr_model, nb_labels, dropout_prob=0.4, freeze=False):\n",
    "        super().__init__()\n",
    "        self.tr_model = tr_model\n",
    "\n",
    "        # Stack features of 4 last encoders\n",
    "        self.hidden_dim = tr_model.config.hidden_size * 4\n",
    "\n",
    "        # hidden linear for the classification\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.hl = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        # Last Linear for the classification\n",
    "        self.last_l = nn.Linear(self.hidden_dim, nb_labels)\n",
    "\n",
    "        # freeze all the parameters if necessary\n",
    "        for param in self.tr_model.parameters():\n",
    "            param.requires_grad = not freeze\n",
    "\n",
    "        # init learning params of last layers\n",
    "        torch.nn.init.xavier_uniform_(self.hl.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.last_l.weight)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        # ids = [batch_size, padded_seq_len]\n",
    "        # mask = [batch_size, padded_seq_len]\n",
    "        # mask: avoid to make self attention on padded data\n",
    "        tr_output = self.tr_model(input_ids=ids,\n",
    "                                  attention_mask=mask,\n",
    "                                  output_hidden_states=True)\n",
    "\n",
    "        # Get all the hidden states\n",
    "        hidden_states = tr_output['hidden_states']\n",
    "\n",
    "        # hs_* = [batch_size, padded_seq_len, 768]\n",
    "        hs_1 = hidden_states[-1][:, 0, :]\n",
    "        hs_2 = hidden_states[-2][:, 0, :]\n",
    "        hs_3 = hidden_states[-3][:, 0, :]\n",
    "        hs_4 = hidden_states[-4][:, 0, :]\n",
    "\n",
    "        # features_vec = [batch_size, 768 * 4]\n",
    "        features_vec = torch.cat([hs_1, hs_2, hs_3, hs_4], dim=-1)\n",
    "\n",
    "        x = self.dropout(features_vec)\n",
    "        x = self.hl(x)\n",
    "\n",
    "        # x = [batch_size, 768 * 4]\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.last_l(x)\n",
    "        \n",
    "        # x = [batch_size, 1]\n",
    "        return x\n",
    "\n",
    "def load_roberta_model(nb_labels):\n",
    "    '''\n",
    "    Load RoBERTa model without any checkpoint\n",
    "    RoBERTa for finetuning\n",
    "    '''\n",
    "    logger.info(f\"transformers.RobertaTokenizer : roberta-base\")\n",
    "    logger.info(f\"transformers.AutoModel : roberta-base\")\n",
    "    tokenizer = transformers.RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    tr_model = transformers.AutoModel.from_pretrained('roberta-base')\n",
    "    model = TransformerClassifierStack(tr_model, nb_labels, freeze=True)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def load_roberta_pretrained(model_path, optimizer_path, nb_labels, lr=2e-5):\n",
    "    '''\n",
    "    Load RoBERTa from checkout point (already trained on Hate Speech tasks)\n",
    "    '''\n",
    "    tokenizer = transformers.RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    tr_model = transformers.AutoModel.from_pretrained('roberta-base')\n",
    "    model = TransformerClassifierStack(tr_model, nb_labels)\n",
    "\n",
    "    # loaded = torch.load(path)\n",
    "    # model.load_state_dict(loaded['state_dict'])\n",
    "    print(f'loading model from: {model_path}')\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "\n",
    "    optimizer = transformers.AdamW(model.parameters(), lr=lr)\n",
    "    # optimizer.load_state_dict(loaded['optimizer_dict'])\n",
    "    if optimizer_path:\n",
    "      print(f'loading optimizer from: {optimizer_path}')\n",
    "      optimizer = torch.load(optimizer_path, map_location=device)\n",
    "    optimizer = set_lr(optimizer, lr)\n",
    "\n",
    "    return model, tokenizer, optimizer\n",
    "\n",
    "def preds_fn(batch, model, device):\n",
    "    '''\n",
    "    Get the predictions for one batch according to the model\n",
    "    '''\n",
    "    b_input = batch['ids'].to(device)\n",
    "    b_mask = batch['mask'].to(device)\n",
    "\n",
    "    return model(b_input, b_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: /Users/lgk1910/Library/CloudStorage/OneDrive-AaltoUniversity/Learning2/Statistical NLP/Assignment/aalto-snlp-project-spring-2024/session/roberta-fl_2024-03-17T20-22-46-379849/roberta-fl_2024-03-17T18-58-51-062923.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-17 22:14:21.459\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[32m\u001b[1mModel loaded !\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "# model, tokenizer = load_roberta_model(nb_labels=len(LABEL_LIST))\n",
    "# model, tokenizer = load_roberta_model(nb_labels=1)\n",
    "\n",
    "pretrained_path = \"/Users/lgk1910/Library/CloudStorage/OneDrive-AaltoUniversity/Learning2/Statistical NLP/Assignment/aalto-snlp-project-spring-2024/session/roberta-fl_2024-03-17T20-22-46-379849/roberta-fl_2024-03-17T18-58-51-062923.model\"\n",
    "model, tokenizer, optimizer = load_roberta_pretrained(pretrained_path, None, nb_labels=1)\n",
    "logger.success(\"Model loaded !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamètre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-17 20:22:48.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mBATCH_SIZE=64\u001b[0m\n",
      "\u001b[32m2024-03-17 20:22:48.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mLR=0.0001\u001b[0m\n",
      "\u001b[32m2024-03-17 20:22:48.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mPIN_MEMORY=True\u001b[0m\n",
      "\u001b[32m2024-03-17 20:22:48.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mNUM_WORKERS=0\u001b[0m\n",
      "\u001b[32m2024-03-17 20:22:48.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mPREFETCH_FACTOR=None\u001b[0m\n",
      "\u001b[32m2024-03-17 20:22:48.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mNUM_EPOCHS=1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 320\n",
    "LR=1e-4\n",
    "PIN_MEMORY = True\n",
    "NUM_WORKERS = 0\n",
    "# PREFETCH_FACTOR = 2\n",
    "PREFETCH_FACTOR = None\n",
    "NUM_EPOCHS = 10\n",
    "logger.info(f\"{BATCH_SIZE=}\")\n",
    "logger.info(f\"{LR=}\")\n",
    "logger.info(f\"{PIN_MEMORY=}\")\n",
    "logger.info(f\"{NUM_WORKERS=}\")\n",
    "logger.info(f\"{PREFETCH_FACTOR=}\")\n",
    "logger.info(f\"{NUM_EPOCHS=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self,\n",
    "                 gamma: float = 2,\n",
    "                 reduction: str = \"mean\",\n",
    "                 pos_weight: torch.Tensor = None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma= gamma\n",
    "        self.reduction = reduction\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor,\n",
    "                targets: torch.Tensor):\n",
    "        p = torch.sigmoid(inputs)\n",
    "        ce_loss = F.binary_cross_entropy_with_logits(\n",
    "            inputs, targets, reduction=\"none\", pos_weight=self.pos_weight\n",
    "        )\n",
    "        p_t =  p * targets + (1 - p) * (1 - targets)\n",
    "        loss = ce_loss * ((1 - p_t) ** self.gamma)\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from: https://github.com/Roche/BalancedLossNLP\n",
    "\n",
    "class ResampleLoss(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 use_sigmoid=True, partial=False,\n",
    "                 loss_weight=1.0, reduction='mean',\n",
    "                 reweight_func=None,  # None, 'inv', 'sqrt_inv', 'rebalance', 'CB'\n",
    "                 weight_norm=None, # None, 'by_instance', 'by_batch'\n",
    "                 focal=dict(\n",
    "                     focal=True,\n",
    "                     alpha=0.5,\n",
    "                     gamma=2,\n",
    "                 ),\n",
    "                 map_param=dict(\n",
    "                     alpha=10.0,\n",
    "                     beta=0.2,\n",
    "                     gamma=0.1\n",
    "                 ),\n",
    "                 CB_loss=dict(\n",
    "                     CB_beta=0.9,\n",
    "                     CB_mode='average_w'  # 'by_class', 'average_n', 'average_w', 'min_n'\n",
    "                 ),\n",
    "                 logit_reg=dict(\n",
    "                     neg_scale=5.0,\n",
    "                     init_bias=0.1\n",
    "                 ),\n",
    "                 class_freq=None,\n",
    "                 train_num=None):\n",
    "        super(ResampleLoss, self).__init__()\n",
    "\n",
    "        assert (use_sigmoid is True) or (partial is False)\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "        self.partial = partial\n",
    "        self.loss_weight = loss_weight\n",
    "        self.reduction = reduction\n",
    "        if self.use_sigmoid:\n",
    "            if self.partial:\n",
    "                raise RuntimeError(\"Not defined here\")\n",
    "                self.cls_criterion = partial_cross_entropy\n",
    "            else:\n",
    "                self.cls_criterion = binary_cross_entropy\n",
    "        else:\n",
    "            raise RuntimeError(\"Not defined here\")\n",
    "            self.cls_criterion = cross_entropy\n",
    "\n",
    "        # reweighting function\n",
    "        self.reweight_func = reweight_func\n",
    "\n",
    "        # normalization (optional)\n",
    "        self.weight_norm = weight_norm\n",
    "\n",
    "        # focal loss params\n",
    "        self.focal = focal['focal']\n",
    "        self.gamma = focal['gamma']\n",
    "        self.alpha = focal['alpha'] # change to alpha\n",
    "\n",
    "        # mapping function params\n",
    "        self.map_alpha = map_param['alpha']\n",
    "        self.map_beta = map_param['beta']\n",
    "        self.map_gamma = map_param['gamma']\n",
    "\n",
    "        # CB loss params (optional)\n",
    "        self.CB_beta = CB_loss['CB_beta']\n",
    "        self.CB_mode = CB_loss['CB_mode']\n",
    "\n",
    "        self.class_freq = torch.from_numpy(np.asarray(class_freq)).float().cuda()\n",
    "        self.num_classes = self.class_freq.shape[0]\n",
    "        self.train_num = train_num # only used to be divided by class_freq\n",
    "        # regularization params\n",
    "        self.logit_reg = logit_reg\n",
    "        self.neg_scale = logit_reg[\n",
    "            'neg_scale'] if 'neg_scale' in logit_reg else 1.0\n",
    "        init_bias = logit_reg['init_bias'] if 'init_bias' in logit_reg else 0.0\n",
    "        # bug fixed https://github.com/wutong16/DistributionBalancedLoss/issues/8\n",
    "        self.init_bias = - torch.log(\n",
    "            self.train_num / self.class_freq - 1) * init_bias\n",
    "\n",
    "        self.freq_inv = torch.ones(self.class_freq.shape).cuda() / self.class_freq\n",
    "        self.propotion_inv = self.train_num / self.class_freq\n",
    "\n",
    "    def forward(self,\n",
    "                cls_score,\n",
    "                label,\n",
    "                weight=None,\n",
    "                avg_factor=None,\n",
    "                reduction_override=None,\n",
    "                **kwargs):\n",
    "\n",
    "        assert reduction_override in (None, 'none', 'mean', 'sum')\n",
    "        reduction = (\n",
    "            reduction_override if reduction_override else self.reduction)\n",
    "\n",
    "        weight = self.reweight_functions(label)\n",
    "\n",
    "        cls_score, weight = self.logit_reg_functions(label.float(), cls_score, weight)\n",
    "\n",
    "        if self.focal:\n",
    "            logpt = self.cls_criterion(\n",
    "                cls_score.clone(), label, weight=None, reduction='none',\n",
    "                avg_factor=avg_factor)\n",
    "            # pt is sigmoid(logit) for pos or sigmoid(-logit) for neg\n",
    "            pt = torch.exp(-logpt)\n",
    "            wtloss = self.cls_criterion(\n",
    "                cls_score, label.float(), weight=weight, reduction='none')\n",
    "            alpha_t = torch.where(label==1, self.alpha, 1-self.alpha)\n",
    "            loss = alpha_t * ((1 - pt) ** self.gamma) * wtloss # balance_param should be a tensor\n",
    "            loss = reduce_loss(loss, reduction)             # add reduction\n",
    "        else:\n",
    "            loss = self.cls_criterion(cls_score, label.float(), weight,\n",
    "                                      reduction=reduction)\n",
    "\n",
    "        loss = self.loss_weight * loss\n",
    "        return loss\n",
    "\n",
    "    def reweight_functions(self, label):\n",
    "        if self.reweight_func is None:\n",
    "            return None\n",
    "        elif self.reweight_func in ['inv', 'sqrt_inv']:\n",
    "            weight = self.RW_weight(label.float())\n",
    "        elif self.reweight_func in 'rebalance':\n",
    "            weight = self.rebalance_weight(label.float())\n",
    "        elif self.reweight_func in 'CB':\n",
    "            weight = self.CB_weight(label.float())\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        if self.weight_norm is not None:\n",
    "            if 'by_instance' in self.weight_norm:\n",
    "                max_by_instance, _ = torch.max(weight, dim=-1, keepdim=True)\n",
    "                weight = weight / max_by_instance\n",
    "            elif 'by_batch' in self.weight_norm:\n",
    "                weight = weight / torch.max(weight)\n",
    "\n",
    "        return weight\n",
    "\n",
    "    def logit_reg_functions(self, labels, logits, weight=None): \n",
    "        if not self.logit_reg:\n",
    "            return logits, weight\n",
    "        if 'init_bias' in self.logit_reg:\n",
    "            logits += self.init_bias\n",
    "        if 'neg_scale' in self.logit_reg:\n",
    "            logits = logits * (1 - labels) * self.neg_scale  + logits * labels\n",
    "            if weight is not None:\n",
    "                weight = weight / self.neg_scale * (1 - labels) + weight * labels\n",
    "        return logits, weight\n",
    "\n",
    "    def rebalance_weight(self, gt_labels):\n",
    "        repeat_rate = torch.sum( gt_labels.float() * self.freq_inv, dim=1, keepdim=True)\n",
    "        pos_weight = self.freq_inv.clone().detach().unsqueeze(0) / repeat_rate\n",
    "        # pos and neg are equally treated\n",
    "        weight = torch.sigmoid(self.map_beta * (pos_weight - self.map_gamma)) + self.map_alpha\n",
    "        return weight\n",
    "\n",
    "    def CB_weight(self, gt_labels):\n",
    "        if  'by_class' in self.CB_mode:\n",
    "            weight = torch.tensor((1 - self.CB_beta)).cuda() / \\\n",
    "                     (1 - torch.pow(self.CB_beta, self.class_freq)).cuda()\n",
    "        elif 'average_n' in self.CB_mode:\n",
    "            avg_n = torch.sum(gt_labels * self.class_freq, dim=1, keepdim=True) / \\\n",
    "                    torch.sum(gt_labels, dim=1, keepdim=True)\n",
    "            weight = torch.tensor((1 - self.CB_beta)).cuda() / \\\n",
    "                     (1 - torch.pow(self.CB_beta, avg_n)).cuda()\n",
    "        elif 'average_w' in self.CB_mode:\n",
    "            weight_ = torch.tensor((1 - self.CB_beta)).cuda() / \\\n",
    "                      (1 - torch.pow(self.CB_beta, self.class_freq)).cuda()\n",
    "            weight = torch.sum(gt_labels * weight_, dim=1, keepdim=True) / \\\n",
    "                     torch.sum(gt_labels, dim=1, keepdim=True)\n",
    "        elif 'min_n' in self.CB_mode:\n",
    "            min_n, _ = torch.min(gt_labels * self.class_freq +\n",
    "                                 (1 - gt_labels) * 100000, dim=1, keepdim=True)\n",
    "            weight = torch.tensor((1 - self.CB_beta)).cuda() / \\\n",
    "                     (1 - torch.pow(self.CB_beta, min_n)).cuda()\n",
    "        else:\n",
    "            raise NameError\n",
    "        return weight\n",
    "\n",
    "    def RW_weight(self, gt_labels, by_class=True):\n",
    "        if 'sqrt' in self.reweight_func:\n",
    "            weight = torch.sqrt(self.propotion_inv)\n",
    "        else:\n",
    "            weight = self.propotion_inv\n",
    "        if not by_class:\n",
    "            sum_ = torch.sum(weight * gt_labels, dim=1, keepdim=True)\n",
    "            weight = sum_ / torch.sum(gt_labels, dim=1, keepdim=True)\n",
    "        return weight\n",
    "    \n",
    "\n",
    "def reduce_loss(loss, reduction):\n",
    "    \"\"\"Reduce loss as specified.\n",
    "    Args:\n",
    "        loss (Tensor): Elementwise loss tensor.\n",
    "        reduction (str): Options are \"none\", \"mean\" and \"sum\".\n",
    "    Return:\n",
    "        Tensor: Reduced loss tensor.\n",
    "    \"\"\"\n",
    "    reduction_enum = F._Reduction.get_enum(reduction)\n",
    "    # none: 0, elementwise_mean:1, sum: 2\n",
    "    if reduction_enum == 0:\n",
    "        return loss\n",
    "    elif reduction_enum == 1:\n",
    "        return loss.mean()\n",
    "    elif reduction_enum == 2:\n",
    "        return loss.sum()\n",
    "\n",
    "\n",
    "def weight_reduce_loss(loss, weight=None, reduction='mean', avg_factor=None):\n",
    "    \"\"\"Apply element-wise weight and reduce loss.\n",
    "    Args:\n",
    "        loss (Tensor): Element-wise loss.\n",
    "        weight (Tensor): Element-wise weights.\n",
    "        reduction (str): Same as built-in losses of PyTorch.\n",
    "        avg_factor (float): Avarage factor when computing the mean of losses.\n",
    "    Returns:\n",
    "        Tensor: Processed loss values.\n",
    "    \"\"\"\n",
    "    # if weight is specified, apply element-wise weight\n",
    "    if weight is not None:\n",
    "        loss = loss * weight\n",
    "\n",
    "    # if avg_factor is not specified, just reduce the loss\n",
    "    if avg_factor is None:\n",
    "        loss = reduce_loss(loss, reduction)\n",
    "    else:\n",
    "        # if reduction is mean, then average the loss by avg_factor\n",
    "        if reduction == 'mean':\n",
    "            loss = loss.sum() / avg_factor\n",
    "        # if reduction is 'none', then do nothing, otherwise raise an error\n",
    "        elif reduction != 'none':\n",
    "            raise ValueError('avg_factor can not be used with reduction=\"sum\"')\n",
    "    return loss\n",
    "\n",
    "\n",
    "def binary_cross_entropy(pred,\n",
    "                         label,\n",
    "                         weight=None,\n",
    "                         reduction='mean',\n",
    "                         avg_factor=None):\n",
    "\n",
    "    # weighted element-wise losses\n",
    "    if weight is not None:\n",
    "        weight = weight.float()\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(\n",
    "        pred, label.float(), weight, reduction='none')\n",
    "    loss = weight_reduce_loss(loss, reduction=reduction, avg_factor=avg_factor)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_weights_bce(df, classes=LABEL_LIST):\n",
    "    weights = torch.empty((len(classes),))\n",
    "\n",
    "    nb_samples = len(df)\n",
    "\n",
    "    for idx, c in enumerate(classes):\n",
    "        nb_zeros = len(df[df[c] == 0])\n",
    "        nb_ones = nb_samples - nb_zeros\n",
    "        weights[idx] = nb_zeros / nb_ones\n",
    "\n",
    "    return weights\n",
    "\n",
    "def get_label_inv_freq(df, classes=LABEL_LIST):\n",
    "    weights = torch.empty((len(classes),))\n",
    "    nb_samples = len(df)\n",
    "\n",
    "    for idx, c in enumerate(classes):\n",
    "        nb_zeros = len(df[df[c] == 0])\n",
    "        weights[idx] = (nb_zeros / nb_samples)\n",
    "\n",
    "    return weights\n",
    "\n",
    "def get_nb_samples_lab(df, classes=LABEL_LIST):\n",
    "    nb_ones_tot, nb_zeros_tot = [], []\n",
    "    nb_tot = len(df)\n",
    "\n",
    "    for c in classes:\n",
    "        nb_zeros = len(df[df[c] == 0])\n",
    "        nb_ones = nb_tot - nb_zeros\n",
    "\n",
    "        nb_ones_tot.append(nb_ones)\n",
    "        nb_zeros_tot.append(nb_zeros)\n",
    "\n",
    "    return torch.tensor(nb_ones_tot), torch.tensor(nb_zeros_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instancier les différents objets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-17 20:22:48.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mFocalLoss()\u001b[0m\n",
      "\u001b[32m2024-03-17 20:22:48.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mAdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FocalLoss()"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = JigsawDataset(train_df, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             prefetch_factor=PREFETCH_FACTOR,\n",
    "                             pin_memory=PIN_MEMORY)\n",
    "\n",
    "validation_dataset = JigsawDataset(validation_df, tokenizer)\n",
    "validation_dataloader = DataLoader(validation_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             prefetch_factor=PREFETCH_FACTOR,\n",
    "                             pin_memory=PIN_MEMORY)\n",
    "\n",
    "# Pas besoin de Sigmoid en sorti du model seulement pour `BCEWithLogitsLoss`\n",
    "criterion = FocalLoss()\n",
    "logger.info(criterion)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "logger.info(optimizer)\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variantes de Hamming Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HammingLossWithoutThreshold(Metric):\n",
    "    def __init__(self, num_classes=1, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.add_state(\"total\", default=torch.tensor(0, dtype=torch.float32), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"nbr_sample\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        current_nbr_sample, current_nbr_category = preds.shape\n",
    "        if current_nbr_category != self.num_classes:\n",
    "          raise AttributeError(\"`num_classes` != `current_nbr_category` detected in `pred` parameter\")\n",
    "        \n",
    "        current_loss_per_pred = torch.absolute(target - preds)\n",
    "        current_hamming_loss = current_loss_per_pred.sum()\n",
    "\n",
    "        self.total += current_hamming_loss.float()\n",
    "        self.nbr_sample += current_nbr_sample\n",
    "\n",
    "    def compute(self):\n",
    "        return self.total/(self.num_classes*self.nbr_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RebalancedHammingLossWithoutThreshold(Metric):\n",
    "    def __init__(self, num_classes=1, average=\"macro\", dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # average = \"macro\" or None\n",
    "        self.average = average\n",
    "\n",
    "        # Nombre de positif 1 & negatif 0 par categorie\n",
    "        self.add_state(\n",
    "            \"number_positive\",\n",
    "            default=torch.tensor([0 for _ in range(num_classes)]),\n",
    "            dist_reduce_fx=\"sum\",\n",
    "        )\n",
    "        self.add_state(\n",
    "            \"number_negative\",\n",
    "            default=torch.tensor([0 for _ in range(num_classes)]),\n",
    "            dist_reduce_fx=\"sum\",\n",
    "        )\n",
    "\n",
    "        self.add_state(\n",
    "            \"hamming_loss_positive\",\n",
    "            default=torch.tensor([0.0 for _ in range(num_classes)]),\n",
    "            dist_reduce_fx=\"sum\",\n",
    "        )\n",
    "        self.add_state(\n",
    "            \"hamming_loss_negative\",\n",
    "            default=torch.tensor([0.0 for _ in range(num_classes)]),\n",
    "            dist_reduce_fx=\"sum\",\n",
    "        )\n",
    "\n",
    "        self.add_state(\"nbr_sample\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        current_nbr_sample, current_nbr_category = preds.shape\n",
    "        if current_nbr_category != self.num_classes:\n",
    "            raise AttributeError(\n",
    "                \"`num_classes` != `current_nbr_category` detected in `pred` parameter\"\n",
    "            )\n",
    "\n",
    "        # Nombre de positif 1 & negatif 0 par categorie\n",
    "        current_number_positive = target.sum(axis=0)\n",
    "        current_number_negative = current_nbr_sample - target.sum(axis=0)\n",
    "\n",
    "        self.number_positive += current_number_positive.int()\n",
    "        self.number_negative += current_number_negative.int()\n",
    "\n",
    "        self.nbr_sample += current_nbr_sample\n",
    "\n",
    "        for class_id in range(self.num_classes):\n",
    "            positive_filter = target[:, class_id] == 1\n",
    "            negative_filter = target[:, class_id] == 0\n",
    "\n",
    "            target_vector = target[:, class_id]\n",
    "            preds_vector = preds[:, class_id]\n",
    "\n",
    "            # Filtered vector\n",
    "            ## Target\n",
    "            pos_filtered_target_vector = target_vector[positive_filter]\n",
    "            neg_filtered_target_vector = target_vector[negative_filter]\n",
    "            ## Preds\n",
    "            pos_filtered_preds_vector = preds_vector[positive_filter]\n",
    "            neg_filtered_preds_vector = preds_vector[negative_filter]\n",
    "\n",
    "            # Hamming Loss without Threshold\n",
    "            hamming_loss_on_positive = torch.absolute(\n",
    "                pos_filtered_target_vector - pos_filtered_preds_vector\n",
    "            )\n",
    "            hamming_loss_on_negative = torch.absolute(\n",
    "                neg_filtered_target_vector - neg_filtered_preds_vector\n",
    "            )\n",
    "\n",
    "            self.hamming_loss_positive[class_id] += hamming_loss_on_positive.sum()\n",
    "            self.hamming_loss_negative[class_id] += hamming_loss_on_negative.sum()\n",
    "\n",
    "    def compute(self):\n",
    "        factor_pos = self.nbr_sample / (2 * self.number_positive)\n",
    "        factor_neg = self.nbr_sample / (2 * self.number_negative)\n",
    "\n",
    "        rebalanced_hamming_loss_per_class = torch.multiply(\n",
    "            self.hamming_loss_positive, factor_pos\n",
    "        ) + torch.multiply(self.hamming_loss_negative, factor_neg)\n",
    "        if self.average == \"macro\":\n",
    "            return rebalanced_hamming_loss_per_class.sum() / (\n",
    "                self.nbr_sample * self.num_classes\n",
    "            )\n",
    "        return rebalanced_hamming_loss_per_class / (self.nbr_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciation des metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = len(LABEL_LIST)\n",
    "num_classes = 1\n",
    "train_metric_dict = dict()\n",
    "\n",
    "# AUROC Macro\n",
    "auroc_macro = AUROC(num_classes=num_classes, compute_on_step=True, average=\"macro\")\n",
    "train_metric_dict[\"auroc_macro\"] = auroc_macro\n",
    "\n",
    "# AUROC per class\n",
    "auroc_per_class = AUROC(num_classes=num_classes, compute_on_step=True, average=None)\n",
    "train_metric_dict[\"auroc_per_class\"] = auroc_per_class\n",
    "\n",
    "# F1 score global\n",
    "f1 = F1Score()\n",
    "train_metric_dict[\"f1\"] = f1\n",
    "\n",
    "# F1 score per class\n",
    "f1_per_calss = F1Score(num_classes=num_classes, average=None)\n",
    "train_metric_dict[\"f1_per_calss\"] = f1_per_calss\n",
    "\n",
    "# Hamming Distance without Threshold\n",
    "hamming_loss_woutt = HammingLossWithoutThreshold(num_classes=num_classes)\n",
    "train_metric_dict[\"hamming_loss_without_threshold\"] = hamming_loss_woutt\n",
    "\n",
    "# Rebalanced Hamming Distance without Threshold macro\n",
    "rebalanced_hamming_loss_woutt_macro = RebalancedHammingLossWithoutThreshold(\n",
    "    num_classes=num_classes, average=\"macro\"\n",
    ")\n",
    "train_metric_dict[\n",
    "    \"rebalanced_hamming_loss_without_threshold_macro\"\n",
    "] = rebalanced_hamming_loss_woutt_macro\n",
    "\n",
    "# Rebalanced Hamming Distance without Threshold macro\n",
    "rebalanced_hamming_loss_woutt_per_class = RebalancedHammingLossWithoutThreshold(\n",
    "    num_classes=num_classes, average=None\n",
    ")\n",
    "train_metric_dict[\n",
    "    \"rebalanced_hamming_loss_without_threshold_per_class\"\n",
    "] = rebalanced_hamming_loss_woutt_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricCollection(\n",
       "  (auroc_macro): AUROC()\n",
       "  (auroc_per_class): AUROC()\n",
       "  (f1): F1Score()\n",
       "  (f1_per_calss): F1Score()\n",
       "  (hamming_loss_without_threshold): HammingLossWithoutThreshold()\n",
       "  (rebalanced_hamming_loss_without_threshold_macro): RebalancedHammingLossWithoutThreshold()\n",
       "  (rebalanced_hamming_loss_without_threshold_per_class): RebalancedHammingLossWithoutThreshold()\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metric = MetricCollection(train_metric_dict)\n",
    "train_metric.to(device)\n",
    "\n",
    "validation_metric = train_metric.clone()\n",
    "validation_metric.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(object_to_serialize: Any, ensure_ascii: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Serialize any object, i.e. convert an object to JSON\n",
    "    Args:\n",
    "        object_to_serialize (Any): The object to serialize\n",
    "        ensure_ascii (bool, optional): If ensure_ascii is true (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If ensure_ascii is false, these characters will be output as-is. Defaults to True.\n",
    "    Returns:\n",
    "            str: string of serialized object (JSON)\n",
    "    \"\"\"\n",
    "\n",
    "    def dumper(obj: Any) -> Union[str, Dict]:\n",
    "        \"\"\"\n",
    "        Function called recursively by json.dumps to know how to serialize an object.\n",
    "        For example, for datetime, we try to convert it to ISO format rather than\n",
    "        retrieve the list of attributes defined in its object.\n",
    "        Args:\n",
    "            obj (Any): The object to serialize\n",
    "        Returns:\n",
    "            Union[str, Dict]: Serialized object\n",
    "        \"\"\"\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.cpu().numpy().tolist()\n",
    "        elif hasattr(obj, \"__dict__\"):\n",
    "            return obj.__dict__\n",
    "        return str(obj)\n",
    "\n",
    "    return json.dumps(object_to_serialize, default=dumper, ensure_ascii=ensure_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_metric(metric_collection, **kwargs):\n",
    "    \"\"\"\n",
    "    Export MetricCollection to json file\n",
    "\n",
    "    Args:\n",
    "        metric_collection: MetricCollection\n",
    "        **kwargs: field to add in json line\n",
    "    \"\"\"\n",
    "    with open(METRIC_FILE_PATH, \"a\") as f:\n",
    "        metric_collection_value = metric_collection.compute()\n",
    "        metric_collection_value.update(kwargs)\n",
    "        serialized_value = serialize(metric_collection_value)\n",
    "        f.write(serialized_value)\n",
    "        f.write(\"\\n\")\n",
    "    logger.success(\"Metrics are exported !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch_id=None):\n",
    "    model.train()\n",
    "    logger.info(f\"START EPOCH {epoch_id=}\")\n",
    "\n",
    "    progress = tqdm(train_dataloader, desc='training batch...', leave=False)\n",
    "    for batch_id, batch in enumerate(progress):\n",
    "        if batch_id % 1_000 == 0:\n",
    "            valid_epoch(epoch_id=epoch, batch_id=batch_id)\n",
    "        \n",
    "        logger.trace(f\"{batch_id=}\")\n",
    "        token_list_batch = batch[\"ids\"].to(device)\n",
    "        attention_mask_batch = batch[\"mask\"].to(device)\n",
    "        # convert [batch_size, 1] to [batch_size]\n",
    "        label_batch = batch[\"labels\"].squeeze().to(device)\n",
    "\n",
    "        # Reset gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Predict\n",
    "        prediction_batch = model(token_list_batch, attention_mask_batch)\n",
    "        transformed_prediction_batch = prediction_batch.squeeze()\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(transformed_prediction_batch.to(torch.float32), label_batch.to(torch.float32))\n",
    "\n",
    "        # Metrics\n",
    "        proba_prediction_batch = torch.sigmoid(transformed_prediction_batch)\n",
    "        proba_prediction_batch = proba_prediction_batch.unsqueeze(1)\n",
    "        label_batch = label_batch.unsqueeze(1)\n",
    "        train_metrics_collection_dict = train_metric(proba_prediction_batch.to(torch.float32), label_batch.to(torch.int32))\n",
    "        logger.trace(train_metrics_collection_dict)\n",
    "\n",
    "        # Backprop        \n",
    "        loss.backward()\n",
    "        # gradient clip\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar description\n",
    "        progress_description = \"Train Loss : {loss:.4f} - Train AUROC : {acc:.4f}\"\n",
    "        auroc_macro_value = float(train_metrics_collection_dict[\"auroc_macro\"])\n",
    "        progress_description = progress_description.format(loss=loss.item(), acc=auroc_macro_value)\n",
    "        progress.set_description(progress_description)\n",
    "\n",
    "    logger.info(f\"END EPOCH {epoch_id=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_epoch(epoch_id=None, batch_id=None):\n",
    "    model.eval()\n",
    "    logger.info(f\"START VALIDATION {epoch_id=}{batch_id=}\")\n",
    "    validation_metric.reset()\n",
    "\n",
    "    loss_list = []\n",
    "    prediction_list = torch.Tensor([])\n",
    "    target_list = torch.Tensor([])\n",
    "\n",
    "\n",
    "    progress = tqdm(validation_dataloader, desc=\"valid batch...\", leave=False)\n",
    "    for _, batch in enumerate(progress):\n",
    "        \n",
    "        token_list_batch = batch[\"ids\"].to(device)\n",
    "        attention_mask_batch = batch[\"mask\"].to(device)\n",
    "        # convert label_batch shape from [batch_size, 1] to [batch_size]\n",
    "        label_batch = batch[\"labels\"].squeeze().to(device)\n",
    "\n",
    "        # Predict\n",
    "        prediction_batch = model(token_list_batch, attention_mask_batch)\n",
    "\n",
    "        transformed_prediction_batch = prediction_batch.squeeze()\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(\n",
    "            transformed_prediction_batch.to(torch.float32),\n",
    "            label_batch.to(torch.float32),\n",
    "        )\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        proba_prediction_batch = torch.sigmoid(transformed_prediction_batch)\n",
    "        prediction_list = torch.concat(\n",
    "            [prediction_list, proba_prediction_batch.cpu()]\n",
    "        )\n",
    "        target_list = torch.concat([target_list, label_batch.cpu()])\n",
    "\n",
    "        # Metrics\n",
    "        # convert shape from [batch_size] to [batch_size, 1]\n",
    "        proba_prediction_batch = proba_prediction_batch.unsqueeze(1)\n",
    "        label_batch = label_batch.unsqueeze(1)\n",
    "        validation_metric(proba_prediction_batch.to(torch.float32), label_batch.to(torch.int32))\n",
    "\n",
    "    loss_mean = np.mean(loss_list)\n",
    "    logger.trace(validation_metric.compute())\n",
    "    logger.info(f\"END VALIDATION {epoch_id=}{batch_id=}\")\n",
    "    export_metric(validation_metric, epoch_id=epoch_id, batch_id=batch_id, loss=loss_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch...:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[32m2024-03-17 20:22:48.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mSTART EPOCH epoch_id=1\u001b[0m\n",
      "\u001b[32m2024-03-17 20:22:48.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalid_epoch\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mSTART VALIDATION epoch_id=1batch_id=0\u001b[0m\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\u001b[32m2024-03-17 20:26:08.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalid_epoch\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mEND VALIDATION epoch_id=1batch_id=0\u001b[0m\n",
      "\u001b[32m2024-03-17 20:26:08.865\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_metric\u001b[0m:\u001b[36m15\u001b[0m - \u001b[32m\u001b[1mMetrics are exported !\u001b[0m\n",
      "\u001b[32m2024-03-17 20:52:28.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalid_epoch\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mSTART VALIDATION epoch_id=1batch_id=1000\u001b[0m\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\u001b[32m2024-03-17 20:57:04.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalid_epoch\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mEND VALIDATION epoch_id=1batch_id=1000\u001b[0m\n",
      "\u001b[32m2024-03-17 20:57:04.325\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexport_metric\u001b[0m:\u001b[36m15\u001b[0m - \u001b[32m\u001b[1mMetrics are exported !\u001b[0m\n",
      "training epoch...:   0%|          | 0/1 [37:38<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m progress \u001b[38;5;241m=\u001b[39m  tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,NUM_EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining epoch...\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m progress:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     valid_epoch(epoch_id\u001b[38;5;241m=\u001b[39mepoch)\n",
      "Cell \u001b[0;32mIn[127], line 20\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch_id)\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m prediction_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_list_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m transformed_prediction_batch \u001b[38;5;241m=\u001b[39m prediction_batch\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[114], line 30\u001b[0m, in \u001b[0;36mTransformerClassifierStack.forward\u001b[0;34m(self, ids, mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, ids, mask):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# ids = [batch_size, padded_seq_len]\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# mask = [batch_size, padded_seq_len]\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# mask: avoid to make self attention on padded data\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     tr_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtr_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                              \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Get all the hidden states\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m tr_output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_states\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:835\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    829\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    830\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    833\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    834\u001b[0m )\n\u001b[0;32m--> 835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    848\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    513\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    514\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    515\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         output_attentions,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:413\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    403\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:349\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    332\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    339\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    340\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    341\u001b[0m         hidden_states,\n\u001b[1;32m    342\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m         output_attentions,\n\u001b[1;32m    348\u001b[0m     )\n\u001b[0;32m--> 349\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:300\u001b[0m, in \u001b[0;36mRobertaSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    298\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    299\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 300\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/modules/normalization.py:201\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sl/lib/python3.10/site-packages/torch/nn/functional.py:2546\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2544\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2545\u001b[0m     )\n\u001b[0;32m-> 2546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "progress =  tqdm(range(1,NUM_EPOCHS+1), desc='training epoch...', leave=True)\n",
    "for epoch in progress:\n",
    "    # Train\n",
    "    train_epoch(epoch_id=epoch)\n",
    "    \n",
    "    # Validation\n",
    "    valid_epoch(epoch_id=epoch)\n",
    "\n",
    "    # Save\n",
    "    torch.save(model, MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del train_df\n",
    "    del validation_df\n",
    "except NameError:\n",
    "    logger.warning(\"Train DataFrame & Validation DataFrame already deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   0      0\n",
       "1   1      0\n",
       "2   2      0\n",
       "3   3      0\n",
       "4   4      1"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.read_csv('../../sample_submission_2024.csv')\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_DATASET_PATH, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I get the odd feeling Klastri  the head of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I couldn't disagree more with this column; Can...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Does the property owner have a vote in the  ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Shawn  do you think it may be due to the fact ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You proved she turned over 100% of the relevan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  label\n",
       "0   0  I get the odd feeling Klastri  the head of the...      0\n",
       "1   1  I couldn't disagree more with this column; Can...      0\n",
       "2   2  Does the property owner have a vote in the  ta...      0\n",
       "3   3  Shawn  do you think it may be due to the fact ...      0\n",
       "4   4  You proved she turned over 100% of the relevan...      0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'] = 0\n",
    "\n",
    "# Take only 1000 samples\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12001, 3)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = JigsawDataset(test_df, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluation(model):\n",
    "    model.eval()\n",
    "    logger.info(f\"START EVALUATION\")\n",
    "\n",
    "    index_tensor = torch.Tensor([])\n",
    "    prediction_tensor = torch.Tensor([])\n",
    "\n",
    "    progress = tqdm(test_dataloader, desc='test batch...', leave=False)\n",
    "    for batch_id, batch in enumerate(progress):\n",
    "        logger.trace(f\"{batch_id=}\")\n",
    "        index_batch = batch[\"index\"].to(device)\n",
    "        token_list_batch = batch[\"ids\"].to(device)\n",
    "        attention_mask_batch = batch[\"mask\"].to(device)\n",
    "        label_batch = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Predict\n",
    "        prediction_batch = model(token_list_batch, attention_mask_batch)\n",
    "        transformed_prediction_batch = prediction_batch.squeeze()\n",
    "        proba_prediction_batch = torch.sigmoid(transformed_prediction_batch)\n",
    "        \n",
    "        index_tensor = torch.concat([index_tensor, index_batch.cpu()])\n",
    "        prediction_tensor = torch.concat([prediction_tensor, proba_prediction_batch.cpu()])\n",
    "        # print(f'probabilities : {proba_prediction_batch}')\n",
    "        # print(f'probabilities shape : {proba_prediction_batch.shape}')\n",
    "    \n",
    "    logger.info(f\"END EVALUATION\")\n",
    "    prediction_test_df = pd.DataFrame((prediction_tensor > 0.5).int().tolist(), \n",
    "                                     columns=['label'],\n",
    "                                     index=index_tensor.to(int).tolist(),\n",
    "                                     )\n",
    "    # rename index column as id\n",
    "    prediction_test_df.index.name = 'id'\n",
    "    prediction_test_df.to_csv(TEST_FILE_PATH)\n",
    "    print(prediction_test_df)\n",
    "    logger.success(f\"Test predictions exported !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-17 21:36:03.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluation\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mSTART EVALUATION\u001b[0m\n",
      "\u001b[32m2024-03-17 21:36:05.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluation\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEND EVALUATION\u001b[0m\n",
      "\u001b[32m2024-03-17 21:36:05.316\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluation\u001b[0m:\u001b[36m36\u001b[0m - \u001b[32m\u001b[1mTest predictions exported !\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label\n",
      "id       \n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "..    ...\n",
      "95      0\n",
      "96      0\n",
      "97      1\n",
      "98      0\n",
      "99      0\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8688887307573709\n",
      "Recall: 0.8478550290113973\n",
      "F1: 0.8564232189061318\n"
     ]
    }
   ],
   "source": [
    "# import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# Compute Precision, Recall, and F1 Score of the imported predicted csv and the validation df\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Load the predicted csv\n",
    "y_pred = pd.read_csv('../../dev_prediction/dev_new2.csv', index_col=0)\n",
    "y_pred = y_pred['label'].tolist()\n",
    "\n",
    "# Load the validation df\n",
    "y_true = pd.read_csv('/Users/lgk1910/Library/CloudStorage/OneDrive-AaltoUniversity/Learning2/Statistical NLP/Assignment/aalto-snlp-project-spring-2024/dev_2024.csv', quoting=3)\n",
    "y_true = y_true['label'].tolist()\n",
    "\n",
    "# Compute the metrics\n",
    "precision, recall, f1 = compute_metrics(y_true, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxicity': [0.000647831242531538, 0.000647831242531538],\n",
       " 'severe_toxicity': [0.00012098397564841434, 0.00012098397564841434],\n",
       " 'obscene': [0.00018694325990509242, 0.00018694325990509242],\n",
       " 'threat': [0.0001162407934316434, 0.0001162407934316434],\n",
       " 'insult': [0.00018111889949068427, 0.00018111889949068427],\n",
       " 'identity_attack': [0.00014001900854054838, 0.00014001900854054838]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# each model takes in either a string or a list of strings\n",
    "\n",
    "result = model.predict(['example text', 'example text'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/unitaryai/detoxify/releases/download/v0.4-alpha/multilingual_debiased-0b549669.ckpt\" to /Users/lgk1910/.cache/torch/hub/checkpoints/multilingual_debiased-0b549669.ckpt\n",
      "100%|██████████| 1.04G/1.04G [01:02<00:00, 17.8MB/s]\n",
      "100%|██████████| 12001/12001 [09:04<00:00, 22.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12001, 6)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "from detoxify import Detoxify\n",
    "\n",
    "results = {\n",
    "\t'toxicity': [],\n",
    "\t'severe_toxicity': [],\n",
    "\t'obscene': [],\n",
    "\t'threat': [],\n",
    "\t'insult': [],\n",
    "\t'identity_attack': []\n",
    "}\n",
    "model = Detoxify('multilingual', device='cpu')\n",
    "seqs = test_df['text'].tolist()\n",
    "\n",
    "batch_size = 100\n",
    "for i in tqdm.tqdm(range(len(seqs))):\n",
    "\tresult = model.predict(seqs[i])\n",
    "\tfor k in results:\n",
    "\t\tresults[k].append(result[k])\n",
    "\n",
    "# Create a (n, 6) matrix from the results\n",
    "import numpy as np\n",
    "results_matrix = np.array([results[k] for k in results]).T\n",
    "results_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the results and check if any of the labels are above 0.5\n",
    "# If so, set the label to 1, otherwise 0\n",
    "# apply OR operations to the columns of the matrix >= 0.5\n",
    "processed_results = (results_matrix >= 0.5).any(axis=1).astype(int)\n",
    "\n",
    "# Save the results to a csv\n",
    "saved_df = test_df.copy()\n",
    "# drop the text column\n",
    "saved_df.drop(columns='text', inplace=True)\n",
    "# add the processed results\n",
    "saved_df['label'] = processed_results\n",
    "saved_df.to_csv('../../submission/detoxify_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporter les prédictions de la dataset de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 01:13:31.374 | INFO     | __main__:export_validation:4 - START GET PREDICTION ON VALIDATION DATASET\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d59e2dabf924fe6ac8cf387e1494891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid batch...:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 01:14:20.205 | INFO     | __main__:export_validation:27 - END GET PREDICTION ON VALIDATION DATASET\n",
      "2022-03-30 01:14:20.346 | SUCCESS  | __main__:export_validation:36 - Validation predictions exported !\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def export_validation(model):\n",
    "    model.eval()\n",
    "    logger.info(f\"START GET PREDICTION ON VALIDATION DATASET\")\n",
    "\n",
    "    index_tensor = torch.Tensor([])\n",
    "    prediction_tensor = torch.Tensor([])\n",
    "    label_tensor = torch.Tensor([])\n",
    "\n",
    "    progress = tqdm(validation_dataloader, desc='valid batch...', leave=False)\n",
    "    for batch_id, batch in enumerate(progress):\n",
    "        logger.trace(f\"{batch_id=}\")\n",
    "        index_batch = batch[\"index\"].to(device)\n",
    "        token_list_batch = batch[\"ids\"].to(device)\n",
    "        attention_mask_batch = batch[\"mask\"].to(device)\n",
    "        label_batch = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Predict\n",
    "        prediction_batch = model(token_list_batch, attention_mask_batch)\n",
    "        transformed_prediction_batch = prediction_batch.squeeze()\n",
    "        proba_prediction_batch = torch.sigmoid(transformed_prediction_batch)\n",
    "        \n",
    "        index_tensor = torch.concat([index_tensor, index_batch.cpu()])\n",
    "        prediction_tensor = torch.concat([prediction_tensor, proba_prediction_batch.cpu()])\n",
    "        label_tensor = torch.concat([label_tensor, label_batch.cpu()])\n",
    "    \n",
    "    logger.info(f\"END GET PREDICTION ON VALIDATION DATASET\")\n",
    "    prediction_valid_df = pd.DataFrame(prediction_tensor.tolist(), \n",
    "                                     columns=LABEL_LIST,\n",
    "                                     index=index_tensor.to(int).tolist())\n",
    "    label_valid_df = pd.DataFrame(label_tensor.tolist(), \n",
    "                                     columns=LABEL_LIST,\n",
    "                                     index=index_tensor.to(int).tolist())\n",
    "    prediction_valid_df.to_csv(VALIDATION_FILE_PATH)\n",
    "    label_valid_df.to_csv(VALIDATION_DATASET_FILE_PATH)\n",
    "    logger.success(f\"Validation predictions exported !\")\n",
    "export_validation(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61bdec511af6d11ab513a76379a59f4e5a5400220f7b851eb051cbea952f89aa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
